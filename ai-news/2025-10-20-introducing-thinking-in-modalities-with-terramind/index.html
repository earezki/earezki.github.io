<!DOCTYPE html><html lang="en" data-theme="dark"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><!-- Primary Meta Tags --><title>Introducing Thinking-in-Modalities with TerraMind: A Novel Approach to Foundation Models • Dev|Journal</title><meta name="description" content="Introduction to TerraMind and Thinking-in-Modalities (TiM) TerraMind is a new foundation model developed by IBM Research, ESA Φ-lab, and Jülich Supercomputing…"><meta name="keywords" content="software architecture, backend development, microservices, Java, Python, Spring Boot, technical blog"><meta name="author" content="El Mehdi Arezki"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://earezki.com/ai-news/2025-10-20-introducing-thinking-in-modalities-with-terramind/"><meta property="og:title" content="Introducing Thinking-in-Modalities with TerraMind: A Novel Approach to Foundation Models • Dev|Journal"><meta property="og:site_name" content="Dev|Journal"><meta property="og:description" content="Introduction to TerraMind and Thinking-in-Modalities (TiM) TerraMind is a new foundation model developed by IBM Research, ESA Φ-lab, and Jülich Supercomputing…"><meta property="og:image" content="https://earezki.com/assets/og-image-default.jpg"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://earezki.com/ai-news/2025-10-20-introducing-thinking-in-modalities-with-terramind/"><meta name="twitter:title" content="Introducing Thinking-in-Modalities with TerraMind: A Novel Approach to Foundation Models • Dev|Journal"><meta name="twitter:description" content="Introduction to TerraMind and Thinking-in-Modalities (TiM) TerraMind is a new foundation model developed by IBM Research, ESA Φ-lab, and Jülich Supercomputing…"><meta name="twitter:image" content="https://earezki.com/assets/og-image-default.jpg"><meta name="twitter:creator" content="@earezki"><!-- Canonical and Indexing --><link rel="canonical" href="https://earezki.com/ai-news/2025-10-20-introducing-thinking-in-modalities-with-terramind/"><!-- Favicons --><link rel="icon" type="image/svg+xml" href="/favicon.svg"><link rel="icon" type="image/x-icon" href="/favicon.ico"><!-- RSS Feed --><link rel="alternate" type="application/rss+xml" title="RSS" href="/rss.xml"><!-- Analytics: Google Analytics (Legacy UA) --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-161447264-1"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);} 
      gtag('js', new Date()); 
      gtag('config', 'UA-161447264-1');
    </script><!-- Analytics: Umami --><script defer src="https://cloud.umami.is/script.js" data-website-id="4a26531d-1053-4f79-97a6-06a1366aff91"></script><!-- Theme Persistence (runs before page render to prevent flash) --><script>
      (function() {
        const theme = localStorage.getItem('theme');
        if (theme) { 
          document.documentElement.setAttribute('data-theme', theme); 
        }
      })();
    </script><!-- Structured Data (JSON-LD) --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Introducing Thinking-in-Modalities with TerraMind: A Novel Approach to Foundation Models","datePublished":"2025-10-20T00:00:00.000Z","dateModified":"2025-10-20T00:00:00.000Z","author":{"@type":"Person","name":"AREZKI El Mehdi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://earezki.com/ai-news/2025-10-20-introducing-thinking-in-modalities-with-terramind/"},"description":"Introduction to TerraMind and Thinking-in-Modalities (TiM) TerraMind is a new foundation model developed by IBM Research, ESA Φ-lab, and Jülich Supercomputing…"}</script><link rel="stylesheet" href="/_astro/_slug_.DxE91F05.css">
<style>.toc[data-astro-cid-xvrfupwn]{position:sticky;top:90px;max-height:calc(100vh - 120px);overflow:auto;padding:1rem 1rem 1.2rem;background:var(--color-bg-alt);border:1px solid var(--color-border);border-radius:var(--radius-md);font-size:.8rem;line-height:1.3}.toc-title[data-astro-cid-xvrfupwn]{font-weight:600;font-size:.75rem;text-transform:uppercase;letter-spacing:.08em;margin-bottom:.6rem;color:var(--color-text-alt)}.toc[data-astro-cid-xvrfupwn] ul[data-astro-cid-xvrfupwn]{list-style:none;margin:0;padding:0;display:flex;flex-direction:column;gap:.35rem}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]{text-decoration:none;color:var(--color-text-alt);transition:color var(--transition)}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]:hover{color:var(--color-accent)}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn][class*=d-3]{margin-left:.75rem}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn][class*=d-4]{margin-left:1.4rem}@media (max-width: 1080px){.toc[data-astro-cid-xvrfupwn]{display:none}}.breadcrumbs[data-astro-cid-ilhxcym7]{margin:0 0 1.5rem;font-size:.85rem}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{list-style:none;padding:0;margin:0;display:flex;flex-wrap:wrap;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{display:flex;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--color-text-alt);text-decoration:none;transition:color var(--transition)}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{color:var(--color-accent);text-decoration:underline}.breadcrumbs[data-astro-cid-ilhxcym7] .separator[data-astro-cid-ilhxcym7]{color:var(--color-text-alt);opacity:.5;user-select:none}.breadcrumbs[data-astro-cid-ilhxcym7] .current[data-astro-cid-ilhxcym7]{color:var(--color-text);font-weight:500}.related-posts[data-astro-cid-dpgbfi7r]{margin:3rem 0;padding-top:2rem;border-top:2px solid var(--color-border)}.related-posts[data-astro-cid-dpgbfi7r] h2[data-astro-cid-dpgbfi7r]{font-size:1.5rem;margin:0 0 1.5rem;color:var(--color-text)}.related-posts-grid[data-astro-cid-dpgbfi7r]{display:grid;grid-template-columns:repeat(auto-fit,minmax(280px,1fr));gap:1.5rem}.related-post-card[data-astro-cid-dpgbfi7r]{background:var(--color-bg-alt);border:1px solid var(--color-border);border-radius:var(--radius-md);padding:1.25rem;transition:all var(--transition)}.related-post-card[data-astro-cid-dpgbfi7r]:hover{border-color:var(--color-accent);transform:translateY(-2px);box-shadow:var(--shadow-md)}.related-post-link[data-astro-cid-dpgbfi7r]{text-decoration:none;color:inherit;display:block}.related-post-card[data-astro-cid-dpgbfi7r] h3[data-astro-cid-dpgbfi7r]{margin:0 0 .75rem;font-size:1.1rem;font-weight:600;color:var(--color-text);line-height:1.3}.related-post-link[data-astro-cid-dpgbfi7r]:hover h3[data-astro-cid-dpgbfi7r]{color:var(--color-accent)}.related-excerpt[data-astro-cid-dpgbfi7r]{font-size:.85rem;color:var(--color-text-alt);line-height:1.5;margin:0 0 .75rem}.related-meta[data-astro-cid-dpgbfi7r]{font-size:.75rem;color:var(--color-text-alt);display:flex;gap:.5rem;align-items:center}@media (max-width: 680px){.related-posts-grid[data-astro-cid-dpgbfi7r]{grid-template-columns:1fr}}
.post-layout[data-astro-cid-rkg3zjxi]{display:grid;grid-template-columns:260px 1fr;gap:2.5rem}.sidebar-left[data-astro-cid-rkg3zjxi]{position:relative}@media (max-width: 1080px){.post-layout[data-astro-cid-rkg3zjxi]{grid-template-columns:1fr}}.ai-disclaimer-article[data-astro-cid-rkg3zjxi]{display:flex;gap:.75rem;padding:.9rem 1.1rem;margin:0 auto 2rem;max-width:780px;background:linear-gradient(135deg,#667eea1a,#764ba21a,#f093fb1a);border:2px solid transparent;border-radius:var(--radius-md);position:relative;background-clip:padding-box;font-size:.85rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi]:before{content:"";position:absolute;inset:-2px;border-radius:var(--radius-md);padding:2px;background:var(--ai-gradient-border);background-size:200% 200%;animation:gradient-rotate 3s linear infinite;-webkit-mask:linear-gradient(#fff 0 0) content-box,linear-gradient(#fff 0 0);-webkit-mask-composite:xor;mask:linear-gradient(#fff 0 0) content-box,linear-gradient(#fff 0 0);mask-composite:exclude;pointer-events:none}html[data-theme=dark] .ai-disclaimer-article[data-astro-cid-rkg3zjxi]{background:linear-gradient(135deg,#667eea26,#764ba226,#f093fb26)}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] svg[data-astro-cid-rkg3zjxi]{margin-top:.15rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] strong[data-astro-cid-rkg3zjxi]{color:var(--color-text);display:block;margin-bottom:.15rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] div[data-astro-cid-rkg3zjxi]{line-height:1.5;color:var(--color-text-alt)}
</style><script type="module" src="/_astro/hoisted.2U5tn40l.js"></script></head> <body> <div id="readingProgress" role="progressbar" aria-label="Reading progress" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100" style="position:fixed;left:0;top:0;height:3px;background:linear-gradient(90deg,#2563eb,#9333ea);width:0;z-index:999;transition:width .15s ease;"></div>  <!-- Site Header --> <header class="site-header container"> <div class="logo-wrap"> <a class="logo" href="/" aria-label="Dev|Journal Home">
Dev|Journal
</a> </div> <nav class="main-nav" aria-label="Main navigation"> <a href="/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="m3 9 9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path> <polyline points="9 22 9 12 15 12 15 22"></polyline> </svg>
Home
</a> <a href="/ai-news/" class="ai-news-link"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="M12 2a2 2 0 0 1 2 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 0 1 7 7h-9.5a.5.5 0 0 0-.5.5.5.5 0 0 1-1 0 .5.5 0 0 0-.5-.5H1a7 7 0 0 1 7-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 0 1 2-2z"></path> <path d="M7 15v4a2 2 0 0 0 2 2h6a2 2 0 0 0 2-2v-4"></path> </svg>
AI News
</a> <a href="/tags/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="M12 2H2v10l9.29 9.29c.94.94 2.48.94 3.42 0l6.58-6.58c.94-.94.94-2.48 0-3.42L12 2z"></path> <circle cx="7" cy="7" r="1.5"></circle> </svg>
Tags
</a> <a href="/about/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <circle cx="12" cy="12" r="10"></circle> <path d="M12 16v-4"></path> <path d="M12 8h.01"></path> </svg>
About
</a> <button id="themeToggle" class="theme-toggle" aria-label="Toggle dark mode"> <span class="theme-icon" aria-hidden="true">☾</span> <span class="theme-text">dark</span> </button> </nav> </header> <!-- Main Content --> <main class="container content-area">  <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7>  <a href="/" data-astro-cid-ilhxcym7>Home</a> <span class="separator" aria-hidden="true" data-astro-cid-ilhxcym7>/</span>  </li><li data-astro-cid-ilhxcym7>  <a href="/ai-news/" data-astro-cid-ilhxcym7>Ai News</a> <span class="separator" aria-hidden="true" data-astro-cid-ilhxcym7>/</span>  </li><li data-astro-cid-ilhxcym7> <span class="current" aria-current="page" data-astro-cid-ilhxcym7>Introducing Thinking-in-Modalities with TerraMind: A Novel Approach to Foundation Models</span> </li> </ol> </nav>  <div class="ai-disclaimer-article" data-astro-cid-rkg3zjxi> <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="flex-shrink: 0;" data-astro-cid-rkg3zjxi> <circle cx="12" cy="12" r="10" data-astro-cid-rkg3zjxi></circle> <line x1="12" y1="8" x2="12" y2="12" data-astro-cid-rkg3zjxi></line> <line x1="12" y1="16" x2="12.01" y2="16" data-astro-cid-rkg3zjxi></line> </svg> <div data-astro-cid-rkg3zjxi> <strong data-astro-cid-rkg3zjxi>AI-Generated Content:</strong> This article was created with AI assistance. Please verify important information and check original references.
</div> </div> <div class="post-layout" data-astro-cid-rkg3zjxi> <aside class="sidebar-left" data-astro-cid-rkg3zjxi> <nav class="toc" aria-label="Table of Contents" data-astro-cid-xvrfupwn> <div class="toc-title" data-astro-cid-xvrfupwn>On this page</div> <ul data-astro-cid-xvrfupwn> <li class="d-2" data-astro-cid-xvrfupwn> <a href="#introduction-to-terramind-and-thinking-in-modalities-tim" data-astro-cid-xvrfupwn> Introduction to TerraMind and Thinking-in-Modalities (TiM) </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#key-features-and-capabilities" data-astro-cid-xvrfupwn> Key Features and Capabilities </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#how-thinking-in-modalities-tim-works" data-astro-cid-xvrfupwn> How Thinking in Modalities (TiM) Works </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#performance-improvements-with-tim" data-astro-cid-xvrfupwn> Performance Improvements with TiM </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#practical-implementation-with-terratorch" data-astro-cid-xvrfupwn> Practical Implementation with TerraTorch </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#applications-beyond-earth-observation" data-astro-cid-xvrfupwn> Applications Beyond Earth Observation </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#further-resources" data-astro-cid-xvrfupwn> Further Resources </a> </li> </ul> </nav>  </aside> <article class="post" data-astro-cid-rkg3zjxi> <header class="post-header" data-astro-cid-rkg3zjxi> <h1 data-astro-cid-rkg3zjxi>Introducing Thinking-in-Modalities with TerraMind: A Novel Approach to Foundation Models</h1> <div class="meta" data-astro-cid-rkg3zjxi> <time datetime="2025-10-20T00:00:00.000Z" data-astro-cid-rkg3zjxi>Mon Oct 20 2025</time> <span data-astro-cid-rkg3zjxi>• 3 min read</span> </div> <div class="tag-row" data-astro-cid-rkg3zjxi><a class="tag ai-news-tag" href="/tags/ai-news/" data-astro-cid-rkg3zjxi>AI News</a><a class="tag " href="/tags/earth-observation/" data-astro-cid-rkg3zjxi>Earth Observation</a><a class="tag " href="/tags/machine-learning/" data-astro-cid-rkg3zjxi>Machine Learning</a></div> </header> <div class="post-body prose" data-astro-cid-rkg3zjxi> <h2 id="introduction-to-terramind-and-thinking-in-modalities-tim">Introduction to TerraMind and Thinking-in-Modalities (TiM)</h2>
<p>TerraMind is a new foundation model developed by IBM Research, ESA Φ-lab, and Jülich Supercomputing Centre for Earth observation. It’s a dual-scale, any-to-any model capable of learning joint representations across nine different modalities, including satellite imagery (like Sentinel-1 and Sentinel-2), land-cover (LULC), and vegetation indices (NDVI). A key innovation of TerraMind is <strong>Thinking in Modalities (TiM)</strong>, which allows the model to generate missing modalities as intermediate tokens rather than full feature maps. This approach enables the model to overcome data limitations and improve prediction performance.</p>
<h3 id="key-features-and-capabilities">Key Features and Capabilities</h3>
<ul>
<li><strong>Dual-Scale Foundation Model:</strong> TerraMind is designed for flexibility and adaptability across various Earth observation tasks.</li>
<li><strong>Nine Modalities:</strong> The model can process and learn from a diverse set of data types, enhancing its understanding of complex environmental relationships.</li>
<li><strong>Thinking in Modalities (TiM):</strong> This core capability allows the model to “imagine” missing data, filling in gaps and improving accuracy.  Instead of generating full feature maps, TiM uses compact tokens to represent these missing aspects.</li>
<li><strong>Outperforms on PANGAEA Benchmark:</strong> TerraMind demonstrates superior performance compared to other existing models on the PANGAEA benchmark, a standard evaluation for Earth observation models.</li>
</ul>
<h2 id="how-thinking-in-modalities-tim-works">How Thinking in Modalities (TiM) Works</h2>
<p>During pre-training, TerraMind learns the correlations between different modalities, such as Sentinel-1 and Sentinel-2 imagery, and other data like LULC and NDVI. This allows the model to predict and understand relationships between them.  The TiM process involves:</p>
<ol>
<li><strong>Imagination:</strong> The model pauses during fine-tuning or inference and “imagines” a helpful, but absent, layer of data.</li>
<li><strong>Token Appending:</strong> It appends these imagined representations as tokens to its input sequence.</li>
<li><strong>Fine-tuning/Inference:</strong> The fine-tuned encoder continues processing the input, incorporating the imagined tokens. This approach avoids the computationally expensive process of full image synthesis.</li>
</ol>
<h3 id="performance-improvements-with-tim">Performance Improvements with TiM</h3>
<ul>
<li><strong>Flood Segmentation (Sen1Floods11 dataset):</strong> Adding a synthetic LULC layer using TiM increased the mean Intersection over Union (mIoU) by approximately 2 percentage points (pp).</li>
<li><strong>South Africa Crop-Type Data:</strong> Fine-tuning with generated NDVI/LULC maps raised the mIoU from 41.9% to 42.7%.</li>
<li><strong>Runtime:</strong> TiM increases runtime by approximately 2x due to multiple forward passes and processing tokens twice, but it avoids the need for multiple modalities as raw inputs.</li>
<li><strong>Modality Suitability:</strong> TiM performs best with modalities containing limited information and complementary information.  For example, the benefits of TiM for optical Sentinel-2 data are often limited (&#x3C;2pp), while Sentinel-1 SAR inputs can gain up to 5pp by generating land-cover or NDVI tokens.</li>
</ul>
<h2 id="practical-implementation-with-terratorch">Practical Implementation with TerraTorch</h2>
<p>TerraMind backbones (both standard and TiM-enabled) are accessible through TerraTorch, a fine-tuning toolkit for Earth observation foundation models.</p>
<ul>
<li><strong>Configuration:</strong> To enable TiM, modify the configuration YAML file.  The change involves adding a statement to the <code>backbone_tim_modalities</code> field.</li>
<li><strong>Training Time:</strong> Training with TiM takes approximately twice as long as standard fine-tuning but remains more efficient than detokenizing full-resolution images or using larger models.</li>
<li><strong>Multi-Step TiM:</strong>  The <code>backbone_tim_modalities</code> field allows specifying multiple targets for multi-step TiM.</li>
<li><strong>TerraMind.tiny:</strong>  Experiments with TerraMind.tiny showed that it can outperform the standard .base and .large versions in some use cases, despite the added computational cost of TiM.</li>
</ul>
<h2 id="applications-beyond-earth-observation">Applications Beyond Earth Observation</h2>
<p>While initially designed for Earth observation, the TiM methodology is applicable to any multimodal vision model where one modality is missing, expensive, or noisy. Potential applications include:</p>
<ul>
<li><strong>Nighttime Tracking:</strong> Generating infrared image tokens from RGB-text inputs to improve tracking in low-light conditions.</li>
<li><strong>Robotics and Augmented Reality:</strong> Generating depth or 3D skeleton tokens from 2D inputs to enhance navigation and spatial understanding.</li>
<li><strong>Remote Sensing:</strong> Topography-aware landslide mapping, water mask-guided ship detection, and chained estimations (e.g., NDVI → biomass → yield).</li>
</ul>
<h2 id="further-resources">Further Resources</h2>
<ul>
<li><strong>Hugging Face:</strong> <a href="https://huggingface.co/">https://huggingface.co/</a></li>
<li><strong>arXiv:</strong> <a href="https://arxiv.org/">https://arxiv.org/</a></li>
<li><strong>TerraTorch Tutorial:</strong> <a href="https://huggingface.co/docs/terratorch/latest/tutorial/fine-tuning">https://huggingface.co/docs/terratorch/latest/tutorial/fine-tuning</a></li>
<li><strong>Tiled Inference Notebook:</strong> <a href="https://github.com/huggingface/terratorch/blob/main/notebooks/tiled_inference.ipynb">https://github.com/huggingface/terratorch/blob/main/notebooks/tiled_inference.ipynb</a></li>
</ul> </div>  <section class="related-posts" data-astro-cid-dpgbfi7r> <h2 data-astro-cid-dpgbfi7r>Related Posts</h2> <div class="related-posts-grid" data-astro-cid-dpgbfi7r> <article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-10-22-google-research-open-sources-the-coral-npu-platform-to-help-build-ai-into-wearables-and-edge-devices/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>Google Open-Sources Coral NPU Platform for AI on Edge Devices</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>Google Open-Sources the Coral NPU Platform This article details Google Research&#39;s open-sourcing of the Coral Neural…</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-10-22T00:00:00.000Z" data-astro-cid-dpgbfi7r> Oct 22, 2025 </time> <span data-astro-cid-dpgbfi7r>•</span> <span data-astro-cid-dpgbfi7r>2 min read</span> </div> </a> </article><article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-10-27-huggingfacehub-v10-five-years-of-building-the-foundation-of-open-machine-learning/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>huggingface_hub v1.0: A Comprehensive Overview of the Next Generation of Open Machine Learning</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>huggingface_hub v1.0: A Comprehensive Overview of the Next Generation of Open Machine Learning **Main Heading:**…</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-10-23T00:00:00.000Z" data-astro-cid-dpgbfi7r> Oct 23, 2025 </time> <span data-astro-cid-dpgbfi7r>•</span> <span data-astro-cid-dpgbfi7r>4 min read</span> </div> </a> </article><article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-10-27-presentation-vector-sync-patterns-keeping-ai-features-fresh-when-your-data-changes/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>Vector Sync Patterns: Keeping AI Features Fresh When Your Data Changes</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>This presentation delves into the critical challenges of maintaining the freshness and consistency of vector embeddings…</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-10-27T00:00:00.000Z" data-astro-cid-dpgbfi7r> Oct 27, 2025 </time> <span data-astro-cid-dpgbfi7r>•</span> <span data-astro-cid-dpgbfi7r>3 min read</span> </div> </a> </article> </div> </section>  </article> </div> <div class="back-link" data-astro-cid-rkg3zjxi><a href="/ai-news/" data-astro-cid-rkg3zjxi>← Back to AI News</a></div>  </main> <!-- Site Footer --> <footer class="site-footer container"> <p>
© 2025 AREZKI El Mehdi •
<a href="https://github.com/earezki">GitHub</a> •
<a href="/rss.xml">RSS</a> •
<a href="/sitemap-index.xml">Sitemap</a> </p> </footer> <!-- Theme Toggle Script -->  <!-- Article Read/Unread Tracking --> <script>
      /**
       * Tracks which articles have been read using localStorage
       * Updates post card styling on list pages
       */
      (function() {
        const STORAGE_KEY = 'readArticles';
        
        /**
         * Gets list of read article URLs from localStorage
         */
        function getReadArticles() {
          try {
            const data = localStorage.getItem(STORAGE_KEY);
            return data ? JSON.parse(data) : [];
          } catch (e) {
            console.error('Failed to get read articles:', e);
            return [];
          }
        }
        
        /**
         * Marks an article URL as read
         */
        function markArticleAsRead(url) {
          try {
            const readArticles = getReadArticles();
            if (!readArticles.includes(url)) {
              readArticles.push(url);
              localStorage.setItem(STORAGE_KEY, JSON.stringify(readArticles));
            }
          } catch (e) {
            console.error('Failed to mark article as read:', e);
          }
        }
        
        /**
         * Checks if an article has been read
         */
        function isArticleRead(url) {
          const readArticles = getReadArticles();
          return readArticles.includes(url);
        }
        
        /**
         * Updates post card styling on list pages based on read status
         */
        function updatePostCards() {
          const postCards = document.querySelectorAll('.post-card[data-article-url]');
          
          postCards.forEach(function(card) {
            const url = card.getAttribute('data-article-url');
            if (!url) return;
            
            if (isArticleRead(url)) {
              card.classList.add('read');
              card.classList.remove('unread');
            } else {
              card.classList.add('unread');
              card.classList.remove('read');
            }
          });
        }
        
        /**
         * Marks current article as read (on article detail pages)
         */
        function markCurrentArticleAsRead() {
          const isArticlePage = document.querySelector('.post-body');
          if (isArticlePage) {
            const currentPath = window.location.pathname;
            markArticleAsRead(currentPath);
          }
        }
        
        /**
         * Initialize tracking system
         */
        function init() {
          updatePostCards();
          markCurrentArticleAsRead();
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', init);
        
        // Handle back/forward navigation (bfcache)
        window.addEventListener('pageshow', function(event) {
          if (event.persisted) {
            init();
          }
        });
      })();
    </script> <!-- Code Copy Functionality --> <script>
      /**
       * Adds copy buttons to all code blocks
       */
      (function() {
        /**
         * Creates a copy button element
         */
        function createCopyButton() {
          const button = document.createElement('button');
          button.className = 'copy-code-button';
          button.setAttribute('aria-label', 'Copy code to clipboard');
          button.innerHTML = `
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
              <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
            </svg>
            <span>Copy</span>
          `;
          return button;
        }
        
        /**
         * Creates a success checkmark icon
         */
        function createCheckIcon() {
          return `
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <polyline points="20 6 9 17 4 12"></polyline>
            </svg>
            <span>Copied!</span>
          `;
        }
        
        /**
         * Copies text to clipboard
         */
        async function copyToClipboard(text) {
          try {
            await navigator.clipboard.writeText(text);
            return true;
          } catch (err) {
            // Fallback for older browsers
            const textArea = document.createElement('textarea');
            textArea.value = text;
            textArea.style.position = 'fixed';
            textArea.style.left = '-999999px';
            document.body.appendChild(textArea);
            textArea.select();
            try {
              document.execCommand('copy');
              document.body.removeChild(textArea);
              return true;
            } catch (e) {
              document.body.removeChild(textArea);
              return false;
            }
          }
        }
        
        /**
         * Handles copy button click
         */
        async function handleCopyClick(button, codeBlock) {
          const code = codeBlock.textContent || '';
          const success = await copyToClipboard(code);
          
          if (success) {
            const originalHTML = button.innerHTML;
            button.classList.add('copied');
            button.innerHTML = createCheckIcon();
            
            setTimeout(function() {
              button.classList.remove('copied');
              button.innerHTML = originalHTML;
            }, 2000);
          }
        }
        
        /**
         * Adds copy buttons to all code blocks
         */
        function addCopyButtons() {
          const codeBlocks = document.querySelectorAll('.post-body pre');
          
          codeBlocks.forEach(function(pre) {
            // Skip if button already exists
            if (pre.querySelector('.copy-code-button')) {
              return;
            }
            
            const button = createCopyButton();
            const codeBlock = pre.querySelector('code');
            
            if (codeBlock) {
              button.addEventListener('click', function() {
                handleCopyClick(button, codeBlock);
              });
              
              pre.appendChild(button);
            }
          });
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', addCopyButtons);
      })();
    </script> </body> </html> 