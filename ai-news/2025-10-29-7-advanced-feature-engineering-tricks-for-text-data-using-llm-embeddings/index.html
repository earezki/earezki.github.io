<!DOCTYPE html><html lang="en" data-theme="dark"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings ‚Ä¢ Dev|Journal</title><meta name="description" content="7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings This article outlines seven advanced strategies to enrich text data for machine‚Ä¶"><meta name="keywords" content="AI News, Technology"><meta name="author" content="El Mehdi Arezki"><meta property="og:type" content="website"><meta property="og:url" content="https://earezki.com/ai-news/2025-10-29-7-advanced-feature-engineering-tricks-for-text-data-using-llm-embeddings/"><meta property="og:title" content="7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings ‚Ä¢ Dev|Journal"><meta property="og:site_name" content="Dev|Journal"><meta property="og:description" content="7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings This article outlines seven advanced strategies to enrich text data for machine‚Ä¶"><meta property="og:image" content="https://earezki.com/assets/og-image-default.jpg"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://earezki.com/ai-news/2025-10-29-7-advanced-feature-engineering-tricks-for-text-data-using-llm-embeddings/"><meta name="twitter:title" content="7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings ‚Ä¢ Dev|Journal"><meta name="twitter:description" content="7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings This article outlines seven advanced strategies to enrich text data for machine‚Ä¶"><meta name="twitter:image" content="https://earezki.com/assets/og-image-default.jpg"><meta name="twitter:creator" content="@earezki"><link rel="canonical" href="https://earezki.com/ai-news/2025-10-29-7-advanced-feature-engineering-tricks-for-text-data-using-llm-embeddings/"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="alternate" type="application/rss+xml" title="RSS" href="/rss.xml"><link rel="dns-prefetch" href="https://cloud.umami.is"><script defer src="https://cloud.umami.is/script.js" data-website-id="4a26531d-1053-4f79-97a6-06a1366aff91"></script><script>
      (function() {
        const theme = localStorage.getItem('theme');
        if (theme) document.documentElement.setAttribute('data-theme', theme);
      })();
    </script><script>
!function(){const o=window.location.pathname;if("/"===o)return;if(/\.\w+$/.test(o))return;const n=o.toLowerCase(),i=n!==o,t=!o.endsWith("/");if(i||t){const o=n+(t?"/":""),i=window.location.origin+o+window.location.search+window.location.hash;window.location.replace(i)}}();
</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings","description":"7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings This article outlines seven advanced strategies to enrich text data for machine‚Ä¶","image":"https://earezki.com/assets/og-image-default.jpg","datePublished":"2025-10-29T00:00:00.000Z","dateModified":"2025-10-29T00:00:00.000Z","author":{"@type":"Person","name":"El Mehdi Arezki","url":"https://earezki.com/about","jobTitle":"Lead Software Engineer","sameAs":["https://github.com/earezki","https://www.linkedin.com/in/mehdi-arezki"]},"publisher":{"@type":"Organization","name":"Dev|Journal","url":"https://earezki.com","logo":{"@type":"ImageObject","url":"https://earezki.com/assets/logo.png"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://earezki.com/ai-news/2025-10-29-7-advanced-feature-engineering-tricks-for-text-data-using-llm-embeddings/"}}</script><link rel="stylesheet" href="/_astro/_slug_.B_eXuGWa.css">
<link rel="stylesheet" href="/_astro/_slug_.CFj9bTVJ.css">
<link rel="stylesheet" href="/_astro/_slug_.ICs7ea4X.css"></head> <body> <div id="readingProgress" role="progressbar" aria-label="Reading progress" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100" style="position:fixed;left:0;top:0;height:3px;background:linear-gradient(90deg,#2563eb,#9333ea);width:0;z-index:999;transition:width .15s ease;"></div> <script type="module">function c(){const t=document.getElementById("readingProgress");if(!t)return;const o=()=>{const e=document.documentElement,r=e.scrollTop||document.body.scrollTop,s=e.scrollHeight-e.clientHeight,n=s>0?r/s*100:0;t.style.width=`${n}%`,t.setAttribute("aria-valuenow",n.toFixed(0))};document.addEventListener("scroll",o,{passive:!0}),o()}c();</script> <header class="site-header container"> <div class="logo-wrap"> <a class="logo" href="/" aria-label="Dev|Journal Home">
Dev|Journal
</a> </div> <!-- Search Box in Header --> <div class="header-search" data-search-api-url="https://api.earezki.com/blog/api/q" data-search-timeout="2000"> <div class="search-box" id="search-box"> <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="search-icon" aria-hidden="true"> <circle cx="11" cy="11" r="8"></circle> <path d="m21 21-4.35-4.35"></path> </svg> <input type="text" id="search-input" placeholder="Search ..." class="search-input" autocomplete="off" aria-label="Search articles" minlength="3"> <button id="clear-search" class="clear-button" style="display: none;" aria-label="Clear search"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"> <line x1="18" y1="6" x2="6" y2="18"></line> <line x1="6" y1="6" x2="18" y2="18"></line> </svg> </button> </div> <div id="search-results" class="search-results" role="status" aria-live="polite"></div> </div> <script type="module" src="/_astro/SearchBox.astro_astro_type_script_index_0_lang.BNnBPVSN.js"></script> <nav class="main-nav" aria-label="Main navigation"> <a href="/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="m3 9 9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path> <polyline points="9 22 9 12 15 12 15 22"></polyline> </svg>
Home
</a> <a href="/ai-news/" class="ai-news-link ai-gradient-nav"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="M12 2a2 2 0 0 1 2 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 0 1 7 7h-9.5a.5.5 0 0 0-.5.5.5.5 0 0 1-1 0 .5.5 0 0 0-.5-.5H1a7 7 0 0 1 7-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 0 1 2-2z"></path> <path d="M7 15v4a2 2 0 0 0 2 2h6a2 2 0 0 0 2-2v-4"></path> </svg>
AI News
</a> <a href="/ai-financial-news/" class="ai-financial-link ai-gradient-nav"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <line x1="12" y1="1" x2="12" y2="23"></line> <path d="M17 5H9.5a3.5 3.5 0 0 0 0 7h5a3.5 3.5 0 0 1 0 7H6"></path> </svg>
AI Financial
</a> <a href="/about/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <circle cx="12" cy="12" r="10"></circle> <path d="M12 16v-4"></path> <path d="M12 8h.01"></path> </svg>
About
</a> <button id="themeToggle" class="theme-toggle" aria-label="Toggle dark mode"> <span class="theme-icon" aria-hidden="true">‚òæ</span> </button> </nav> </header> <!-- Main Content --> <main class="container content-area">  <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7>  <a href="/" data-astro-cid-ilhxcym7>Home</a> <span class="separator" aria-hidden="true" data-astro-cid-ilhxcym7>/</span>  </li><li data-astro-cid-ilhxcym7>  <a href="/ai-news/" data-astro-cid-ilhxcym7>Ai News</a> <span class="separator" aria-hidden="true" data-astro-cid-ilhxcym7>/</span>  </li><li data-astro-cid-ilhxcym7> <span class="current" aria-current="page" data-astro-cid-ilhxcym7>7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings</span> </li>  </ol> </nav>  <div class="post-layout" data-astro-cid-rkg3zjxi> <aside class="sidebar-left" data-astro-cid-rkg3zjxi> <nav class="toc" aria-label="Table of Contents" data-astro-cid-xvrfupwn> <div class="toc-title" data-astro-cid-xvrfupwn>On this page</div> <ul data-astro-cid-xvrfupwn> <li class="d-2" data-astro-cid-xvrfupwn> <a href="#7-advanced-feature-engineering-tricks-for-text-data-using-llm-embeddings" data-astro-cid-xvrfupwn> 7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-combining-tf-idf-and-embedding-features" data-astro-cid-xvrfupwn> 1. **Combining TF-IDF and Embedding Features** </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-topic-aware-embedding-clusters" data-astro-cid-xvrfupwn> 2. **Topic-Aware Embedding Clusters** </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#3-semantic-anchor-similarity-features" data-astro-cid-xvrfupwn> 3. **Semantic Anchor Similarity Features** </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#4-meta-feature-stacking-via-auxiliary-classifier" data-astro-cid-xvrfupwn> 4. **Meta-Feature Stacking via Auxiliary Classifier** </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#5-embedding-compression-and-nonlinear-expansion" data-astro-cid-xvrfupwn> 5. **Embedding Compression and Nonlinear Expansion** </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#6-relational-learning-with-pairwise-contrastive-features" data-astro-cid-xvrfupwn> 6. **Relational Learning with Pairwise Contrastive Features** </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#7-cross-modal-fusion" data-astro-cid-xvrfupwn> 7. **Cross-Modal Fusion** </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#working-example-code-related" data-astro-cid-xvrfupwn> Working Example (Code-Related) </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#recommendations-code-related" data-astro-cid-xvrfupwn> Recommendations (Code-Related) </a> </li> </ul> </nav>  </aside> <article class="post" data-astro-cid-rkg3zjxi> <header class="post-header" data-astro-cid-rkg3zjxi> <h1 data-astro-cid-rkg3zjxi>7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings</h1> <div class="meta" data-astro-cid-rkg3zjxi> <time datetime="2025-10-29T00:00:00.000Z" data-astro-cid-rkg3zjxi>Wed Oct 29 2025</time> <span data-astro-cid-rkg3zjxi>‚Ä¢ 4 min read</span> </div> <div class="tag-row" data-astro-cid-rkg3zjxi><a class="post-tag ai-news-tag ai-gradient-tag" href="/tags/ai-news/" data-astro-cid-rkg3zjxi>AI News</a><a class="post-tag" href="/tags/language-models/" data-astro-cid-rkg3zjxi>Language Models</a><a class="post-tag" href="/tags/machine-learning/" data-astro-cid-rkg3zjxi>Machine Learning</a></div> </header>    <div class="post-body prose" data-astro-cid-rkg3zjxi> <h2 id="7-advanced-feature-engineering-tricks-for-text-data-using-llm-embeddings">7 Advanced Feature Engineering Tricks for Text Data Using LLM Embeddings</h2>
<p>This article outlines seven advanced strategies to enrich text data for machine learning models by leveraging <strong>LLM-generated embeddings</strong> (e.g., from Sentence Transformers). These techniques combine semantic and lexical features to improve performance in tasks like classification, clustering, and similarity detection.</p>
<hr>
<h3 id="1-combining-tf-idf-and-embedding-features">1. <strong>Combining TF-IDF and Embedding Features</strong></h3>
<ul>
<li><strong>Purpose</strong>: Merge lexical (TF-IDF) and semantic (LLM) features to capture both word frequency and contextual meaning.</li>
<li><strong>Implementation</strong>:
<ul>
<li>Use <code>TfidfVectorizer</code> to extract TF-IDF features.</li>
<li>Generate embeddings using a pre-trained model (e.g., <code>all-MiniLM-L6-v2</code>).</li>
<li>Concatenate and scale features before training a classifier (e.g., logistic regression).</li>
</ul>
</li>
<li><strong>Impact</strong>: Boosts model accuracy by combining lexical and semantic signals.</li>
<li><strong>Example Code</strong>:
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_20newsgroups
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer
<span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> SentenceTransformer
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
model <span class="token operator">=</span> SentenceTransformer<span class="token punctuation">(</span><span class="token string">"all-MiniLM-L6-v2"</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> fetch_20newsgroups<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> categories<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'sci.space'</span><span class="token punctuation">,</span> <span class="token string">'rec.autos'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
texts<span class="token punctuation">,</span> y <span class="token operator">=</span> data<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">500</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>target<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">500</span><span class="token punctuation">]</span>
tfidf <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>max_features<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>texts<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>
emb <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>texts<span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">[</span>tfidf<span class="token punctuation">,</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>emb<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
clf <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>max_iter<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy:"</span><span class="token punctuation">,</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
</li>
<li><strong>Best Practices</strong>: Use <code>StandardScaler</code> on embeddings to normalize their range.</li>
</ul>
<hr>
<h3 id="2-topic-aware-embedding-clusters">2. <strong>Topic-Aware Embedding Clusters</strong></h3>
<ul>
<li><strong>Purpose</strong>: Create compact topic meta-features by clustering embeddings.</li>
<li><strong>Implementation</strong>:
<ul>
<li>Use K-Means to cluster embeddings into topics.</li>
<li>Encode cluster labels with <code>OneHotEncoder</code> and concatenate with original embeddings.</li>
</ul>
</li>
<li><strong>Impact</strong>: Adds interpretability by grouping similar texts into topics.</li>
<li><strong>Example Code</strong>:
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OneHotEncoder
texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Tokyo Tower is a popular landmark."</span><span class="token punctuation">,</span> <span class="token string">"Sushi is a traditional Japanese dish."</span><span class="token punctuation">]</span>
emb <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>texts<span class="token punctuation">)</span>
topics <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_predict<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
topic_ohe <span class="token operator">=</span> OneHotEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>topics<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">[</span>emb<span class="token punctuation">,</span> topic_ohe<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
</li>
<li><strong>Pitfalls</strong>: Poorly chosen <code>n_clusters</code> may lead to overfitting or loss of semantic meaning.</li>
</ul>
<hr>
<h3 id="3-semantic-anchor-similarity-features">3. <strong>Semantic Anchor Similarity Features</strong></h3>
<ul>
<li><strong>Purpose</strong>: Measure similarity between text and predefined ‚Äúanchor‚Äù sentences.</li>
<li><strong>Implementation</strong>:
<ul>
<li>Encode anchor sentences and compute cosine similarity with text embeddings.</li>
</ul>
</li>
<li><strong>Impact</strong>: Helps models learn relationships between text and key concepts.</li>
<li><strong>Example Code</strong>:
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>pairwise <span class="token keyword">import</span> cosine_similarity
anchors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"space mission"</span><span class="token punctuation">,</span> <span class="token string">"car performance"</span><span class="token punctuation">]</span>
anchor_emb <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>anchors<span class="token punctuation">)</span>
texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"The rocket launch was successful."</span><span class="token punctuation">,</span> <span class="token string">"The car handled well on the track."</span><span class="token punctuation">]</span>
emb <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>texts<span class="token punctuation">)</span>
sim_features <span class="token operator">=</span> cosine_similarity<span class="token punctuation">(</span>emb<span class="token punctuation">,</span> anchor_emb<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>sim_features<span class="token punctuation">)</span>
</code></pre>
</li>
<li><strong>Use Case</strong>: Useful for classification tasks with predefined categories (e.g., sentiment labels).</li>
</ul>
<hr>
<h3 id="4-meta-feature-stacking-via-auxiliary-classifier">4. <strong>Meta-Feature Stacking via Auxiliary Classifier</strong></h3>
<ul>
<li><strong>Purpose</strong>: Use an auxiliary classifier to generate meta-features from embeddings.</li>
<li><strong>Implementation</strong>:
<ul>
<li>Train a classifier (e.g., logistic regression) on embeddings.</li>
<li>Use its predicted probabilities as a meta-feature.</li>
</ul>
</li>
<li><strong>Impact</strong>: Augments embeddings with discriminative signals for downstream tasks.</li>
<li><strong>Example Code</strong>:
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>emb<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
meta_clf <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>max_iter<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
meta_feature <span class="token operator">=</span> meta_clf<span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>emb<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
X_aug <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">[</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>emb<span class="token punctuation">)</span><span class="token punctuation">,</span> meta_feature<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Augmented shape:"</span><span class="token punctuation">,</span> X_aug<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
</li>
<li><strong>Recommendations</strong>: Ensure the auxiliary model is trained on a separate dataset to avoid overfitting.</li>
</ul>
<hr>
<h3 id="5-embedding-compression-and-nonlinear-expansion">5. <strong>Embedding Compression and Nonlinear Expansion</strong></h3>
<ul>
<li><strong>Purpose</strong>: Reduce dimensionality (via PCA) and expand features nonlinearly (via polynomial features).</li>
<li><strong>Implementation</strong>:
<ul>
<li>Apply PCA to compress embeddings.</li>
<li>Use <code>PolynomialFeatures</code> to create interactions between compressed dimensions.</li>
</ul>
</li>
<li><strong>Impact</strong>: Captures nonlinear patterns while maintaining efficiency.</li>
<li><strong>Example Code</strong>:
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> PolynomialFeatures
pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
poly <span class="token operator">=</span> PolynomialFeatures<span class="token punctuation">(</span>degree<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>pca<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"After polynomial expansion:"</span><span class="token punctuation">,</span> poly<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
</li>
<li><strong>Pitfalls</strong>: High-degree polynomials may overfit; use cross-validation to tune parameters.</li>
</ul>
<hr>
<h3 id="6-relational-learning-with-pairwise-contrastive-features">6. <strong>Relational Learning with Pairwise Contrastive Features</strong></h3>
<ul>
<li><strong>Purpose</strong>: Highlight similarity/dissimilarity between text pairs.</li>
<li><strong>Implementation</strong>:
<ul>
<li>Compute absolute difference and element-wise product of embeddings for paired texts.</li>
</ul>
</li>
<li><strong>Impact</strong>: Effective for tasks requiring pairwise comparisons (e.g., semantic similarity).</li>
<li><strong>Example Code</strong>:
<pre class="language-python" data-language="python"><code is:raw="" class="language-python">pairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"The car is fast."</span><span class="token punctuation">,</span> <span class="token string">"The vehicle moves quickly."</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
emb1 <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token punctuation">[</span>p<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> pairs<span class="token punctuation">]</span><span class="token punctuation">)</span>
emb2 <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token punctuation">[</span>p<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> pairs<span class="token punctuation">]</span><span class="token punctuation">)</span>
X_pairs <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>emb1 <span class="token operator">-</span> emb2<span class="token punctuation">)</span><span class="token punctuation">,</span> emb1 <span class="token operator">*</span> emb2<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Pairwise feature shape:"</span><span class="token punctuation">,</span> X_pairs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
</li>
<li><strong>Best Practices</strong>: Use large datasets to avoid bias in pairwise comparisons.</li>
</ul>
<hr>
<h3 id="7-cross-modal-fusion">7. <strong>Cross-Modal Fusion</strong></h3>
<ul>
<li><strong>Purpose</strong>: Combine LLM embeddings with handcrafted linguistic features (e.g., punctuation ratio).</li>
<li><strong>Implementation</strong>:
<ul>
<li>Calculate features like word count and punctuation ratio.</li>
<li>Concatenate with embeddings.</li>
</ul>
</li>
<li><strong>Impact</strong>: Adds domain-specific signals to semantic representations.</li>
<li><strong>Example Code</strong>:
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">import</span> re
punct_ratio <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">r"[^\w\s]"</span><span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> texts<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">[</span>emb<span class="token punctuation">,</span> lengths<span class="token punctuation">,</span> punct_ratio<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Final feature matrix shape:"</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
</li>
<li><strong>Use Case</strong>: Useful for tasks requiring both semantic and syntactic analysis (e.g., sentiment analysis).</li>
</ul>
<hr>
<h2 id="working-example-code-related">Working Example (Code-Related)</h2>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> SentenceTransformer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> PolynomialFeatures
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># Load model and text data</span>
model <span class="token operator">=</span> SentenceTransformer<span class="token punctuation">(</span><span class="token string">"all-MiniLM-L6-v2"</span><span class="token punctuation">)</span>
texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Mars mission 2024!"</span><span class="token punctuation">,</span> <span class="token string">"New electric car model launched."</span><span class="token punctuation">]</span>
emb <span class="token operator">=</span> model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>texts<span class="token punctuation">)</span>

<span class="token comment"># Compress embeddings and expand nonlinearly</span>
pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
poly <span class="token operator">=</span> PolynomialFeatures<span class="token punctuation">(</span>degree<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> include_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>pca<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"After polynomial expansion:"</span><span class="token punctuation">,</span> poly<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre>
<hr>
<h2 id="recommendations-code-related">Recommendations (Code-Related)</h2>
<ul>
<li><strong>When to Use</strong>: Apply these techniques when raw embeddings alone are insufficient for downstream tasks (e.g., low accuracy in classification).</li>
<li><strong>Best Practices</strong>:
<ul>
<li>Always scale embeddings before combining with other features.</li>
<li>Use cross-validation to tune hyperparameters (e.g., PCA components, polynomial degree).</li>
<li>Avoid overfitting by using separate validation sets for auxiliary models.</li>
</ul>
</li>
<li><strong>Pitfalls</strong>:
<ul>
<li>Over-reliance on handcrafted features may limit model generalization.</li>
<li>High-dimensional feature spaces can increase computational costs.</li>
</ul>
</li>
</ul> </div>  <section class="related-posts" data-astro-cid-dpgbfi7r> <h2 data-astro-cid-dpgbfi7r>Related Posts</h2> <div class="related-posts-grid" data-astro-cid-dpgbfi7r> <article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-12-17-openai-at-qcon-ai-nyc-fine-tuning-the-enterprise/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>OpenAI‚Äôs Agent RFT: Reinforcement Fine-Tuning for Tool-Using Agents</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>OpenAI‚Äôs Agent RFT: Reinforcement Fine-Tuning for Tool-Using Agents At QCon AI NYC 2025, Will Hang from OpenAI‚Ä¶</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-12-17T00:00:00.000Z" data-astro-cid-dpgbfi7r> Dec 17, 2025 </time> <span data-astro-cid-dpgbfi7r>‚Ä¢</span> <span data-astro-cid-dpgbfi7r>1 min read</span> </div> </a> </article><article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-12-16-lyft-rearchitects-ml-platform-with-hybrid-aws-sagemaker-kubernetes-approach/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>Lyft Rearchitects ML Platform with Hybrid AWS SageMaker-Kubernetes Approach</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>Lyft Rearchitects ML Platform with Hybrid AWS SageMaker-Kubernetes Approach Lyft rearchitected its machine learning‚Ä¶</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-12-16T00:00:00.000Z" data-astro-cid-dpgbfi7r> Dec 16, 2025 </time> <span data-astro-cid-dpgbfi7r>‚Ä¢</span> <span data-astro-cid-dpgbfi7r>1 min read</span> </div> </a> </article><article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-12-16-metas-optimization-platform-ax-10-streamlines-llm-and-system-optimization/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>Meta‚Äôs Optimization Platform Ax 1.0 Streamlines LLM and System Optimization</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>Meta‚Äôs Optimization Platform Ax 1.0 Streamlines LLM and System Optimization Ax 1.0, released by Meta, is an adaptive‚Ä¶</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-12-16T00:00:00.000Z" data-astro-cid-dpgbfi7r> Dec 16, 2025 </time> <span data-astro-cid-dpgbfi7r>‚Ä¢</span> <span data-astro-cid-dpgbfi7r>1 min read</span> </div> </a> </article><article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-12-15-alphaevolve-enters-google-cloud-as-an-agentic-system-for-algorithm-optimization/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>AlphaEvolve Enters Google Cloud as an Agentic System for Algorithm Optimization</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>AlphaEvolve Enters Google Cloud as an Agentic System for Algorithm Optimization Google Cloud announced the private‚Ä¶</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-12-15T00:00:00.000Z" data-astro-cid-dpgbfi7r> Dec 15, 2025 </time> <span data-astro-cid-dpgbfi7r>‚Ä¢</span> <span data-astro-cid-dpgbfi7r>1 min read</span> </div> </a> </article> </div> </section>  </article> </div> <div class="back-link" data-astro-cid-rkg3zjxi><a href="/ai-news/" data-astro-cid-rkg3zjxi>‚Üê Back to AI News</a></div>  </main> <!-- Site Footer --> <footer class="site-footer container"> <p>
¬© 2025 AREZKI El Mehdi ‚Ä¢
<a href="https://github.com/earezki">GitHub</a> ‚Ä¢
<a href="/rss.xml">RSS</a> ‚Ä¢
<a href="/tags/">Tags</a> ‚Ä¢
<a href="/sitemap-index.xml">Sitemap</a> ‚Ä¢
<button id="footer-subscribe-btn" class="footer-subscribe-btn" aria-label="Subscribe to newsletter">
üì¨ Subscribe
</button> </p> </footer> <!-- Footer Subscribe Button Handler --> <script type="module">const e=document.getElementById("themeToggle"),o=n=>{if(!e)return;const t=e.querySelector(".theme-icon");t&&(t.textContent=n==="dark"?"‚òÄ":"‚òæ")};if(e){const n=document.documentElement.getAttribute("data-theme")||"dark";o(n),e.addEventListener("click",()=>{const t=document.documentElement,c=t.getAttribute("data-theme")==="dark"?"light":"dark";t.setAttribute("data-theme",c),localStorage.setItem("theme",c),o(c)})}</script> <!-- Theme Toggle --> <script type="module">document.addEventListener("DOMContentLoaded",()=>{const e=document.getElementById("footer-subscribe-btn");e&&e.addEventListener("click",n=>{n.preventDefault();const t=document.getElementById("subscription-popup");t&&(t.setAttribute("data-state","visible"),document.body.style.overflow="hidden")})});</script> <!-- Article read/unread tracking --> <script>
      (function() {
        const KEY = 'readArticles';
        
        function getRead() {
          try {
            const d = localStorage.getItem(KEY);
            return d ? JSON.parse(d) : [];
          } catch (e) {
            return [];
          }
        }
        
        function markRead(url) {
          try {
            const read = getRead();
            if (!read.includes(url)) {
              read.push(url);
              localStorage.setItem(KEY, JSON.stringify(read));
            }
          } catch (e) {}
        }
        
        function updateCards() {
          const read = new Set(getRead());
          const cards = document.querySelectorAll('.post-card[data-article-url]');
          cards.forEach(function(card) {
            const url = card.getAttribute('data-article-url');
            if (!url) return;
            const isRead = read.has(url);
            card.classList.toggle('read', isRead);
            card.classList.toggle('unread', !isRead);
          });
        }
        
        function markCurrent() {
          if (document.querySelector('.post-body')) {
            markRead(window.location.pathname);
          }
        }
        
        function init() {
          updateCards();
          markCurrent();
        }
        
        function clearRead(url) {
          try {
            const read = new Set(getRead());
            if (read.has(url)) {
              read.delete(url);
              localStorage.setItem(KEY, JSON.stringify(Array.from(read)));
              updateCards();
            }
          } catch (e) {}
        }
        
        window.clearReadArticle = clearRead;
        document.addEventListener('DOMContentLoaded', init);
        window.addEventListener('pageshow', function(e) {
          if (e.persisted) init();
        });
      })();
    </script> <!-- Clear read button handler --> <script>
      (function() {
        document.addEventListener('click', function(e) {
          var tgt = e.target, btn = null;
          while (tgt && tgt !== document) {
            if (tgt.classList && tgt.classList.contains('clear-read-btn')) {
              btn = tgt;
              break;
            }
            tgt = tgt.parentNode;
          }
          if (!btn) return;
          e.preventDefault();
          e.stopPropagation();
          var url = btn.getAttribute('data-article-url');
          if (url && window.clearReadArticle) window.clearReadArticle(url);
        });
      })();
    </script> <!-- External links open in new tab --> <script>
      (function() {
        function makeExternal() {
          const domain = window.location.hostname;
          const links = document.querySelectorAll('a[href]');
          links.forEach(function(link) {
            const href = link.getAttribute('href');
            if (!href || link.hasAttribute('target')) return;
            const isExt = (href.startsWith('http://') || href.startsWith('https://')) && !href.includes(domain);
            if (isExt) {
              link.setAttribute('target', '_blank');
              link.setAttribute('rel', 'noopener noreferrer');
            }
          });
        }
        document.addEventListener('DOMContentLoaded', makeExternal);
        if (window.MutationObserver) {
          const obs = new MutationObserver(function(muts) {
            muts.forEach(function(mut) {
              if (mut.addedNodes.length) makeExternal();
            });
          });
          obs.observe(document.body, { childList: true, subtree: true });
        }
      })();
    </script> <!-- Code copy buttons --> <script>
      (function() {
        function createBtn() {
          const btn = document.createElement('button');
          btn.className = 'copy-code-button';
          btn.setAttribute('aria-label', 'Copy code to clipboard');
          btn.innerHTML = `
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
              <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
            </svg>
            <span>Copy</span>
          `;
          return btn;
        }
        
        function checkIcon() {
          return `
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <polyline points="20 6 9 17 4 12"></polyline>
            </svg>
            <span>Copied!</span>
          `;
        }
        
        async function copyText(txt) {
          try {
            await navigator.clipboard.writeText(txt);
            return true;
          } catch (err) {
            const ta = document.createElement('textarea');
            ta.value = txt;
            ta.style.position = 'fixed';
            ta.style.left = '-999999px';
            document.body.appendChild(ta);
            ta.select();
            try {
              document.execCommand('copy');
              document.body.removeChild(ta);
              return true;
            } catch (e) {
              document.body.removeChild(ta);
              return false;
            }
          }
        }
        
        async function handleCopy(btn, code) {
          const txt = code.textContent || '';
          const ok = await copyText(txt);
          if (ok) {
            const orig = btn.innerHTML;
            btn.classList.add('copied');
            btn.innerHTML = checkIcon();
            setTimeout(function() {
              btn.classList.remove('copied');
              btn.innerHTML = orig;
            }, 2000);
          }
        }
        
        function addBtns() {
          const blocks = document.querySelectorAll('.post-body pre');
          blocks.forEach(function(pre) {
            if (pre.querySelector('.copy-code-button')) return;
            const btn = createBtn();
            const code = pre.querySelector('code');
            if (code) {
              btn.addEventListener('click', function() {
                handleCopy(btn, code);
              });
              pre.appendChild(btn);
            }
          });
        }
        
        document.addEventListener('DOMContentLoaded', addBtns);
      })();
    </script> <!-- Newsletter Subscription Popup --> <div id="subscription-popup" class="subscription-popup" data-state="hidden" data-auto-trigger="true" data-astro-cid-we5gmdnp> <div class="popup-overlay" id="popup-overlay" data-astro-cid-we5gmdnp></div> <div class="popup-container" data-astro-cid-we5gmdnp> <div class="popup-content" data-astro-cid-we5gmdnp> <div class="popup-icon" data-astro-cid-we5gmdnp> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-we5gmdnp> <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z" data-astro-cid-we5gmdnp></path> <polyline points="22,6 12,13 2,6" data-astro-cid-we5gmdnp></polyline> </svg> </div> <h2 class="popup-title" data-astro-cid-we5gmdnp>Stay Updated with Dev|Journal</h2> <p class="popup-description" id="popup-description" data-astro-cid-we5gmdnp>
Join our community of developers and engineers. Get insights on:
</p> <ul class="popup-features" data-astro-cid-we5gmdnp> <li data-astro-cid-we5gmdnp> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" data-astro-cid-we5gmdnp> <polyline points="20 6 9 17 4 12" data-astro-cid-we5gmdnp></polyline> </svg>
Software Architecture & Design Patterns
</li> <li data-astro-cid-we5gmdnp> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" data-astro-cid-we5gmdnp> <polyline points="20 6 9 17 4 12" data-astro-cid-we5gmdnp></polyline> </svg>
Backend Development Best Practices
</li> <li data-astro-cid-we5gmdnp> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" data-astro-cid-we5gmdnp> <polyline points="20 6 9 17 4 12" data-astro-cid-we5gmdnp></polyline> </svg>
AI & Tech Industry Analysis
</li> </ul> <form id="subscription-form" class="popup-form" data-astro-cid-we5gmdnp> <div class="form-group" data-astro-cid-we5gmdnp> <input type="text" id="subscriber-name" name="name" placeholder="Your name" required autocomplete="name" data-astro-cid-we5gmdnp> </div> <div class="form-group" data-astro-cid-we5gmdnp> <input type="email" id="subscriber-email" name="email" placeholder="your.email@example.com" required autocomplete="email" data-astro-cid-we5gmdnp> </div> <div id="form-message" class="form-message" data-astro-cid-we5gmdnp></div> <div class="popup-actions" data-astro-cid-we5gmdnp> <button type="submit" class="btn btn-primary" id="subscribe-btn" data-astro-cid-we5gmdnp> <span class="btn-text" data-astro-cid-we5gmdnp>Subscribe</span> <span class="btn-loader" data-astro-cid-we5gmdnp> <svg class="spinner" viewBox="0 0 24 24" data-astro-cid-we5gmdnp> <circle cx="12" cy="12" r="10" stroke="currentColor" stroke-width="2" fill="none" data-astro-cid-we5gmdnp></circle> </svg> </span> </button> <button type="button" class="btn btn-secondary" id="not-now-btn" data-astro-cid-we5gmdnp>Not Now</button> <button type="button" class="btn btn-text" id="cancel-btn" data-astro-cid-we5gmdnp>Don't Show Again</button> </div> </form> </div> </div> </div>  <script>
  // Configuration
  const CONFIG = {
    graceDelay: 5000, // 5 seconds delay before showing popup
    notNowDelay: 24 * 60 * 60 * 1000, // 1 day in milliseconds
    apiUrl: 'https://api.earezki.com/blog/api',
  };

  const STORAGE_KEYS = {
    subscribed: 'newsletter_subscribed',
    cancelled: 'newsletter_cancelled',
    notNowUntil: 'newsletter_not_now_until',
  };

  // State management
  let popupTimeout = null;

  function showPopup() {
    const popup = document.getElementById('subscription-popup');
    if (popup) {
      popup.setAttribute('data-state', 'visible');
      document.body.style.overflow = 'hidden';
    }
  }

  function hidePopup() {
    const popup = document.getElementById('subscription-popup');
    if (popup) {
      popup.setAttribute('data-state', 'hidden');
      document.body.style.overflow = '';
    }
  }

  function shouldShowPopup() {
    // Check if user has already subscribed
    if (localStorage.getItem(STORAGE_KEYS.subscribed) === 'true') {
      return false;
    }

    // Check if user clicked "Don't show again"
    if (localStorage.getItem(STORAGE_KEYS.cancelled) === 'true') {
      return false;
    }

    // Check if user clicked "Not now" and delay hasn't passed
    const notNowUntil = localStorage.getItem(STORAGE_KEYS.notNowUntil);
    if (notNowUntil) {
      const notNowTime = parseInt(notNowUntil, 10);
      if (Date.now() < notNowTime) {
        return false;
      }
    }

    return true;
  }

  async function getSubscriberStats() {
    try {
      const response = await fetch(`${CONFIG.apiUrl}/subscribers/stats`, {
        method: 'GET',
        headers: {
          'Accept': 'application/json',
        },
      });
      
      if (!response.ok) {
        return null;
      }
      
      const data = await response.json();
      return data.subscriber_count || null;
    } catch (error) {
      console.error('Failed to fetch subscriber stats:', error);
      return null;
    }
  }

  async function schedulePopup() {
    if (!shouldShowPopup()) {
      return;
    }

    // Fetch subscriber stats before scheduling popup
    const subscriberCount = await getSubscriberStats();
    if (subscriberCount === null) {
      console.log('Failed to fetch subscriber stats, not showing subscription popup');
      return;
    }

    // Update popup with subscriber count
    updatePopupWithStats(subscriberCount);

    // Show popup after grace period
    popupTimeout = window.setTimeout(() => {
      showPopup();
    }, CONFIG.graceDelay);
  }

  function updatePopupWithStats(count) {
    const descriptionEl = document.querySelector('.popup-description');
    if (descriptionEl) {
      const formattedCount = new Intl.NumberFormat('en-US').format(count);
      descriptionEl.innerHTML = `Join a community of <strong>${formattedCount}+</strong> developers and engineers who are growing together. Get insights on:`;
    }
  }

  async function handleSubscribe(event) {
    event.preventDefault();
    
    const form = event.target;
    const nameInput = form.querySelector('#subscriber-name');
    const emailInput = form.querySelector('#subscriber-email');
    const submitBtn = form.querySelector('#subscribe-btn');
    const messageEl = document.getElementById('form-message');

    const name = nameInput.value.trim();
    const email = emailInput.value.trim();

    if (!name || !email) {
      if (messageEl) {
        messageEl.textContent = 'Please fill in all fields.';
        messageEl.className = 'form-message error';
      }
      return;
    }

    // Show loading state
    submitBtn.classList.add('loading');
    submitBtn.disabled = true;
    if (messageEl) {
      messageEl.textContent = '';
      messageEl.className = 'form-message';
    }

    try {
      const response = await fetch(`${CONFIG.apiUrl}/subscribe`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ name, email }),
      });

      const data = await response.json();

      if (data.success) {
        localStorage.setItem(STORAGE_KEYS.subscribed, 'true');
        
        if (messageEl) {
          messageEl.textContent = 'üéâ Successfully subscribed! Thank you for joining us.';
          messageEl.className = 'form-message success';
        }

        // Hide popup after 2 seconds
        setTimeout(() => {
          hidePopup();
        }, 2000);
      } else {
        if (messageEl) {
          messageEl.textContent = data.error || 'Subscription failed. Please try again.';
          messageEl.className = 'form-message error';
        }
      }
    } catch (error) {
      console.error('Subscription error:', error);
      if (messageEl) {
        messageEl.textContent = 'Network error. Please check your connection and try again.';
        messageEl.className = 'form-message error';
      }
    } finally {
      submitBtn.classList.remove('loading');
      submitBtn.disabled = false;
    }
  }

  function handleNotNow() {
    const notNowUntil = Date.now() + CONFIG.notNowDelay;
    localStorage.setItem(STORAGE_KEYS.notNowUntil, notNowUntil.toString());
    hidePopup();
  }

  function handleCancel() {
    localStorage.setItem(STORAGE_KEYS.cancelled, 'true');
    hidePopup();
  }

  // Initialize popup
  document.addEventListener('DOMContentLoaded', () => {
    const popup = document.getElementById('subscription-popup');
    const autoTrigger = popup?.getAttribute('data-auto-trigger') === 'true';
    
    // Schedule popup to show after grace period only if autoTrigger is enabled
    if (autoTrigger) {
      schedulePopup();
    }

    // Event listeners
    const form = document.getElementById('subscription-form');
    const overlay = document.getElementById('popup-overlay');
    const notNowBtn = document.getElementById('not-now-btn');
    const cancelBtn = document.getElementById('cancel-btn');

    if (form) {
      form.addEventListener('submit', handleSubscribe);
    }

    if (overlay) {
      overlay.addEventListener('click', handleNotNow);
    }

    if (notNowBtn) {
      notNowBtn.addEventListener('click', handleNotNow);
    }

    if (cancelBtn) {
      cancelBtn.addEventListener('click', handleCancel);
    }

    // Clean up on page unload
    window.addEventListener('beforeunload', () => {
      if (popupTimeout) {
        clearTimeout(popupTimeout);
      }
    });
  });
</script> </body></html> 