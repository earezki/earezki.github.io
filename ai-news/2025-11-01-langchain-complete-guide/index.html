<!DOCTYPE html><html lang="en" data-theme="dark"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><!-- Primary Meta Tags --><title>LangChain Complete Guide: Building Production-Ready LLM Applications • Dev|Journal</title><meta name="description" content="LangChain Complete Guide: Building Production-Ready LLM Applications LangChain is the leading framework for building applications with Large Language Models.…"><meta name="keywords" content="software architecture, backend development, microservices, Java, Python, Spring Boot, technical blog"><meta name="author" content="El Mehdi Arezki"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://earezki.com/ai-news/2025-11-01-langchain-complete-guide/"><meta property="og:title" content="LangChain Complete Guide: Building Production-Ready LLM Applications • Dev|Journal"><meta property="og:site_name" content="Dev|Journal"><meta property="og:description" content="LangChain Complete Guide: Building Production-Ready LLM Applications LangChain is the leading framework for building applications with Large Language Models.…"><meta property="og:image" content="https://earezki.com/assets/og-image-default.jpg"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://earezki.com/ai-news/2025-11-01-langchain-complete-guide/"><meta name="twitter:title" content="LangChain Complete Guide: Building Production-Ready LLM Applications • Dev|Journal"><meta name="twitter:description" content="LangChain Complete Guide: Building Production-Ready LLM Applications LangChain is the leading framework for building applications with Large Language Models.…"><meta name="twitter:image" content="https://earezki.com/assets/og-image-default.jpg"><meta name="twitter:creator" content="@earezki"><!-- Canonical and Indexing --><link rel="canonical" href="https://earezki.com/ai-news/2025-11-01-langchain-complete-guide/"><!-- Favicons --><link rel="icon" type="image/svg+xml" href="/favicon.svg"><link rel="icon" type="image/x-icon" href="/favicon.ico"><!-- RSS Feed --><link rel="alternate" type="application/rss+xml" title="RSS" href="/rss.xml"><!-- Analytics: Google Analytics (Legacy UA) --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-161447264-1"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);} 
      gtag('js', new Date()); 
      gtag('config', 'UA-161447264-1');
    </script><!-- Analytics: Umami --><script defer src="https://cloud.umami.is/script.js" data-website-id="4a26531d-1053-4f79-97a6-06a1366aff91"></script><!-- Theme Persistence (runs before page render to prevent flash) --><script>
      (function() {
        const theme = localStorage.getItem('theme');
        if (theme) { 
          document.documentElement.setAttribute('data-theme', theme); 
        }
      })();
    </script><!-- Structured Data (JSON-LD) --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"LangChain Complete Guide: Building Production-Ready LLM Applications","datePublished":"2025-11-01T16:00:00.000Z","dateModified":"2025-11-01T16:00:00.000Z","author":{"@type":"Person","name":"AREZKI El Mehdi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://earezki.com/ai-news/2025-11-01-langchain-complete-guide/"},"description":"LangChain Complete Guide: Building Production-Ready LLM Applications LangChain is the leading framework for building applications with Large Language Models.…"}</script><link rel="stylesheet" href="/_astro/_slug_.DxE91F05.css">
<style>.toc[data-astro-cid-xvrfupwn]{position:sticky;top:90px;max-height:calc(100vh - 120px);overflow:auto;padding:1rem 1rem 1.2rem;background:var(--color-bg-alt);border:1px solid var(--color-border);border-radius:var(--radius-md);font-size:.8rem;line-height:1.3}.toc-title[data-astro-cid-xvrfupwn]{font-weight:600;font-size:.75rem;text-transform:uppercase;letter-spacing:.08em;margin-bottom:.6rem;color:var(--color-text-alt)}.toc[data-astro-cid-xvrfupwn] ul[data-astro-cid-xvrfupwn]{list-style:none;margin:0;padding:0;display:flex;flex-direction:column;gap:.35rem}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]{text-decoration:none;color:var(--color-text-alt);transition:color var(--transition)}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]:hover{color:var(--color-accent)}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn][class*=d-3]{margin-left:.75rem}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn][class*=d-4]{margin-left:1.4rem}@media (max-width: 1080px){.toc[data-astro-cid-xvrfupwn]{display:none}}.breadcrumbs[data-astro-cid-ilhxcym7]{margin:0 0 1.5rem;font-size:.85rem}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{list-style:none;padding:0;margin:0;display:flex;flex-wrap:wrap;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{display:flex;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--color-text-alt);text-decoration:none;transition:color var(--transition)}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{color:var(--color-accent);text-decoration:underline}.breadcrumbs[data-astro-cid-ilhxcym7] .separator[data-astro-cid-ilhxcym7]{color:var(--color-text-alt);opacity:.5;user-select:none}.breadcrumbs[data-astro-cid-ilhxcym7] .current[data-astro-cid-ilhxcym7]{color:var(--color-text);font-weight:500}.related-posts[data-astro-cid-dpgbfi7r]{margin:3rem 0;padding-top:2rem;border-top:2px solid var(--color-border)}.related-posts[data-astro-cid-dpgbfi7r] h2[data-astro-cid-dpgbfi7r]{font-size:1.5rem;margin:0 0 1.5rem;color:var(--color-text)}.related-posts-grid[data-astro-cid-dpgbfi7r]{display:grid;grid-template-columns:repeat(auto-fit,minmax(280px,1fr));gap:1.5rem}.related-post-card[data-astro-cid-dpgbfi7r]{background:var(--color-bg-alt);border:1px solid var(--color-border);border-radius:var(--radius-md);padding:1.25rem;transition:all var(--transition)}.related-post-card[data-astro-cid-dpgbfi7r]:hover{border-color:var(--color-accent);transform:translateY(-2px);box-shadow:var(--shadow-md)}.related-post-link[data-astro-cid-dpgbfi7r]{text-decoration:none;color:inherit;display:block}.related-post-card[data-astro-cid-dpgbfi7r] h3[data-astro-cid-dpgbfi7r]{margin:0 0 .75rem;font-size:1.1rem;font-weight:600;color:var(--color-text);line-height:1.3}.related-post-link[data-astro-cid-dpgbfi7r]:hover h3[data-astro-cid-dpgbfi7r]{color:var(--color-accent)}.related-excerpt[data-astro-cid-dpgbfi7r]{font-size:.85rem;color:var(--color-text-alt);line-height:1.5;margin:0 0 .75rem}.related-meta[data-astro-cid-dpgbfi7r]{font-size:.75rem;color:var(--color-text-alt);display:flex;gap:.5rem;align-items:center}@media (max-width: 680px){.related-posts-grid[data-astro-cid-dpgbfi7r]{grid-template-columns:1fr}}
.post-layout[data-astro-cid-rkg3zjxi]{display:grid;grid-template-columns:260px 1fr;gap:2.5rem}.sidebar-left[data-astro-cid-rkg3zjxi]{position:relative}@media (max-width: 1080px){.post-layout[data-astro-cid-rkg3zjxi]{grid-template-columns:1fr}}.ai-disclaimer-article[data-astro-cid-rkg3zjxi]{display:flex;gap:.75rem;padding:.9rem 1.1rem;margin:0 auto 2rem;max-width:780px;background:linear-gradient(135deg,#667eea1a,#764ba21a,#f093fb1a);border:2px solid transparent;border-radius:var(--radius-md);position:relative;background-clip:padding-box;font-size:.85rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi]:before{content:"";position:absolute;inset:-2px;border-radius:var(--radius-md);padding:2px;background:var(--ai-gradient-border);background-size:200% 200%;animation:gradient-rotate 3s linear infinite;-webkit-mask:linear-gradient(#fff 0 0) content-box,linear-gradient(#fff 0 0);-webkit-mask-composite:xor;mask:linear-gradient(#fff 0 0) content-box,linear-gradient(#fff 0 0);mask-composite:exclude;pointer-events:none}html[data-theme=dark] .ai-disclaimer-article[data-astro-cid-rkg3zjxi]{background:linear-gradient(135deg,#667eea26,#764ba226,#f093fb26)}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] svg[data-astro-cid-rkg3zjxi]{margin-top:.15rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] strong[data-astro-cid-rkg3zjxi]{color:var(--color-text);display:block;margin-bottom:.15rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] div[data-astro-cid-rkg3zjxi]{line-height:1.5;color:var(--color-text-alt)}
</style><script type="module" src="/_astro/hoisted.2U5tn40l.js"></script></head> <body> <div id="readingProgress" role="progressbar" aria-label="Reading progress" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100" style="position:fixed;left:0;top:0;height:3px;background:linear-gradient(90deg,#2563eb,#9333ea);width:0;z-index:999;transition:width .15s ease;"></div>  <!-- Site Header --> <header class="site-header container"> <div class="logo-wrap"> <a class="logo" href="/" aria-label="Dev|Journal Home">
Dev|Journal
</a> </div> <nav class="main-nav" aria-label="Main navigation"> <a href="/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="m3 9 9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path> <polyline points="9 22 9 12 15 12 15 22"></polyline> </svg>
Home
</a> <a href="/ai-news/" class="ai-news-link"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="M12 2a2 2 0 0 1 2 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 0 1 7 7h-9.5a.5.5 0 0 0-.5.5.5.5 0 0 1-1 0 .5.5 0 0 0-.5-.5H1a7 7 0 0 1 7-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 0 1 2-2z"></path> <path d="M7 15v4a2 2 0 0 0 2 2h6a2 2 0 0 0 2-2v-4"></path> </svg>
AI News
</a> <a href="/tags/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="M12 2H2v10l9.29 9.29c.94.94 2.48.94 3.42 0l6.58-6.58c.94-.94.94-2.48 0-3.42L12 2z"></path> <circle cx="7" cy="7" r="1.5"></circle> </svg>
Tags
</a> <a href="/about/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <circle cx="12" cy="12" r="10"></circle> <path d="M12 16v-4"></path> <path d="M12 8h.01"></path> </svg>
About
</a> <button id="themeToggle" class="theme-toggle" aria-label="Toggle dark mode"> <span class="theme-icon" aria-hidden="true">☾</span> <span class="theme-text">dark</span> </button> </nav> </header> <!-- Main Content --> <main class="container content-area">  <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7>  <a href="/" data-astro-cid-ilhxcym7>Home</a> <span class="separator" aria-hidden="true" data-astro-cid-ilhxcym7>/</span>  </li><li data-astro-cid-ilhxcym7>  <a href="/ai-news/" data-astro-cid-ilhxcym7>Ai News</a> <span class="separator" aria-hidden="true" data-astro-cid-ilhxcym7>/</span>  </li><li data-astro-cid-ilhxcym7> <span class="current" aria-current="page" data-astro-cid-ilhxcym7>LangChain Complete Guide: Building Production-Ready LLM Applications</span> </li> </ol> </nav>  <div class="ai-disclaimer-article" data-astro-cid-rkg3zjxi> <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="flex-shrink: 0;" data-astro-cid-rkg3zjxi> <circle cx="12" cy="12" r="10" data-astro-cid-rkg3zjxi></circle> <line x1="12" y1="8" x2="12" y2="12" data-astro-cid-rkg3zjxi></line> <line x1="12" y1="16" x2="12.01" y2="16" data-astro-cid-rkg3zjxi></line> </svg> <div data-astro-cid-rkg3zjxi> <strong data-astro-cid-rkg3zjxi>AI-Generated Content:</strong> This article was created with AI assistance. Please verify important information and check original references.
</div> </div> <div class="post-layout" data-astro-cid-rkg3zjxi> <aside class="sidebar-left" data-astro-cid-rkg3zjxi> <nav class="toc" aria-label="Table of Contents" data-astro-cid-xvrfupwn> <div class="toc-title" data-astro-cid-xvrfupwn>On this page</div> <ul data-astro-cid-xvrfupwn> <li class="d-2" data-astro-cid-xvrfupwn> <a href="#table-of-contents" data-astro-cid-xvrfupwn> Table of Contents </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#langchain-fundamentals-fundamentals" data-astro-cid-xvrfupwn> LangChain Fundamentals {#fundamentals} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-installation-and-setup" data-astro-cid-xvrfupwn> 1. Installation and Setup </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-basic-llm-usage" data-astro-cid-xvrfupwn> 2. Basic LLM Usage </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#3-core-components-overview" data-astro-cid-xvrfupwn> 3. Core Components Overview </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#llm-integration-llm-integration" data-astro-cid-xvrfupwn> LLM Integration {#llm-integration} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-multiple-llm-providers" data-astro-cid-xvrfupwn> 1. Multiple LLM Providers </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-token-management-and-cost-optimization" data-astro-cid-xvrfupwn> 2. Token Management and Cost Optimization </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#prompt-engineering-prompts" data-astro-cid-xvrfupwn> Prompt Engineering {#prompts} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-prompt-templates" data-astro-cid-xvrfupwn> 1. Prompt Templates </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-advanced-prompt-techniques" data-astro-cid-xvrfupwn> 2. Advanced Prompt Techniques </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#chains-and-lcel-chains" data-astro-cid-xvrfupwn> Chains and LCEL {#chains} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-langchain-expression-language-lcel" data-astro-cid-xvrfupwn> 1. LangChain Expression Language (LCEL) </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-complex-chains" data-astro-cid-xvrfupwn> 2. Complex Chains </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#agents-and-tools-agents" data-astro-cid-xvrfupwn> Agents and Tools {#agents} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-creating-custom-tools" data-astro-cid-xvrfupwn> 1. Creating Custom Tools </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-agent-types-and-usage" data-astro-cid-xvrfupwn> 2. Agent Types and Usage </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#3-custom-agent-implementation" data-astro-cid-xvrfupwn> 3. Custom Agent Implementation </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#memory-systems-memory" data-astro-cid-xvrfupwn> Memory Systems {#memory} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-memory-types" data-astro-cid-xvrfupwn> 1. Memory Types </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-memory-in-chains" data-astro-cid-xvrfupwn> 2. Memory in Chains </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#rag-retrieval-augmented-generation-rag" data-astro-cid-xvrfupwn> RAG (Retrieval Augmented Generation) {#rag} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-basic-rag-implementation" data-astro-cid-xvrfupwn> 1. Basic RAG Implementation </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-advanced-rag-techniques" data-astro-cid-xvrfupwn> 2. Advanced RAG Techniques </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#vector-stores-vector-stores" data-astro-cid-xvrfupwn> Vector Stores {#vector-stores} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-vector-store-options" data-astro-cid-xvrfupwn> 1. Vector Store Options </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-vector-store-operations" data-astro-cid-xvrfupwn> 2. Vector Store Operations </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#evaluation-and-monitoring-evaluation" data-astro-cid-xvrfupwn> Evaluation and Monitoring {#evaluation} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-evaluating-rag-systems" data-astro-cid-xvrfupwn> 1. Evaluating RAG Systems </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-monitoring-and-logging" data-astro-cid-xvrfupwn> 2. Monitoring and Logging </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#production-deployment-deployment" data-astro-cid-xvrfupwn> Production Deployment {#deployment} </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-fastapi-integration" data-astro-cid-xvrfupwn> 1. FastAPI Integration </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-caching-and-optimization" data-astro-cid-xvrfupwn> 2. Caching and Optimization </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#3-production-best-practices" data-astro-cid-xvrfupwn> 3. Production Best Practices </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#conclusion" data-astro-cid-xvrfupwn> Conclusion </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#resources" data-astro-cid-xvrfupwn> Resources </a> </li> </ul> </nav>  </aside> <article class="post" data-astro-cid-rkg3zjxi> <header class="post-header" data-astro-cid-rkg3zjxi> <h1 data-astro-cid-rkg3zjxi>LangChain Complete Guide: Building Production-Ready LLM Applications</h1> <div class="meta" data-astro-cid-rkg3zjxi> <time datetime="2025-11-01T16:00:00.000Z" data-astro-cid-rkg3zjxi>Sat Nov 01 2025</time> <span data-astro-cid-rkg3zjxi>• 15 min read</span> </div> <div class="tag-row" data-astro-cid-rkg3zjxi><a class="tag " href="/tags/python/" data-astro-cid-rkg3zjxi>Python</a><a class="tag " href="/tags/ai/" data-astro-cid-rkg3zjxi>AI</a><a class="tag " href="/tags/langchain/" data-astro-cid-rkg3zjxi>LangChain</a><a class="tag " href="/tags/llm/" data-astro-cid-rkg3zjxi>LLM</a><a class="tag " href="/tags/machine-learning/" data-astro-cid-rkg3zjxi>Machine Learning</a></div> </header> <div class="post-body prose" data-astro-cid-rkg3zjxi> <h1 id="langchain-complete-guide-building-production-ready-llm-applications">LangChain Complete Guide: Building Production-Ready LLM Applications</h1>
<p>LangChain is the leading framework for building applications with Large Language Models. This comprehensive guide covers everything from basics to production deployment, with real-world examples and best practices.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#fundamentals">LangChain Fundamentals</a></li>
<li><a href="#llm-integration">LLM Integration</a></li>
<li><a href="#prompts">Prompt Engineering</a></li>
<li><a href="#chains">Chains and LCEL</a></li>
<li><a href="#agents">Agents and Tools</a></li>
<li><a href="#memory">Memory Systems</a></li>
<li><a href="#rag">RAG (Retrieval Augmented Generation)</a></li>
<li><a href="#vector-stores">Vector Stores</a></li>
<li><a href="#evaluation">Evaluation and Monitoring</a></li>
<li><a href="#deployment">Production Deployment</a></li>
</ol>
<h2 id="langchain-fundamentals-fundamentals">LangChain Fundamentals {#fundamentals}</h2>
<h3 id="1-installation-and-setup">1. Installation and Setup</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token comment"># Install LangChain and dependencies</span>
pip install langchain langchain<span class="token operator">-</span>openai langchain<span class="token operator">-</span>community
pip install chromadb  <span class="token comment"># Vector store</span>
pip install faiss<span class="token operator">-</span>cpu  <span class="token comment"># Alternative vector store</span>
pip install sentence<span class="token operator">-</span>transformers  <span class="token comment"># Embeddings</span>

<span class="token comment"># Basic imports</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token punctuation">,</span> OpenAIEmbeddings
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> HumanMessage<span class="token punctuation">,</span> SystemMessage
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> StrOutputParser

<span class="token keyword">import</span> os
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"your-api-key"</span>
</code></pre>
<h3 id="2-basic-llm-usage">2. Basic LLM Usage</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token comment"># Initialize LLM</span>
llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">"gpt-4"</span><span class="token punctuation">,</span>
    temperature<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">500</span>
<span class="token punctuation">)</span>

<span class="token comment"># Simple invocation</span>
response <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"What is LangChain?"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>

<span class="token comment"># With message history</span>
messages <span class="token operator">=</span> <span class="token punctuation">[</span>
    SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"You are a helpful AI assistant."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"What is Python?"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
response <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>

<span class="token comment"># Streaming responses</span>
<span class="token keyword">for</span> chunk <span class="token keyword">in</span> llm<span class="token punctuation">.</span>stream<span class="token punctuation">(</span><span class="token string">"Write a poem about coding"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>chunk<span class="token punctuation">.</span>content<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">,</span> flush<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Async usage</span>
<span class="token keyword">import</span> asyncio

<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">async_generate</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    response <span class="token operator">=</span> <span class="token keyword">await</span> llm<span class="token punctuation">.</span>ainvoke<span class="token punctuation">(</span><span class="token string">"Tell me a joke"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> response<span class="token punctuation">.</span>content

result <span class="token operator">=</span> asyncio<span class="token punctuation">.</span>run<span class="token punctuation">(</span>async_generate<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="3-core-components-overview">3. Core Components Overview</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables <span class="token keyword">import</span> RunnablePassthrough
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> JsonOutputParser

<span class="token comment"># Prompt Template</span>
prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    template<span class="token operator">=</span><span class="token string">"Tell me a {adjective} joke about {topic}"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"adjective"</span><span class="token punctuation">,</span> <span class="token string">"topic"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token comment"># Output Parser</span>
parser <span class="token operator">=</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Chain components together using LCEL</span>
chain <span class="token operator">=</span> prompt <span class="token operator">|</span> llm <span class="token operator">|</span> parser

<span class="token comment"># Invoke chain</span>
result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"adjective"</span><span class="token punctuation">:</span> <span class="token string">"funny"</span><span class="token punctuation">,</span>
    <span class="token string">"topic"</span><span class="token punctuation">:</span> <span class="token string">"programming"</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>

<span class="token comment"># Batch processing</span>
results <span class="token operator">=</span> chain<span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">{</span><span class="token string">"adjective"</span><span class="token punctuation">:</span> <span class="token string">"funny"</span><span class="token punctuation">,</span> <span class="token string">"topic"</span><span class="token punctuation">:</span> <span class="token string">"Python"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span><span class="token string">"adjective"</span><span class="token punctuation">:</span> <span class="token string">"silly"</span><span class="token punctuation">,</span> <span class="token string">"topic"</span><span class="token punctuation">:</span> <span class="token string">"JavaScript"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="llm-integration-llm-integration">LLM Integration {#llm-integration}</h2>
<h3 id="1-multiple-llm-providers">1. Multiple LLM Providers</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token comment"># OpenAI</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI
openai_llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4"</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># Anthropic Claude</span>
<span class="token keyword">from</span> langchain_anthropic <span class="token keyword">import</span> ChatAnthropic
claude_llm <span class="token operator">=</span> ChatAnthropic<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"claude-3-opus-20240229"</span><span class="token punctuation">)</span>

<span class="token comment"># Google PaLM</span>
<span class="token keyword">from</span> langchain_google_genai <span class="token keyword">import</span> ChatGoogleGenerativeAI
palm_llm <span class="token operator">=</span> ChatGoogleGenerativeAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gemini-pro"</span><span class="token punctuation">)</span>

<span class="token comment"># Local models with Ollama</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> Ollama
local_llm <span class="token operator">=</span> Ollama<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"llama2"</span><span class="token punctuation">)</span>

<span class="token comment"># HuggingFace models</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> HuggingFaceHub
hf_llm <span class="token operator">=</span> HuggingFaceHub<span class="token punctuation">(</span>
    repo_id<span class="token operator">=</span><span class="token string">"google/flan-t5-xl"</span><span class="token punctuation">,</span>
    model_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"temperature"</span><span class="token punctuation">:</span> <span class="token number">0.5</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token comment"># LLM abstraction for switching providers</span>
<span class="token keyword">class</span> <span class="token class-name">LLMFactory</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">create_llm</span><span class="token punctuation">(</span>provider<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        providers <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">"openai"</span><span class="token punctuation">:</span> ChatOpenAI<span class="token punctuation">,</span>
            <span class="token string">"anthropic"</span><span class="token punctuation">:</span> ChatAnthropic<span class="token punctuation">,</span>
            <span class="token string">"google"</span><span class="token punctuation">:</span> ChatGoogleGenerativeAI<span class="token punctuation">,</span>
            <span class="token string">"ollama"</span><span class="token punctuation">:</span> Ollama<span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        
        llm_class <span class="token operator">=</span> providers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>provider<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> llm_class<span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Unknown provider: </span><span class="token interpolation"><span class="token punctuation">{</span>provider<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> llm_class<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>

<span class="token comment"># Usage</span>
llm <span class="token operator">=</span> LLMFactory<span class="token punctuation">.</span>create_llm<span class="token punctuation">(</span>
    <span class="token string">"openai"</span><span class="token punctuation">,</span>
    model<span class="token operator">=</span><span class="token string">"gpt-4"</span><span class="token punctuation">,</span>
    temperature<span class="token operator">=</span><span class="token number">0</span>
<span class="token punctuation">)</span>
</code></pre>
<h3 id="2-token-management-and-cost-optimization">2. Token Management and Cost Optimization</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> get_openai_callback
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI

llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>

<span class="token comment"># Track token usage and cost</span>
<span class="token keyword">with</span> get_openai_callback<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cb<span class="token punctuation">:</span>
    result <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"Write a long story about AI"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Total Tokens: </span><span class="token interpolation"><span class="token punctuation">{</span>cb<span class="token punctuation">.</span>total_tokens<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Prompt Tokens: </span><span class="token interpolation"><span class="token punctuation">{</span>cb<span class="token punctuation">.</span>prompt_tokens<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Completion Tokens: </span><span class="token interpolation"><span class="token punctuation">{</span>cb<span class="token punctuation">.</span>completion_tokens<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Total Cost (USD): $</span><span class="token interpolation"><span class="token punctuation">{</span>cb<span class="token punctuation">.</span>total_cost<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># Token counting</span>
<span class="token keyword">from</span> tiktoken <span class="token keyword">import</span> encoding_for_model

<span class="token keyword">def</span> <span class="token function">count_tokens</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> model<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"gpt-4"</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">int</span><span class="token punctuation">:</span>
    encoding <span class="token operator">=</span> encoding_for_model<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>encoding<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>

text <span class="token operator">=</span> <span class="token string">"Hello, how are you?"</span>
tokens <span class="token operator">=</span> count_tokens<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Tokens: </span><span class="token interpolation"><span class="token punctuation">{</span>tokens<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># Cost estimation before API call</span>
<span class="token keyword">def</span> <span class="token function">estimate_cost</span><span class="token punctuation">(</span>prompt<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> max_tokens<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">500</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">float</span><span class="token punctuation">:</span>
    input_tokens <span class="token operator">=</span> count_tokens<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
    total_tokens <span class="token operator">=</span> input_tokens <span class="token operator">+</span> max_tokens
    
    <span class="token comment"># GPT-4 pricing (example)</span>
    cost_per_1k <span class="token operator">=</span> <span class="token number">0.03</span>  <span class="token comment"># Input</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>total_tokens <span class="token operator">/</span> <span class="token number">1000</span><span class="token punctuation">)</span> <span class="token operator">*</span> cost_per_1k

estimated <span class="token operator">=</span> estimate_cost<span class="token punctuation">(</span><span class="token string">"Write a detailed analysis..."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Estimated cost: $</span><span class="token interpolation"><span class="token punctuation">{</span>estimated<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre>
<h2 id="prompt-engineering-prompts">Prompt Engineering {#prompts}</h2>
<h3 id="1-prompt-templates">1. Prompt Templates</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> <span class="token punctuation">(</span>
    ChatPromptTemplate<span class="token punctuation">,</span>
    PromptTemplate<span class="token punctuation">,</span>
    FewShotPromptTemplate<span class="token punctuation">,</span>
    MessagesPlaceholder
<span class="token punctuation">)</span>

<span class="token comment"># Simple prompt template</span>
simple_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    template<span class="token operator">=</span><span class="token string">"What is the capital of {country}?"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"country"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token comment"># Chat prompt template</span>
chat_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a {role} expert."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"{question}"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

chain <span class="token operator">=</span> chat_prompt <span class="token operator">|</span> llm <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"Python programming"</span><span class="token punctuation">,</span>
    <span class="token string">"question"</span><span class="token punctuation">:</span> <span class="token string">"What are decorators?"</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment"># Few-shot prompting</span>
examples <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"happy"</span><span class="token punctuation">,</span>
        <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"sad"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"tall"</span><span class="token punctuation">,</span>
        <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"short"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"hot"</span><span class="token punctuation">,</span>
        <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"cold"</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>

example_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    template<span class="token operator">=</span><span class="token string">"Input: {input}\nOutput: {output}"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">,</span> <span class="token string">"output"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

few_shot_prompt <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
    examples<span class="token operator">=</span>examples<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    prefix<span class="token operator">=</span><span class="token string">"Give the opposite of every word:"</span><span class="token punctuation">,</span>
    suffix<span class="token operator">=</span><span class="token string">"Input: {word}\nOutput:"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"word"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token comment"># Dynamic few-shot with example selector</span>
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>example_selectors <span class="token keyword">import</span> SemanticSimilarityExampleSelector
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma

example_selector <span class="token operator">=</span> SemanticSimilarityExampleSelector<span class="token punctuation">.</span>from_examples<span class="token punctuation">(</span>
    examples<span class="token punctuation">,</span>
    OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Chroma<span class="token punctuation">,</span>
    k<span class="token operator">=</span><span class="token number">2</span>  <span class="token comment"># Select 2 most similar examples</span>
<span class="token punctuation">)</span>

dynamic_prompt <span class="token operator">=</span> FewShotPromptTemplate<span class="token punctuation">(</span>
    example_selector<span class="token operator">=</span>example_selector<span class="token punctuation">,</span>
    example_prompt<span class="token operator">=</span>example_prompt<span class="token punctuation">,</span>
    prefix<span class="token operator">=</span><span class="token string">"Give the opposite:"</span><span class="token punctuation">,</span>
    suffix<span class="token operator">=</span><span class="token string">"Input: {word}\nOutput:"</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"word"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>
</code></pre>
<h3 id="2-advanced-prompt-techniques">2. Advanced Prompt Techniques</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token comment"># Chain of Thought prompting</span>
cot_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""
Solve this problem step by step:

Problem: {problem}

Let's approach this systematically:
1. Understand the problem
2. Break it down into steps
3. Solve each step
4. Provide the final answer

Solution:
"""</span><span class="token punctuation">)</span>

<span class="token comment"># Self-consistency prompting</span>
<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">self_consistency</span><span class="token punctuation">(</span>question<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">str</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Generate multiple responses and pick most common"""</span>
    responses <span class="token operator">=</span> <span class="token keyword">await</span> asyncio<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">[</span>
        llm<span class="token punctuation">.</span>ainvoke<span class="token punctuation">(</span>question<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment"># Find most common response (simplified)</span>
    <span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter
    answers <span class="token operator">=</span> <span class="token punctuation">[</span>r<span class="token punctuation">.</span>content <span class="token keyword">for</span> r <span class="token keyword">in</span> responses<span class="token punctuation">]</span>
    most_common <span class="token operator">=</span> Counter<span class="token punctuation">(</span>answers<span class="token punctuation">)</span><span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> most_common

<span class="token comment"># ReAct prompting (Reasoning + Acting)</span>
react_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""
Answer the following question using this format:

Thought: Think about what to do
Action: The action to take
Observation: The result of the action
... (repeat Thought/Action/Observation as needed)
Thought: Final conclusion
Answer: The final answer

Question: {question}
"""</span><span class="token punctuation">)</span>

<span class="token comment"># Prompt with output structuring</span>
structured_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""
Extract information from the text and return as JSON:

Text: {text}

Return JSON with these fields:
- name: Person's name
- age: Person's age  
- occupation: Person's occupation
- location: Person's location

JSON:
"""</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> JsonOutputParser

parser <span class="token operator">=</span> JsonOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
chain <span class="token operator">=</span> structured_prompt <span class="token operator">|</span> llm <span class="token operator">|</span> parser

result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"text"</span><span class="token punctuation">:</span> <span class="token string">"John Smith is a 35-year-old software engineer living in San Francisco."</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>  <span class="token comment"># {"name": "John Smith", "age": 35, ...}</span>
</code></pre>
<h2 id="chains-and-lcel-chains">Chains and LCEL {#chains}</h2>
<h3 id="1-langchain-expression-language-lcel">1. LangChain Expression Language (LCEL)</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables <span class="token keyword">import</span> <span class="token punctuation">(</span>
    RunnablePassthrough<span class="token punctuation">,</span>
    RunnableParallel<span class="token punctuation">,</span>
    RunnableLambda
<span class="token punctuation">)</span>

<span class="token comment"># Basic chain</span>
prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">"Tell me about {topic}"</span><span class="token punctuation">)</span>
chain <span class="token operator">=</span> prompt <span class="token operator">|</span> llm <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Chain with intermediate steps</span>
<span class="token keyword">def</span> <span class="token function">extract_keywords</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token comment"># Extract keywords from text</span>
    <span class="token keyword">return</span> text<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>

keyword_chain <span class="token operator">=</span> <span class="token punctuation">(</span>
    prompt
    <span class="token operator">|</span> llm
    <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token operator">|</span> RunnableLambda<span class="token punctuation">(</span>extract_keywords<span class="token punctuation">)</span>
<span class="token punctuation">)</span>

keywords <span class="token operator">=</span> keyword_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"topic"</span><span class="token punctuation">:</span> <span class="token string">"Python programming"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment"># Parallel execution</span>
parallel_chain <span class="token operator">=</span> RunnableParallel<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"summary"</span><span class="token punctuation">:</span> prompt <span class="token operator">|</span> llm <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">"keywords"</span><span class="token punctuation">:</span> keyword_chain<span class="token punctuation">,</span>
    <span class="token string">"length"</span><span class="token punctuation">:</span> RunnableLambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">"topic"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

results <span class="token operator">=</span> parallel_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"topic"</span><span class="token punctuation">:</span> <span class="token string">"Machine Learning"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment"># Branching chain</span>
<span class="token keyword">def</span> <span class="token function">route_question</span><span class="token punctuation">(</span>input_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
    question <span class="token operator">=</span> input_dict<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> <span class="token string">"python"</span> <span class="token keyword">in</span> question<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"python_chain"</span>
    <span class="token keyword">return</span> <span class="token string">"general_chain"</span>

python_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    <span class="token string">"As a Python expert: {question}"</span>
<span class="token punctuation">)</span>
general_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    <span class="token string">"Answer: {question}"</span>
<span class="token punctuation">)</span>

branch_chain <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"python_chain"</span><span class="token punctuation">:</span> python_prompt <span class="token operator">|</span> llm<span class="token punctuation">,</span>
    <span class="token string">"general_chain"</span><span class="token punctuation">:</span> general_prompt <span class="token operator">|</span> llm
<span class="token punctuation">}</span>

<span class="token comment"># Conditional routing</span>
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables <span class="token keyword">import</span> RunnableBranch

conditional_chain <span class="token operator">=</span> RunnableBranch<span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">"python"</span> <span class="token keyword">in</span> x<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> python_prompt <span class="token operator">|</span> llm<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string">"javascript"</span> <span class="token keyword">in</span> x<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> general_prompt <span class="token operator">|</span> llm<span class="token punctuation">)</span><span class="token punctuation">,</span>
    general_prompt <span class="token operator">|</span> llm  <span class="token comment"># default</span>
<span class="token punctuation">)</span>
</code></pre>
<h3 id="2-complex-chains">2. Complex Chains</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token comment"># Map-Reduce chain for document summarization</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>combine_documents<span class="token punctuation">.</span>stuff <span class="token keyword">import</span> create_stuff_documents_chain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> MapReduceDocumentsChain

<span class="token comment"># Map step: Summarize each document</span>
map_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    <span class="token string">"Summarize this document:\n\n{page_content}"</span>
<span class="token punctuation">)</span>
map_chain <span class="token operator">=</span> map_prompt <span class="token operator">|</span> llm <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Reduce step: Combine summaries</span>
reduce_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    <span class="token string">"Combine these summaries into a final summary:\n\n{summaries}"</span>
<span class="token punctuation">)</span>
reduce_chain <span class="token operator">=</span> reduce_prompt <span class="token operator">|</span> llm <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Sequential chain with multiple steps</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> SequentialChain

<span class="token comment"># Step 1: Generate outline</span>
outline_chain <span class="token operator">=</span> <span class="token punctuation">(</span>
    ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">"Create an outline for: {topic}"</span><span class="token punctuation">)</span>
    <span class="token operator">|</span> llm
    <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># Step 2: Write content based on outline</span>
content_chain <span class="token operator">=</span> <span class="token punctuation">(</span>
    ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
        <span class="token string">"Write content for this outline:\n{outline}"</span>
    <span class="token punctuation">)</span>
    <span class="token operator">|</span> llm
    <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># Combine steps</span>
full_chain <span class="token operator">=</span> outline_chain <span class="token operator">|</span> content_chain

<span class="token comment"># Transform chain for data processing</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> Document

<span class="token keyword">def</span> <span class="token function">load_documents</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">list</span><span class="token punctuation">[</span>Document<span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>
        Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">"Document 1 content"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">"Document 2 content"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

<span class="token comment"># Process each document</span>
process_chain <span class="token operator">=</span> <span class="token punctuation">(</span>
    RunnableLambda<span class="token punctuation">(</span>load_documents<span class="token punctuation">)</span>
    <span class="token operator">|</span> RunnableLambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> docs<span class="token punctuation">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">(</span>map_prompt <span class="token operator">|</span> llm<span class="token punctuation">)</span><span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"page_content"</span><span class="token punctuation">:</span> doc<span class="token punctuation">.</span>page_content<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> doc <span class="token keyword">in</span> docs
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre>
<h2 id="agents-and-tools-agents">Agents and Tools {#agents}</h2>
<h3 id="1-creating-custom-tools">1. Creating Custom Tools</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>tools <span class="token keyword">import</span> Tool<span class="token punctuation">,</span> StructuredTool
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>tools <span class="token keyword">import</span> tool
<span class="token keyword">from</span> pydantic <span class="token keyword">import</span> BaseModel<span class="token punctuation">,</span> Field

<span class="token comment"># Simple function tool</span>
<span class="token keyword">def</span> <span class="token function">search_api</span><span class="token punctuation">(</span>query<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">str</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Search the internet for information"""</span>
    <span class="token comment"># Implement actual search logic</span>
    <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f"Search results for: </span><span class="token interpolation"><span class="token punctuation">{</span>query<span class="token punctuation">}</span></span><span class="token string">"</span></span>

search_tool <span class="token operator">=</span> Tool<span class="token punctuation">(</span>
    name<span class="token operator">=</span><span class="token string">"Search"</span><span class="token punctuation">,</span>
    func<span class="token operator">=</span>search_api<span class="token punctuation">,</span>
    description<span class="token operator">=</span><span class="token string">"Searches the internet for information"</span>
<span class="token punctuation">)</span>

<span class="token comment"># Decorator-based tool</span>
<span class="token decorator annotation punctuation">@tool</span>
<span class="token keyword">def</span> <span class="token function">calculator</span><span class="token punctuation">(</span>expression<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">float</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Evaluates mathematical expressions"""</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>expression<span class="token punctuation">)</span>
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f"Error: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>

<span class="token comment"># Structured tool with typed inputs</span>
<span class="token keyword">class</span> <span class="token class-name">CalculatorInput</span><span class="token punctuation">(</span>BaseModel<span class="token punctuation">)</span><span class="token punctuation">:</span>
    a<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"First number"</span><span class="token punctuation">)</span>
    b<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"Second number"</span><span class="token punctuation">)</span>
    operation<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"Operation: add, subtract, multiply, divide"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">calculator_func</span><span class="token punctuation">(</span>a<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span> b<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span> operation<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">float</span><span class="token punctuation">:</span>
    operations <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">"add"</span><span class="token punctuation">:</span> a <span class="token operator">+</span> b<span class="token punctuation">,</span>
        <span class="token string">"subtract"</span><span class="token punctuation">:</span> a <span class="token operator">-</span> b<span class="token punctuation">,</span>
        <span class="token string">"multiply"</span><span class="token punctuation">:</span> a <span class="token operator">*</span> b<span class="token punctuation">,</span>
        <span class="token string">"divide"</span><span class="token punctuation">:</span> a <span class="token operator">/</span> b <span class="token keyword">if</span> b <span class="token operator">!=</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">'inf'</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">return</span> operations<span class="token punctuation">.</span>get<span class="token punctuation">(</span>operation<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

structured_calc <span class="token operator">=</span> StructuredTool<span class="token punctuation">.</span>from_function<span class="token punctuation">(</span>
    func<span class="token operator">=</span>calculator_func<span class="token punctuation">,</span>
    name<span class="token operator">=</span><span class="token string">"Calculator"</span><span class="token punctuation">,</span>
    description<span class="token operator">=</span><span class="token string">"Performs basic arithmetic"</span><span class="token punctuation">,</span>
    args_schema<span class="token operator">=</span>CalculatorInput
<span class="token punctuation">)</span>

<span class="token comment"># Tool from API</span>
<span class="token keyword">import</span> requests

<span class="token keyword">def</span> <span class="token function">weather_tool</span><span class="token punctuation">(</span>city<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">str</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Get current weather for a city"""</span>
    <span class="token comment"># Replace with actual API call</span>
    response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>
        <span class="token string-interpolation"><span class="token string">f"https://api.weather.com/v1/current?city=</span><span class="token interpolation"><span class="token punctuation">{</span>city<span class="token punctuation">}</span></span><span class="token string">"</span></span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>

weather <span class="token operator">=</span> Tool<span class="token punctuation">.</span>from_function<span class="token punctuation">(</span>
    func<span class="token operator">=</span>weather_tool<span class="token punctuation">,</span>
    name<span class="token operator">=</span><span class="token string">"Weather"</span><span class="token punctuation">,</span>
    description<span class="token operator">=</span><span class="token string">"Gets current weather for a city"</span>
<span class="token punctuation">)</span>
</code></pre>
<h3 id="2-agent-types-and-usage">2. Agent Types and Usage</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>agents <span class="token keyword">import</span> <span class="token punctuation">(</span>
    create_openai_functions_agent<span class="token punctuation">,</span>
    create_react_agent<span class="token punctuation">,</span>
    AgentExecutor<span class="token punctuation">,</span>
    Tool
<span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>agents <span class="token keyword">import</span> load_tools

<span class="token comment"># Load built-in tools</span>
tools <span class="token operator">=</span> load_tools<span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token string">"serpapi"</span><span class="token punctuation">,</span> <span class="token string">"llm-math"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    llm<span class="token operator">=</span>llm
<span class="token punctuation">)</span>

<span class="token comment"># Custom tools</span>
custom_tools <span class="token operator">=</span> <span class="token punctuation">[</span>search_tool<span class="token punctuation">,</span> calculator<span class="token punctuation">,</span> weather<span class="token punctuation">]</span>
all_tools <span class="token operator">=</span> tools <span class="token operator">+</span> custom_tools

<span class="token comment"># OpenAI Functions Agent</span>
<span class="token keyword">from</span> langchain <span class="token keyword">import</span> hub

prompt <span class="token operator">=</span> hub<span class="token punctuation">.</span>pull<span class="token punctuation">(</span><span class="token string">"hwchase17/openai-functions-agent"</span><span class="token punctuation">)</span>
agent <span class="token operator">=</span> create_openai_functions_agent<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> all_tools<span class="token punctuation">,</span> prompt<span class="token punctuation">)</span>

agent_executor <span class="token operator">=</span> AgentExecutor<span class="token punctuation">(</span>
    agent<span class="token operator">=</span>agent<span class="token punctuation">,</span>
    tools<span class="token operator">=</span>all_tools<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    max_iterations<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    handle_parsing_errors<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token comment"># Run agent</span>
result <span class="token operator">=</span> agent_executor<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"What's the weather in Paris and what's 25 + 37?"</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment"># ReAct Agent (Reasoning + Acting)</span>
react_prompt <span class="token operator">=</span> hub<span class="token punctuation">.</span>pull<span class="token punctuation">(</span><span class="token string">"hwchase17/react"</span><span class="token punctuation">)</span>
react_agent <span class="token operator">=</span> create_react_agent<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> all_tools<span class="token punctuation">,</span> react_prompt<span class="token punctuation">)</span>

react_executor <span class="token operator">=</span> AgentExecutor<span class="token punctuation">(</span>
    agent<span class="token operator">=</span>react_agent<span class="token punctuation">,</span>
    tools<span class="token operator">=</span>all_tools<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token comment"># Conversational Agent with memory</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationBufferMemory

memory <span class="token operator">=</span> ConversationBufferMemory<span class="token punctuation">(</span>
    memory_key<span class="token operator">=</span><span class="token string">"chat_history"</span><span class="token punctuation">,</span>
    return_messages<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

conversational_agent <span class="token operator">=</span> AgentExecutor<span class="token punctuation">(</span>
    agent<span class="token operator">=</span>agent<span class="token punctuation">,</span>
    tools<span class="token operator">=</span>all_tools<span class="token punctuation">,</span>
    memory<span class="token operator">=</span>memory<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token comment"># Multi-step agent execution</span>
response1 <span class="token operator">=</span> conversational_agent<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"My name is John"</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

response2 <span class="token operator">=</span> conversational_agent<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"What's my name?"</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>  <span class="token comment"># Agent remembers: "John"</span>
</code></pre>
<h3 id="3-custom-agent-implementation">3. Custom Agent Implementation</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>agents <span class="token keyword">import</span> BaseSingleActionAgent
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> AgentAction<span class="token punctuation">,</span> AgentFinish

<span class="token keyword">class</span> <span class="token class-name">CustomAgent</span><span class="token punctuation">(</span>BaseSingleActionAgent<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tools<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span>Tool<span class="token punctuation">]</span>
    llm<span class="token punctuation">:</span> ChatOpenAI
    
    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">input_keys</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span>
    
    <span class="token keyword">def</span> <span class="token function">plan</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        intermediate_steps<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">,</span>
        <span class="token operator">**</span>kwargs
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> AgentAction <span class="token operator">|</span> AgentFinish<span class="token punctuation">:</span>
        <span class="token comment"># Custom planning logic</span>
        user_input <span class="token operator">=</span> kwargs<span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span>
        
        <span class="token comment"># Decide which tool to use</span>
        <span class="token keyword">if</span> <span class="token string">"weather"</span> <span class="token keyword">in</span> user_input<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> AgentAction<span class="token punctuation">(</span>
                tool<span class="token operator">=</span><span class="token string">"Weather"</span><span class="token punctuation">,</span>
                tool_input<span class="token operator">=</span>user_input<span class="token punctuation">,</span>
                log<span class="token operator">=</span><span class="token string">"Using weather tool"</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">elif</span> <span class="token string">"calculate"</span> <span class="token keyword">in</span> user_input<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> AgentAction<span class="token punctuation">(</span>
                tool<span class="token operator">=</span><span class="token string">"Calculator"</span><span class="token punctuation">,</span>
                tool_input<span class="token operator">=</span>user_input<span class="token punctuation">,</span>
                log<span class="token operator">=</span><span class="token string">"Using calculator"</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> AgentFinish<span class="token punctuation">(</span>
                return_values<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"I don't know how to help with that"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                log<span class="token operator">=</span><span class="token string">"No suitable tool found"</span>
            <span class="token punctuation">)</span>
    
    <span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">aplan</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        intermediate_steps<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">,</span>
        <span class="token operator">**</span>kwargs
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> AgentAction <span class="token operator">|</span> AgentFinish<span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>plan<span class="token punctuation">(</span>intermediate_steps<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>

<span class="token comment"># Use custom agent</span>
custom_agent <span class="token operator">=</span> CustomAgent<span class="token punctuation">(</span>tools<span class="token operator">=</span>custom_tools<span class="token punctuation">,</span> llm<span class="token operator">=</span>llm<span class="token punctuation">)</span>
custom_executor <span class="token operator">=</span> AgentExecutor<span class="token punctuation">(</span>agent<span class="token operator">=</span>custom_agent<span class="token punctuation">,</span> tools<span class="token operator">=</span>custom_tools<span class="token punctuation">)</span>
</code></pre>
<h2 id="memory-systems-memory">Memory Systems {#memory}</h2>
<h3 id="1-memory-types">1. Memory Types</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> <span class="token punctuation">(</span>
    ConversationBufferMemory<span class="token punctuation">,</span>
    ConversationBufferWindowMemory<span class="token punctuation">,</span>
    ConversationSummaryMemory<span class="token punctuation">,</span>
    ConversationKGMemory<span class="token punctuation">,</span>
    VectorStoreRetrieverMemory
<span class="token punctuation">)</span>

<span class="token comment"># Buffer memory - stores all messages</span>
buffer_memory <span class="token operator">=</span> ConversationBufferMemory<span class="token punctuation">(</span><span class="token punctuation">)</span>
buffer_memory<span class="token punctuation">.</span>save_context<span class="token punctuation">(</span>
    <span class="token punctuation">{</span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"Hi, I'm John"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"Hello John! How can I help you?"</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token comment"># Window memory - keeps last K messages</span>
window_memory <span class="token operator">=</span> ConversationBufferWindowMemory<span class="token punctuation">(</span>k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token comment"># Summary memory - summarizes old conversations</span>
summary_memory <span class="token operator">=</span> ConversationSummaryMemory<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">)</span>

<span class="token comment"># Knowledge graph memory - extracts entities and relationships</span>
kg_memory <span class="token operator">=</span> ConversationKGMemory<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">)</span>

<span class="token comment"># Vector store memory - uses similarity search</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma

embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
vector_store <span class="token operator">=</span> Chroma<span class="token punctuation">(</span>embedding_function<span class="token operator">=</span>embeddings<span class="token punctuation">)</span>

vector_memory <span class="token operator">=</span> VectorStoreRetrieverMemory<span class="token punctuation">(</span>
    retriever<span class="token operator">=</span>vector_store<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>search_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"k"</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># Add memories</span>
vector_memory<span class="token punctuation">.</span>save_context<span class="token punctuation">(</span>
    <span class="token punctuation">{</span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"I love programming"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"That's great! What languages?"</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>
</code></pre>
<h3 id="2-memory-in-chains">2. Memory in Chains</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token comment"># Chain with memory</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ConversationChain

conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    memory<span class="token operator">=</span>buffer_memory<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token comment"># Conversation maintains context</span>
response1 <span class="token operator">=</span> conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"Hi, I'm Alice"</span><span class="token punctuation">)</span>
response2 <span class="token operator">=</span> conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"What's my name?"</span><span class="token punctuation">)</span>
<span class="token comment"># Response: "Your name is Alice"</span>

<span class="token comment"># Custom memory implementation</span>
<span class="token keyword">class</span> <span class="token class-name">CustomMemory</span><span class="token punctuation">(</span>ConversationBufferMemory<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">save_context</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">,</span> outputs<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Custom logic before saving</span>
        <span class="token comment"># E.g., filter sensitive information</span>
        filtered_inputs <span class="token operator">=</span> self<span class="token punctuation">.</span>_filter_sensitive<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save_context<span class="token punctuation">(</span>filtered_inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">_filter_sensitive</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">dict</span><span class="token punctuation">:</span>
        <span class="token comment"># Remove credit card numbers, etc.</span>
        <span class="token keyword">return</span> inputs

<span class="token comment"># Memory with multiple stores</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> CombinedMemory

<span class="token comment"># Short-term memory</span>
short_term <span class="token operator">=</span> ConversationBufferWindowMemory<span class="token punctuation">(</span>k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token comment"># Long-term memory  </span>
long_term <span class="token operator">=</span> VectorStoreRetrieverMemory<span class="token punctuation">(</span>
    retriever<span class="token operator">=</span>vector_store<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># Combine memories</span>
combined_memory <span class="token operator">=</span> CombinedMemory<span class="token punctuation">(</span>memories<span class="token operator">=</span><span class="token punctuation">[</span>short_term<span class="token punctuation">,</span> long_term<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="rag-retrieval-augmented-generation-rag">RAG (Retrieval Augmented Generation) {#rag}</h2>
<h3 id="1-basic-rag-implementation">1. Basic RAG Implementation</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> <span class="token punctuation">(</span>
    TextLoader<span class="token punctuation">,</span>
    PyPDFLoader<span class="token punctuation">,</span>
    WebBaseLoader
<span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> RecursiveCharacterTextSplitter
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> StrOutputParser
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables <span class="token keyword">import</span> RunnablePassthrough

<span class="token comment"># Load documents</span>
loader <span class="token operator">=</span> PyPDFLoader<span class="token punctuation">(</span><span class="token string">"document.pdf"</span><span class="token punctuation">)</span>
documents <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Split documents</span>
text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>
    chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>
    chunk_overlap<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
    length_function<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
splits <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>

<span class="token comment"># Create embeddings and vector store</span>
embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
vectorstore <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>
    documents<span class="token operator">=</span>splits<span class="token punctuation">,</span>
    embedding<span class="token operator">=</span>embeddings
<span class="token punctuation">)</span>

<span class="token comment"># Create retriever</span>
retriever <span class="token operator">=</span> vectorstore<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>
    search_type<span class="token operator">=</span><span class="token string">"similarity"</span><span class="token punctuation">,</span>
    search_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"k"</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token comment"># RAG prompt</span>
rag_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""
Answer the question based only on the following context:

{context}

Question: {question}

Answer:
"""</span><span class="token punctuation">)</span>

<span class="token comment"># Format documents</span>
<span class="token keyword">def</span> <span class="token function">format_docs</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token string">"\n\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>doc<span class="token punctuation">.</span>page_content <span class="token keyword">for</span> doc <span class="token keyword">in</span> docs<span class="token punctuation">)</span>

<span class="token comment"># Create RAG chain</span>
rag_chain <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token punctuation">{</span>
        <span class="token string">"context"</span><span class="token punctuation">:</span> retriever <span class="token operator">|</span> format_docs<span class="token punctuation">,</span>
        <span class="token string">"question"</span><span class="token punctuation">:</span> RunnablePassthrough<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    <span class="token operator">|</span> rag_prompt
    <span class="token operator">|</span> llm
    <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># Query</span>
answer <span class="token operator">=</span> rag_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"What is the main topic of the document?"</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="2-advanced-rag-techniques">2. Advanced RAG Techniques</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token comment"># Multi-query retrieval</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>retrievers<span class="token punctuation">.</span>multi_query <span class="token keyword">import</span> MultiQueryRetriever

multi_query_retriever <span class="token operator">=</span> MultiQueryRetriever<span class="token punctuation">.</span>from_llm<span class="token punctuation">(</span>
    retriever<span class="token operator">=</span>vectorstore<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    llm<span class="token operator">=</span>llm
<span class="token punctuation">)</span>

<span class="token comment"># Generates multiple queries and retrieves for each</span>
results <span class="token operator">=</span> multi_query_retriever<span class="token punctuation">.</span>get_relevant_documents<span class="token punctuation">(</span>
    <span class="token string">"Tell me about climate change"</span>
<span class="token punctuation">)</span>

<span class="token comment"># Contextual compression</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>retrievers <span class="token keyword">import</span> ContextualCompressionRetriever
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>retrievers<span class="token punctuation">.</span>document_compressors <span class="token keyword">import</span> LLMChainExtractor

compressor <span class="token operator">=</span> LLMChainExtractor<span class="token punctuation">.</span>from_llm<span class="token punctuation">(</span>llm<span class="token punctuation">)</span>
compression_retriever <span class="token operator">=</span> ContextualCompressionRetriever<span class="token punctuation">(</span>
    base_compressor<span class="token operator">=</span>compressor<span class="token punctuation">,</span>
    base_retriever<span class="token operator">=</span>vectorstore<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># Returns only relevant parts of documents</span>
compressed_docs <span class="token operator">=</span> compression_retriever<span class="token punctuation">.</span>get_relevant_documents<span class="token punctuation">(</span>
    <span class="token string">"What is Python?"</span>
<span class="token punctuation">)</span>

<span class="token comment"># Parent document retrieval</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>retrievers <span class="token keyword">import</span> ParentDocumentRetriever
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>storage <span class="token keyword">import</span> InMemoryStore

<span class="token comment"># Store for parent documents</span>
store <span class="token operator">=</span> InMemoryStore<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Small chunks for retrieval</span>
child_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">400</span><span class="token punctuation">)</span>

<span class="token comment"># Larger chunks for context</span>
parent_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">)</span>

parent_retriever <span class="token operator">=</span> ParentDocumentRetriever<span class="token punctuation">(</span>
    vectorstore<span class="token operator">=</span>vectorstore<span class="token punctuation">,</span>
    docstore<span class="token operator">=</span>store<span class="token punctuation">,</span>
    child_splitter<span class="token operator">=</span>child_splitter<span class="token punctuation">,</span>
    parent_splitter<span class="token operator">=</span>parent_splitter<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># Hybrid search (keyword + semantic)</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>retrievers <span class="token keyword">import</span> BM25Retriever<span class="token punctuation">,</span> EnsembleRetriever

<span class="token comment"># Keyword-based retriever</span>
bm25_retriever <span class="token operator">=</span> BM25Retriever<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>splits<span class="token punctuation">)</span>
bm25_retriever<span class="token punctuation">.</span>k <span class="token operator">=</span> <span class="token number">3</span>

<span class="token comment"># Semantic retriever</span>
semantic_retriever <span class="token operator">=</span> vectorstore<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>search_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"k"</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment"># Combine both</span>
ensemble_retriever <span class="token operator">=</span> EnsembleRetriever<span class="token punctuation">(</span>
    retrievers<span class="token operator">=</span><span class="token punctuation">[</span>bm25_retriever<span class="token punctuation">,</span> semantic_retriever<span class="token punctuation">]</span><span class="token punctuation">,</span>
    weights<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token comment"># Self-query retriever with metadata</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>retrievers<span class="token punctuation">.</span>self_query<span class="token punctuation">.</span>base <span class="token keyword">import</span> SelfQueryRetriever
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>query_constructor<span class="token punctuation">.</span>base <span class="token keyword">import</span> AttributeInfo

metadata_field_info <span class="token operator">=</span> <span class="token punctuation">[</span>
    AttributeInfo<span class="token punctuation">(</span>
        name<span class="token operator">=</span><span class="token string">"category"</span><span class="token punctuation">,</span>
        description<span class="token operator">=</span><span class="token string">"The category of the document"</span><span class="token punctuation">,</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">"string"</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    AttributeInfo<span class="token punctuation">(</span>
        name<span class="token operator">=</span><span class="token string">"year"</span><span class="token punctuation">,</span>
        description<span class="token operator">=</span><span class="token string">"The year the document was written"</span><span class="token punctuation">,</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">"integer"</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

document_content_description <span class="token operator">=</span> <span class="token string">"Technical documentation"</span>

self_query_retriever <span class="token operator">=</span> SelfQueryRetriever<span class="token punctuation">.</span>from_llm<span class="token punctuation">(</span>
    llm<span class="token punctuation">,</span>
    vectorstore<span class="token punctuation">,</span>
    document_content_description<span class="token punctuation">,</span>
    metadata_field_info<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token comment"># Query with metadata filter</span>
docs <span class="token operator">=</span> self_query_retriever<span class="token punctuation">.</span>get_relevant_documents<span class="token punctuation">(</span>
    <span class="token string">"Documents about Python from 2023"</span>
<span class="token punctuation">)</span>
</code></pre>
<h2 id="vector-stores-vector-stores">Vector Stores {#vector-stores}</h2>
<h3 id="1-vector-store-options">1. Vector Store Options</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token comment"># Chroma (local)</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma

chroma_db <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>
    documents<span class="token operator">=</span>splits<span class="token punctuation">,</span>
    embedding<span class="token operator">=</span>embeddings<span class="token punctuation">,</span>
    persist_directory<span class="token operator">=</span><span class="token string">"./chroma_db"</span>
<span class="token punctuation">)</span>

<span class="token comment"># FAISS (local, fast)</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS

faiss_db <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>splits<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>
faiss_db<span class="token punctuation">.</span>save_local<span class="token punctuation">(</span><span class="token string">"faiss_index"</span><span class="token punctuation">)</span>

<span class="token comment"># Load existing index</span>
loaded_db <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>load_local<span class="token punctuation">(</span><span class="token string">"faiss_index"</span><span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>

<span class="token comment"># Pinecone (cloud)</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Pinecone
<span class="token keyword">import</span> pinecone

pinecone<span class="token punctuation">.</span>init<span class="token punctuation">(</span>api_key<span class="token operator">=</span><span class="token string">"your-key"</span><span class="token punctuation">,</span> environment<span class="token operator">=</span><span class="token string">"us-west1-gcp"</span><span class="token punctuation">)</span>

pinecone_db <span class="token operator">=</span> Pinecone<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>
    splits<span class="token punctuation">,</span>
    embeddings<span class="token punctuation">,</span>
    index_name<span class="token operator">=</span><span class="token string">"my-index"</span>
<span class="token punctuation">)</span>

<span class="token comment"># Weaviate (cloud/self-hosted)</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Weaviate
<span class="token keyword">import</span> weaviate

client <span class="token operator">=</span> weaviate<span class="token punctuation">.</span>Client<span class="token punctuation">(</span>url<span class="token operator">=</span><span class="token string">"http://localhost:8080"</span><span class="token punctuation">)</span>

weaviate_db <span class="token operator">=</span> Weaviate<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>
    splits<span class="token punctuation">,</span>
    embeddings<span class="token punctuation">,</span>
    client<span class="token operator">=</span>client<span class="token punctuation">,</span>
    by_text<span class="token operator">=</span><span class="token boolean">False</span>
<span class="token punctuation">)</span>

<span class="token comment"># Qdrant (cloud/self-hosted)</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Qdrant

qdrant_db <span class="token operator">=</span> Qdrant<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>
    splits<span class="token punctuation">,</span>
    embeddings<span class="token punctuation">,</span>
    url<span class="token operator">=</span><span class="token string">"http://localhost:6333"</span><span class="token punctuation">,</span>
    collection_name<span class="token operator">=</span><span class="token string">"my_documents"</span>
<span class="token punctuation">)</span>
</code></pre>
<h3 id="2-vector-store-operations">2. Vector Store Operations</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token comment"># Add documents</span>
new_docs <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>create_documents<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token string">"New document content"</span><span class="token punctuation">,</span>
    <span class="token string">"Another document"</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
vectorstore<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>new_docs<span class="token punctuation">)</span>

<span class="token comment"># Similarity search</span>
results <span class="token operator">=</span> vectorstore<span class="token punctuation">.</span>similarity_search<span class="token punctuation">(</span>
    <span class="token string">"What is machine learning?"</span><span class="token punctuation">,</span>
    k<span class="token operator">=</span><span class="token number">5</span>
<span class="token punctuation">)</span>

<span class="token comment"># Similarity search with scores</span>
results_with_scores <span class="token operator">=</span> vectorstore<span class="token punctuation">.</span>similarity_search_with_score<span class="token punctuation">(</span>
    <span class="token string">"Python programming"</span><span class="token punctuation">,</span>
    k<span class="token operator">=</span><span class="token number">3</span>
<span class="token punctuation">)</span>

<span class="token keyword">for</span> doc<span class="token punctuation">,</span> score <span class="token keyword">in</span> results_with_scores<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Score: </span><span class="token interpolation"><span class="token punctuation">{</span>score<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Content: </span><span class="token interpolation"><span class="token punctuation">{</span>doc<span class="token punctuation">.</span>page_content<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">100]</span><span class="token punctuation">}</span></span><span class="token string">..."</span></span><span class="token punctuation">)</span>

<span class="token comment"># MMR (Maximal Marginal Relevance) search</span>
<span class="token comment"># Returns diverse results</span>
mmr_results <span class="token operator">=</span> vectorstore<span class="token punctuation">.</span>max_marginal_relevance_search<span class="token punctuation">(</span>
    <span class="token string">"Python"</span><span class="token punctuation">,</span>
    k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    fetch_k<span class="token operator">=</span><span class="token number">20</span>  <span class="token comment"># Fetch more, return diverse subset</span>
<span class="token punctuation">)</span>

<span class="token comment"># Metadata filtering</span>
filtered_results <span class="token operator">=</span> vectorstore<span class="token punctuation">.</span>similarity_search<span class="token punctuation">(</span>
    <span class="token string">"Python tutorial"</span><span class="token punctuation">,</span>
    k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    <span class="token builtin">filter</span><span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"category"</span><span class="token punctuation">:</span> <span class="token string">"programming"</span><span class="token punctuation">,</span> <span class="token string">"year"</span><span class="token punctuation">:</span> <span class="token number">2023</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token comment"># Delete documents</span>
vectorstore<span class="token punctuation">.</span>delete<span class="token punctuation">(</span>ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"doc_id_1"</span><span class="token punctuation">,</span> <span class="token string">"doc_id_2"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Update documents</span>
vectorstore<span class="token punctuation">.</span>update_document<span class="token punctuation">(</span>
    document_id<span class="token operator">=</span><span class="token string">"doc_id"</span><span class="token punctuation">,</span>
    document<span class="token operator">=</span>new_document
<span class="token punctuation">)</span>
</code></pre>
<h2 id="evaluation-and-monitoring-evaluation">Evaluation and Monitoring {#evaluation}</h2>
<h3 id="1-evaluating-rag-systems">1. Evaluating RAG Systems</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>evaluation <span class="token keyword">import</span> <span class="token punctuation">(</span>
    load_evaluator<span class="token punctuation">,</span>
    EvaluatorType
<span class="token punctuation">)</span>

<span class="token comment"># Question-Answer evaluation</span>
qa_evaluator <span class="token operator">=</span> load_evaluator<span class="token punctuation">(</span><span class="token string">"qa"</span><span class="token punctuation">)</span>

eval_result <span class="token operator">=</span> qa_evaluator<span class="token punctuation">.</span>evaluate_strings<span class="token punctuation">(</span>
    prediction<span class="token operator">=</span><span class="token string">"Paris is the capital of France"</span><span class="token punctuation">,</span>
    <span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"What is the capital of France?"</span><span class="token punctuation">,</span>
    reference<span class="token operator">=</span><span class="token string">"Paris"</span>
<span class="token punctuation">)</span>

<span class="token comment"># Criteria-based evaluation</span>
criteria_evaluator <span class="token operator">=</span> load_evaluator<span class="token punctuation">(</span>
    <span class="token string">"criteria"</span><span class="token punctuation">,</span>
    criteria<span class="token operator">=</span><span class="token string">"conciseness"</span>
<span class="token punctuation">)</span>

eval_result <span class="token operator">=</span> criteria_evaluator<span class="token punctuation">.</span>evaluate_strings<span class="token punctuation">(</span>
    prediction<span class="token operator">=</span><span class="token string">"The answer is very long and verbose..."</span><span class="token punctuation">,</span>
    <span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"What is 2+2?"</span>
<span class="token punctuation">)</span>

<span class="token comment"># Custom evaluation</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>evaluation <span class="token keyword">import</span> StringEvaluator

<span class="token keyword">class</span> <span class="token class-name">CustomEvaluator</span><span class="token punctuation">(</span>StringEvaluator<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">_evaluate_strings</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        prediction<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
        reference<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        <span class="token builtin">input</span><span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        <span class="token operator">**</span>kwargs
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">dict</span><span class="token punctuation">:</span>
        <span class="token comment"># Custom evaluation logic</span>
        score <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>prediction<span class="token punctuation">)</span> <span class="token operator">&#x3C;</span> <span class="token number">100</span>  <span class="token comment"># Example: brevity</span>
        <span class="token keyword">return</span> <span class="token punctuation">{</span>
            <span class="token string">"score"</span><span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"reasoning"</span><span class="token punctuation">:</span> <span class="token string">"Response is concise"</span> <span class="token keyword">if</span> score <span class="token keyword">else</span> <span class="token string">"Too long"</span>
        <span class="token punctuation">}</span>

<span class="token comment"># RAG evaluation metrics</span>
<span class="token keyword">from</span> ragas <span class="token keyword">import</span> evaluate
<span class="token keyword">from</span> ragas<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> <span class="token punctuation">(</span>
    faithfulness<span class="token punctuation">,</span>
    answer_relevancy<span class="token punctuation">,</span>
    context_precision<span class="token punctuation">,</span>
    context_recall
<span class="token punctuation">)</span>

<span class="token comment"># Prepare evaluation dataset</span>
eval_dataset <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"question"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"What is Python?"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"answer"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"Python is a programming language"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"contexts"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">"Python is a high-level programming language..."</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"ground_truths"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">"Python is a programming language"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>

<span class="token comment"># Evaluate</span>
result <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>
    eval_dataset<span class="token punctuation">,</span>
    metrics<span class="token operator">=</span><span class="token punctuation">[</span>
        faithfulness<span class="token punctuation">,</span>
        answer_relevancy<span class="token punctuation">,</span>
        context_precision<span class="token punctuation">,</span>
        context_recall
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
</code></pre>
<h3 id="2-monitoring-and-logging">2. Monitoring and Logging</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> StdOutCallbackHandler
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>tracers <span class="token keyword">import</span> LangChainTracer

<span class="token comment"># Stdout logging</span>
handler <span class="token operator">=</span> StdOutCallbackHandler<span class="token punctuation">(</span><span class="token punctuation">)</span>

chain <span class="token operator">=</span> prompt <span class="token operator">|</span> llm <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>
    <span class="token punctuation">{</span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"Hello"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"callbacks"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>handler<span class="token punctuation">]</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token comment"># LangSmith tracing</span>
<span class="token keyword">import</span> os
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"LANGCHAIN_TRACING_V2"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"true"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"LANGCHAIN_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"your-key"</span>

tracer <span class="token operator">=</span> LangChainTracer<span class="token punctuation">(</span><span class="token punctuation">)</span>

result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>
    <span class="token punctuation">{</span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"Hello"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"callbacks"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tracer<span class="token punctuation">]</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token comment"># Custom callback</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>base <span class="token keyword">import</span> BaseCallbackHandler

<span class="token keyword">class</span> <span class="token class-name">CustomCallback</span><span class="token punctuation">(</span>BaseCallbackHandler<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">on_llm_start</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> serialized<span class="token punctuation">,</span> prompts<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"LLM started with prompts: </span><span class="token interpolation"><span class="token punctuation">{</span>prompts<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">on_llm_end</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"LLM ended with response: </span><span class="token interpolation"><span class="token punctuation">{</span>response<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">on_llm_error</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> error<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"LLM error: </span><span class="token interpolation"><span class="token punctuation">{</span>error<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">on_chain_start</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> serialized<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Chain started with inputs: </span><span class="token interpolation"><span class="token punctuation">{</span>inputs<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">on_chain_end</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Chain ended with outputs: </span><span class="token interpolation"><span class="token punctuation">{</span>outputs<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

custom_callback <span class="token operator">=</span> CustomCallback<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Token counting callback</span>
<span class="token keyword">class</span> <span class="token class-name">TokenCountCallback</span><span class="token punctuation">(</span>BaseCallbackHandler<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>total_tokens <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>prompt_tokens <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>completion_tokens <span class="token operator">=</span> <span class="token number">0</span>
    
    <span class="token keyword">def</span> <span class="token function">on_llm_end</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>response<span class="token punctuation">,</span> <span class="token string">"llm_output"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            token_usage <span class="token operator">=</span> response<span class="token punctuation">.</span>llm_output<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"token_usage"</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>total_tokens <span class="token operator">+=</span> token_usage<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"total_tokens"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>prompt_tokens <span class="token operator">+=</span> token_usage<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"prompt_tokens"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>completion_tokens <span class="token operator">+=</span> token_usage<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"completion_tokens"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

token_counter <span class="token operator">=</span> TokenCountCallback<span class="token punctuation">(</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>
    <span class="token punctuation">{</span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"Hello"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"callbacks"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>token_counter<span class="token punctuation">]</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Total tokens used: </span><span class="token interpolation"><span class="token punctuation">{</span>token_counter<span class="token punctuation">.</span>total_tokens<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre>
<h2 id="production-deployment-deployment">Production Deployment {#deployment}</h2>
<h3 id="1-fastapi-integration">1. FastAPI Integration</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> fastapi <span class="token keyword">import</span> FastAPI<span class="token punctuation">,</span> HTTPException
<span class="token keyword">from</span> pydantic <span class="token keyword">import</span> BaseModel
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> StrOutputParser

app <span class="token operator">=</span> FastAPI<span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">"LangChain API"</span><span class="token punctuation">)</span>

<span class="token comment"># Initialize LLM and chain</span>
llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>
prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">"Answer: {question}"</span><span class="token punctuation">)</span>
chain <span class="token operator">=</span> prompt <span class="token operator">|</span> llm <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Request model</span>
<span class="token keyword">class</span> <span class="token class-name">QuestionRequest</span><span class="token punctuation">(</span>BaseModel<span class="token punctuation">)</span><span class="token punctuation">:</span>
    question<span class="token punctuation">:</span> <span class="token builtin">str</span>

<span class="token keyword">class</span> <span class="token class-name">AnswerResponse</span><span class="token punctuation">(</span>BaseModel<span class="token punctuation">)</span><span class="token punctuation">:</span>
    answer<span class="token punctuation">:</span> <span class="token builtin">str</span>

<span class="token decorator annotation punctuation">@app<span class="token punctuation">.</span>post</span><span class="token punctuation">(</span><span class="token string">"/ask"</span><span class="token punctuation">,</span> response_model<span class="token operator">=</span>AnswerResponse<span class="token punctuation">)</span>
<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">ask_question</span><span class="token punctuation">(</span>request<span class="token punctuation">:</span> QuestionRequest<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        answer <span class="token operator">=</span> <span class="token keyword">await</span> chain<span class="token punctuation">.</span>ainvoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"question"</span><span class="token punctuation">:</span> request<span class="token punctuation">.</span>question<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> AnswerResponse<span class="token punctuation">(</span>answer<span class="token operator">=</span>answer<span class="token punctuation">)</span>
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        <span class="token keyword">raise</span> HTTPException<span class="token punctuation">(</span>status_code<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> detail<span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># RAG endpoint</span>
<span class="token decorator annotation punctuation">@app<span class="token punctuation">.</span>post</span><span class="token punctuation">(</span><span class="token string">"/rag"</span><span class="token punctuation">)</span>
<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">rag_query</span><span class="token punctuation">(</span>request<span class="token punctuation">:</span> QuestionRequest<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token comment"># Use RAG chain</span>
        answer <span class="token operator">=</span> <span class="token keyword">await</span> rag_chain<span class="token punctuation">.</span>ainvoke<span class="token punctuation">(</span>request<span class="token punctuation">.</span>question<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">"answer"</span><span class="token punctuation">:</span> answer<span class="token punctuation">}</span>
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        <span class="token keyword">raise</span> HTTPException<span class="token punctuation">(</span>status_code<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> detail<span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Health check</span>
<span class="token decorator annotation punctuation">@app<span class="token punctuation">.</span>get</span><span class="token punctuation">(</span><span class="token string">"/health"</span><span class="token punctuation">)</span>
<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">health</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">"status"</span><span class="token punctuation">:</span> <span class="token string">"healthy"</span><span class="token punctuation">}</span>

<span class="token comment"># Run with: uvicorn main:app --reload</span>
</code></pre>
<h3 id="2-caching-and-optimization">2. Caching and Optimization</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>cache <span class="token keyword">import</span> InMemoryCache<span class="token punctuation">,</span> SQLiteCache
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span><span class="token builtin">globals</span> <span class="token keyword">import</span> set_llm_cache
<span class="token keyword">import</span> langchain

<span class="token comment"># In-memory cache</span>
set_llm_cache<span class="token punctuation">(</span>InMemoryCache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># SQLite cache (persistent)</span>
set_llm_cache<span class="token punctuation">(</span>SQLiteCache<span class="token punctuation">(</span>database_path<span class="token operator">=</span><span class="token string">".langchain.db"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Redis cache</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>cache <span class="token keyword">import</span> RedisCache
<span class="token keyword">import</span> redis

redis_client <span class="token operator">=</span> redis<span class="token punctuation">.</span>Redis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'localhost'</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
set_llm_cache<span class="token punctuation">(</span>RedisCache<span class="token punctuation">(</span>redis_client<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Semantic cache</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>cache <span class="token keyword">import</span> RedisSemanticCache

set_llm_cache<span class="token punctuation">(</span>
    RedisSemanticCache<span class="token punctuation">(</span>
        redis_url<span class="token operator">=</span><span class="token string">"redis://localhost:6379"</span><span class="token punctuation">,</span>
        embedding<span class="token operator">=</span>OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># Rate limiting</span>
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables <span class="token keyword">import</span> RateLimiter

rate_limiter <span class="token operator">=</span> RateLimiter<span class="token punctuation">(</span>
    requests_per_second<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    check_every_n_seconds<span class="token operator">=</span><span class="token number">1</span>
<span class="token punctuation">)</span>

rate_limited_chain <span class="token operator">=</span> rate_limiter <span class="token operator">|</span> chain

<span class="token comment"># Batch processing</span>
<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">process_batch</span><span class="token punctuation">(</span>questions<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    results <span class="token operator">=</span> <span class="token keyword">await</span> chain<span class="token punctuation">.</span>abatch<span class="token punctuation">(</span>
        <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"question"</span><span class="token punctuation">:</span> q<span class="token punctuation">}</span> <span class="token keyword">for</span> q <span class="token keyword">in</span> questions<span class="token punctuation">]</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"max_concurrency"</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">}</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> results

<span class="token comment"># Retry logic</span>
<span class="token keyword">from</span> tenacity <span class="token keyword">import</span> retry<span class="token punctuation">,</span> stop_after_attempt<span class="token punctuation">,</span> wait_exponential

<span class="token decorator annotation punctuation">@retry</span><span class="token punctuation">(</span>
    stop<span class="token operator">=</span>stop_after_attempt<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    wait<span class="token operator">=</span>wait_exponential<span class="token punctuation">(</span>multiplier<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">resilient_invoke</span><span class="token punctuation">(</span>question<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token keyword">await</span> chain<span class="token punctuation">.</span>ainvoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"question"</span><span class="token punctuation">:</span> question<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="3-production-best-practices">3. Production Best Practices</h3>
<pre class="language-python" data-language="python"><code is:raw="" class="language-python"><span class="token keyword">import</span> structlog
<span class="token keyword">from</span> prometheus_client <span class="token keyword">import</span> Counter<span class="token punctuation">,</span> Histogram
<span class="token keyword">import</span> time

<span class="token comment"># Structured logging</span>
logger <span class="token operator">=</span> structlog<span class="token punctuation">.</span>get_logger<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Metrics</span>
request_counter <span class="token operator">=</span> Counter<span class="token punctuation">(</span>
    <span class="token string">'langchain_requests_total'</span><span class="token punctuation">,</span>
    <span class="token string">'Total LangChain requests'</span>
<span class="token punctuation">)</span>
request_duration <span class="token operator">=</span> Histogram<span class="token punctuation">(</span>
    <span class="token string">'langchain_request_duration_seconds'</span><span class="token punctuation">,</span>
    <span class="token string">'Request duration'</span>
<span class="token punctuation">)</span>

<span class="token comment"># Production-ready chain wrapper</span>
<span class="token keyword">class</span> <span class="token class-name">ProductionChain</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> chain<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>chain <span class="token operator">=</span> chain
        self<span class="token punctuation">.</span>logger <span class="token operator">=</span> structlog<span class="token punctuation">.</span>get_logger<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">invoke</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_data<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">str</span><span class="token punctuation">:</span>
        request_id <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>uuid<span class="token punctuation">.</span>uuid4<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span>
                <span class="token string">"chain_started"</span><span class="token punctuation">,</span>
                request_id<span class="token operator">=</span>request_id<span class="token punctuation">,</span>
                input_data<span class="token operator">=</span>input_data
            <span class="token punctuation">)</span>
            
            result <span class="token operator">=</span> <span class="token keyword">await</span> self<span class="token punctuation">.</span>chain<span class="token punctuation">.</span>ainvoke<span class="token punctuation">(</span>input_data<span class="token punctuation">)</span>
            
            duration <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time
            request_counter<span class="token punctuation">.</span>inc<span class="token punctuation">(</span><span class="token punctuation">)</span>
            request_duration<span class="token punctuation">.</span>observe<span class="token punctuation">(</span>duration<span class="token punctuation">)</span>
            
            self<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span>
                <span class="token string">"chain_completed"</span><span class="token punctuation">,</span>
                request_id<span class="token operator">=</span>request_id<span class="token punctuation">,</span>
                duration<span class="token operator">=</span>duration
            <span class="token punctuation">)</span>
            
            <span class="token keyword">return</span> result
            
        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span>
                <span class="token string">"chain_failed"</span><span class="token punctuation">,</span>
                request_id<span class="token operator">=</span>request_id<span class="token punctuation">,</span>
                error<span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
            <span class="token keyword">raise</span>

<span class="token comment"># Environment-specific configuration</span>
<span class="token keyword">import</span> os
<span class="token keyword">from</span> pydantic <span class="token keyword">import</span> BaseSettings

<span class="token keyword">class</span> <span class="token class-name">Settings</span><span class="token punctuation">(</span>BaseSettings<span class="token punctuation">)</span><span class="token punctuation">:</span>
    openai_api_key<span class="token punctuation">:</span> <span class="token builtin">str</span>
    model_name<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"gpt-3.5-turbo"</span>
    temperature<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.7</span>
    max_tokens<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">500</span>
    redis_url<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"redis://localhost:6379"</span>
    
    <span class="token keyword">class</span> <span class="token class-name">Config</span><span class="token punctuation">:</span>
        env_file <span class="token operator">=</span> <span class="token string">".env"</span>

settings <span class="token operator">=</span> Settings<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Initialize with settings</span>
llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    api_key<span class="token operator">=</span>settings<span class="token punctuation">.</span>openai_api_key<span class="token punctuation">,</span>
    model<span class="token operator">=</span>settings<span class="token punctuation">.</span>model_name<span class="token punctuation">,</span>
    temperature<span class="token operator">=</span>settings<span class="token punctuation">.</span>temperature<span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span>settings<span class="token punctuation">.</span>max_tokens
<span class="token punctuation">)</span>
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>LangChain enables building powerful LLM applications. Key takeaways:</p>
<ol>
<li><strong>Start Simple</strong> - Begin with basic chains, add complexity gradually</li>
<li><strong>Use RAG</strong> - Enhance responses with relevant context</li>
<li><strong>Implement Agents</strong> - Let LLMs use tools intelligently</li>
<li><strong>Evaluate Rigorously</strong> - Test quality with proper metrics</li>
<li><strong>Monitor Production</strong> - Track usage, costs, and performance</li>
</ol>
<p><strong>Remember</strong>: Building with LLMs is iterative - experiment, evaluate, refine.</p>
<h2 id="resources">Resources</h2>
<ul>
<li><a href="https://python.langchain.com/">LangChain Documentation</a></li>
<li><a href="https://github.com/langchain-ai/langchain/tree/master/cookbook">LangChain Cookbook</a></li>
<li><a href="https://smith.langchain.com/">LangSmith</a> - Monitoring platform</li>
<li><a href="https://smith.langchain.com/hub">LangChain Hub</a> - Prompt templates</li>
</ul>
<hr>
<p><em>What LangChain patterns work best for your use case? Share your experience!</em></p> </div>  <section class="related-posts" data-astro-cid-dpgbfi7r> <h2 data-astro-cid-dpgbfi7r>Related Posts</h2> <div class="related-posts-grid" data-astro-cid-dpgbfi7r> <article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/stock-weather-ai/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>Stock Weather AI</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>Stock Weather AI — Reading the Market&#39;s Forecast Imagine a weather report for the markets: a short, clear summary about…</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-10-03T23:00:00.000Z" data-astro-cid-dpgbfi7r> Oct 3, 2025 </time> <span data-astro-cid-dpgbfi7r>•</span> <span data-astro-cid-dpgbfi7r>3 min read</span> </div> </a> </article><article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-10-20-introducing-thinking-in-modalities-with-terramind/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>Introducing Thinking-in-Modalities with TerraMind: A Novel Approach to Foundation Models</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>Introduction to TerraMind and Thinking-in-Modalities (TiM) TerraMind is a new foundation model developed by IBM…</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-10-20T00:00:00.000Z" data-astro-cid-dpgbfi7r> Oct 20, 2025 </time> <span data-astro-cid-dpgbfi7r>•</span> <span data-astro-cid-dpgbfi7r>3 min read</span> </div> </a> </article><article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-10-20-presentation-why-observability-matters-more-with-ai-applications/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>Why Observability Matters for AI Applications: A Deep Dive into LLM Monitoring</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>Main Heading: Observability in the Age of AI: Addressing the Unique Challenges of LLMs This presentation by Sally…</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-10-20T00:00:00.000Z" data-astro-cid-dpgbfi7r> Oct 20, 2025 </time> <span data-astro-cid-dpgbfi7r>•</span> <span data-astro-cid-dpgbfi7r>4 min read</span> </div> </a> </article> </div> </section>  </article> </div> <div class="back-link" data-astro-cid-rkg3zjxi><a href="/ai-news/" data-astro-cid-rkg3zjxi>← Back to AI News</a></div>  </main> <!-- Site Footer --> <footer class="site-footer container"> <p>
© 2025 AREZKI El Mehdi •
<a href="https://github.com/earezki">GitHub</a> •
<a href="/rss.xml">RSS</a> •
<a href="/sitemap-index.xml">Sitemap</a> </p> </footer> <!-- Theme Toggle Script -->  <!-- Article Read/Unread Tracking --> <script>
      /**
       * Tracks which articles have been read using localStorage
       * Updates post card styling on list pages
       */
      (function() {
        const STORAGE_KEY = 'readArticles';
        
        /**
         * Gets list of read article URLs from localStorage
         */
        function getReadArticles() {
          try {
            const data = localStorage.getItem(STORAGE_KEY);
            return data ? JSON.parse(data) : [];
          } catch (e) {
            console.error('Failed to get read articles:', e);
            return [];
          }
        }
        
        /**
         * Marks an article URL as read
         */
        function markArticleAsRead(url) {
          try {
            const readArticles = getReadArticles();
            if (!readArticles.includes(url)) {
              readArticles.push(url);
              localStorage.setItem(STORAGE_KEY, JSON.stringify(readArticles));
            }
          } catch (e) {
            console.error('Failed to mark article as read:', e);
          }
        }
        
        /**
         * Checks if an article has been read
         */
        function isArticleRead(url) {
          const readArticles = getReadArticles();
          return readArticles.includes(url);
        }
        
        /**
         * Updates post card styling on list pages based on read status
         */
        function updatePostCards() {
          const postCards = document.querySelectorAll('.post-card[data-article-url]');
          
          postCards.forEach(function(card) {
            const url = card.getAttribute('data-article-url');
            if (!url) return;
            
            if (isArticleRead(url)) {
              card.classList.add('read');
              card.classList.remove('unread');
            } else {
              card.classList.add('unread');
              card.classList.remove('read');
            }
          });
        }
        
        /**
         * Marks current article as read (on article detail pages)
         */
        function markCurrentArticleAsRead() {
          const isArticlePage = document.querySelector('.post-body');
          if (isArticlePage) {
            const currentPath = window.location.pathname;
            markArticleAsRead(currentPath);
          }
        }
        
        /**
         * Initialize tracking system
         */
        function init() {
          updatePostCards();
          markCurrentArticleAsRead();
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', init);
        
        // Handle back/forward navigation (bfcache)
        window.addEventListener('pageshow', function(event) {
          if (event.persisted) {
            init();
          }
        });
      })();
    </script> <!-- Code Copy Functionality --> <script>
      /**
       * Adds copy buttons to all code blocks
       */
      (function() {
        /**
         * Creates a copy button element
         */
        function createCopyButton() {
          const button = document.createElement('button');
          button.className = 'copy-code-button';
          button.setAttribute('aria-label', 'Copy code to clipboard');
          button.innerHTML = `
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
              <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
            </svg>
            <span>Copy</span>
          `;
          return button;
        }
        
        /**
         * Creates a success checkmark icon
         */
        function createCheckIcon() {
          return `
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <polyline points="20 6 9 17 4 12"></polyline>
            </svg>
            <span>Copied!</span>
          `;
        }
        
        /**
         * Copies text to clipboard
         */
        async function copyToClipboard(text) {
          try {
            await navigator.clipboard.writeText(text);
            return true;
          } catch (err) {
            // Fallback for older browsers
            const textArea = document.createElement('textarea');
            textArea.value = text;
            textArea.style.position = 'fixed';
            textArea.style.left = '-999999px';
            document.body.appendChild(textArea);
            textArea.select();
            try {
              document.execCommand('copy');
              document.body.removeChild(textArea);
              return true;
            } catch (e) {
              document.body.removeChild(textArea);
              return false;
            }
          }
        }
        
        /**
         * Handles copy button click
         */
        async function handleCopyClick(button, codeBlock) {
          const code = codeBlock.textContent || '';
          const success = await copyToClipboard(code);
          
          if (success) {
            const originalHTML = button.innerHTML;
            button.classList.add('copied');
            button.innerHTML = createCheckIcon();
            
            setTimeout(function() {
              button.classList.remove('copied');
              button.innerHTML = originalHTML;
            }, 2000);
          }
        }
        
        /**
         * Adds copy buttons to all code blocks
         */
        function addCopyButtons() {
          const codeBlocks = document.querySelectorAll('.post-body pre');
          
          codeBlocks.forEach(function(pre) {
            // Skip if button already exists
            if (pre.querySelector('.copy-code-button')) {
              return;
            }
            
            const button = createCopyButton();
            const codeBlock = pre.querySelector('code');
            
            if (codeBlock) {
              button.addEventListener('click', function() {
                handleCopyClick(button, codeBlock);
              });
              
              pre.appendChild(button);
            }
          });
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', addCopyButtons);
      })();
    </script> </body> </html> 