<!DOCTYPE html><html lang="en" data-theme="dark"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>LeRobot v0.4.0: Supercharging OSS Robot Learning with New Features and Integrations • Dev|Journal</title><meta name="description" content="LeRobot v0.4.0: Supercharging OSS Robot Learning This release, LeRobot v0.4.0, marks a significant leap forward in open-source robotics, focusing on enhancing…"><meta name="keywords" content="software architecture, backend development, microservices, Java, Python, Spring Boot, technical blog"><meta name="author" content="El Mehdi Arezki"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://earezki.com/ai-news/2025-10-24-lerobot-v040-supercharging-oss-robot-learning/"><meta property="og:title" content="LeRobot v0.4.0: Supercharging OSS Robot Learning with New Features and Integrations • Dev|Journal"><meta property="og:site_name" content="Dev|Journal"><meta property="og:description" content="LeRobot v0.4.0: Supercharging OSS Robot Learning This release, LeRobot v0.4.0, marks a significant leap forward in open-source robotics, focusing on enhancing…"><meta property="og:image" content="https://earezki.com/assets/og-image-default.jpg"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://earezki.com/ai-news/2025-10-24-lerobot-v040-supercharging-oss-robot-learning/"><meta name="twitter:title" content="LeRobot v0.4.0: Supercharging OSS Robot Learning with New Features and Integrations • Dev|Journal"><meta name="twitter:description" content="LeRobot v0.4.0: Supercharging OSS Robot Learning This release, LeRobot v0.4.0, marks a significant leap forward in open-source robotics, focusing on enhancing…"><meta name="twitter:image" content="https://earezki.com/assets/og-image-default.jpg"><meta name="twitter:creator" content="@earezki"><link rel="canonical" href="https://earezki.com/ai-news/2025-10-24-lerobot-v040-supercharging-oss-robot-learning/"><link rel="alternate" type="application/rss+xml" title="RSS" href="/rss.xml"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-161447264-1"></script><script defer src="https://cloud.umami.is/script.js" data-website-id="4a26531d-1053-4f79-97a6-06a1366aff91"></script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"LeRobot v0.4.0: Supercharging OSS Robot Learning with New Features and Integrations","datePublished":"2025-10-25T00:00:00.000Z","dateModified":"2025-10-25T00:00:00.000Z","author":{"@type":"Person","name":"AREZKI El Mehdi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://earezki.com/ai-news/2025-10-24-lerobot-v040-supercharging-oss-robot-learning/"},"description":"LeRobot v0.4.0: Supercharging OSS Robot Learning This release, LeRobot v0.4.0, marks a significant leap forward in open-source robotics, focusing on enhancing…"}</script><link rel="stylesheet" href="/_astro/_slug_.CDWqF8AB.css">
<style>.post-layout[data-astro-cid-rkg3zjxi]{display:grid;grid-template-columns:260px 1fr;gap:2.5rem}.sidebar-left[data-astro-cid-rkg3zjxi]{position:relative}@media (max-width: 1080px){.post-layout[data-astro-cid-rkg3zjxi]{grid-template-columns:1fr}}.ai-disclaimer-article[data-astro-cid-rkg3zjxi]{display:flex;gap:.75rem;padding:.9rem 1.1rem;margin:0 auto 2rem;max-width:780px;background:linear-gradient(135deg,#667eea1a,#764ba21a,#f093fb1a);border:2px solid transparent;border-radius:var(--radius-md);position:relative;background-clip:padding-box;font-size:.85rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi]:before{content:"";position:absolute;inset:-2px;border-radius:var(--radius-md);padding:2px;background:var(--ai-gradient-border);background-size:200% 200%;animation:gradient-rotate 3s linear infinite;-webkit-mask:linear-gradient(#fff 0 0) content-box,linear-gradient(#fff 0 0);-webkit-mask-composite:xor;mask:linear-gradient(#fff 0 0) content-box,linear-gradient(#fff 0 0);mask-composite:exclude;pointer-events:none}html[data-theme=dark] .ai-disclaimer-article[data-astro-cid-rkg3zjxi]{background:linear-gradient(135deg,#667eea26,#764ba226,#f093fb26)}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] svg[data-astro-cid-rkg3zjxi]{margin-top:.15rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] strong[data-astro-cid-rkg3zjxi]{color:var(--color-text);display:block;margin-bottom:.15rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] div[data-astro-cid-rkg3zjxi]{line-height:1.5;color:var(--color-text-alt)}
.toc[data-astro-cid-xvrfupwn]{position:sticky;top:90px;max-height:calc(100vh - 120px);overflow:auto;padding:1rem 1rem 1.2rem;background:var(--color-bg-alt);border:1px solid var(--color-border);border-radius:var(--radius-md);font-size:.8rem;line-height:1.3}.toc-title[data-astro-cid-xvrfupwn]{font-weight:600;font-size:.75rem;text-transform:uppercase;letter-spacing:.08em;margin-bottom:.6rem;color:var(--color-text-alt)}.toc[data-astro-cid-xvrfupwn] ul[data-astro-cid-xvrfupwn]{list-style:none;margin:0;padding:0;display:flex;flex-direction:column;gap:.35rem}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]{text-decoration:none;color:var(--color-text-alt)}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]:hover{color:var(--color-accent)}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn][class*=d-3]{margin-left:.75rem}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn][class*=d-4]{margin-left:1.4rem}@media (max-width: 1080px){.toc[data-astro-cid-xvrfupwn]{display:none}}
</style><script type="module" src="/_astro/hoisted.CwSnpN4J.js"></script></head> <body> <div id="readingProgress" style="position:fixed;left:0;top:0;height:3px;background:linear-gradient(90deg,#2563eb,#9333ea);width:0;z-index:999;transition:width .15s ease;"></div>  <header class="site-header container"> <div class="logo-wrap"> <a class="logo" href="/">Dev|Journal</a> </div> <nav class="main-nav"> <a href="/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: -2px; margin-right: 4px;"> <path d="m3 9 9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path> <polyline points="9 22 9 12 15 12 15 22"></polyline> </svg>
Home
</a> <a href="/ai-news/" class="ai-news-link"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: -2px; margin-right: 4px;"> <path d="M12 2a2 2 0 0 1 2 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 0 1 7 7h-9.5a.5.5 0 0 0-.5.5.5.5 0 0 1-1 0 .5.5 0 0 0-.5-.5H1a7 7 0 0 1 7-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 0 1 2-2z"></path> <path d="M7 15v4a2 2 0 0 0 2 2h6a2 2 0 0 0 2-2v-4"></path> </svg>
AI News
</a> <a href="/tags/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: -2px; margin-right: 4px;"> <path d="M12 2H2v10l9.29 9.29c.94.94 2.48.94 3.42 0l6.58-6.58c.94-.94.94-2.48 0-3.42L12 2z"></path> <circle cx="7" cy="7" r="1.5"></circle> </svg>
Tags
</a> <a href="/about/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="vertical-align: -2px; margin-right: 4px;"> <circle cx="12" cy="12" r="10"></circle> <path d="M12 16v-4"></path> <path d="M12 8h.01"></path> </svg>
About
</a> <button id="themeToggle" class="theme-toggle" aria-label="Toggle dark mode"> <span class="theme-icon">☾</span> <span class="theme-text">dark</span> </button> </nav> </header> <main class="container content-area">  <div class="ai-disclaimer-article" data-astro-cid-rkg3zjxi> <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="flex-shrink: 0;" data-astro-cid-rkg3zjxi> <circle cx="12" cy="12" r="10" data-astro-cid-rkg3zjxi></circle> <line x1="12" y1="8" x2="12" y2="12" data-astro-cid-rkg3zjxi></line> <line x1="12" y1="16" x2="12.01" y2="16" data-astro-cid-rkg3zjxi></line> </svg> <div data-astro-cid-rkg3zjxi> <strong data-astro-cid-rkg3zjxi>AI-Generated Content:</strong> This article was created with AI assistance. Please verify important information and check original references.
</div> </div> <div class="post-layout" data-astro-cid-rkg3zjxi> <aside class="sidebar-left" data-astro-cid-rkg3zjxi> <nav class="toc" aria-label="Table of Contents" data-astro-cid-xvrfupwn> <div class="toc-title" data-astro-cid-xvrfupwn>On this page</div> <ul data-astro-cid-xvrfupwn> <li class="d-2" data-astro-cid-xvrfupwn><a href="#lerobot-v040-supercharging-oss-robot-learning" data-astro-cid-xvrfupwn>LeRobot v0.4.0: Supercharging OSS Robot Learning</a></li><li class="d-3" data-astro-cid-xvrfupwn><a href="#overview" data-astro-cid-xvrfupwn>Overview</a></li><li class="d-2" data-astro-cid-xvrfupwn><a href="#datasets-ready-for-the-next-wave-of-large-scale-robot-learning" data-astro-cid-xvrfupwn>Datasets: Ready for the Next Wave of Large-Scale Robot Learning</a></li><li class="d-3" data-astro-cid-xvrfupwn><a href="#key-features-of-lerobotdataset-v30" data-astro-cid-xvrfupwn>Key Features of LeRobotDataset v3.0:</a></li><li class="d-3" data-astro-cid-xvrfupwn><a href="#new-feature-dataset-editing-tools" data-astro-cid-xvrfupwn>New Feature: Dataset Editing Tools</a></li><li class="d-2" data-astro-cid-xvrfupwn><a href="#simulation-environments-expanding-your-training-grounds" data-astro-cid-xvrfupwn>Simulation Environments: Expanding Your Training Grounds</a></li><li class="d-3" data-astro-cid-xvrfupwn><a href="#libero-support" data-astro-cid-xvrfupwn>LIBERO Support</a></li><li class="d-3" data-astro-cid-xvrfupwn><a href="#meta-world-integration" data-astro-cid-xvrfupwn>Meta-World Integration</a></li><li class="d-2" data-astro-cid-xvrfupwn><a href="#codebase-powerful-tools-for-everyone" data-astro-cid-xvrfupwn>Codebase: Powerful Tools For Everyone</a></li><li class="d-3" data-astro-cid-xvrfupwn><a href="#the-new-pipeline-for-data-processing" data-astro-cid-xvrfupwn>The New Pipeline for Data Processing</a></li><li class="d-3" data-astro-cid-xvrfupwn><a href="#multi-gpu-training-made-easy" data-astro-cid-xvrfupwn>Multi-GPU Training Made Easy</a></li><li class="d-2" data-astro-cid-xvrfupwn><a href="#policies-unleashing-open-world-generalization" data-astro-cid-xvrfupwn>Policies: Unleashing Open-World Generalization</a></li><li class="d-3" data-astro-cid-xvrfupwn><a href="#pi0-and-pi05" data-astro-cid-xvrfupwn>PI0 and PI0.5</a></li><li class="d-3" data-astro-cid-xvrfupwn><a href="#gr00t-n15" data-astro-cid-xvrfupwn>GR00T N1.5</a></li><li class="d-2" data-astro-cid-xvrfupwn><a href="#robots-a-new-era-of-hardware-integration-with-the-plugin-system" data-astro-cid-xvrfupwn>Robots: A New Era of Hardware Integration with the Plugin System</a></li><li class="d-2" data-astro-cid-xvrfupwn><a href="#the-hugging-face-robot-learning-course" data-astro-cid-xvrfupwn>The Hugging Face Robot Learning Course</a></li><li class="d-2" data-astro-cid-xvrfupwn><a href="#final-thoughts-from-the-team" data-astro-cid-xvrfupwn>Final thoughts from the team</a></li> </ul> </nav>  </aside> <article class="post" data-astro-cid-rkg3zjxi> <header class="post-header" data-astro-cid-rkg3zjxi> <h1 data-astro-cid-rkg3zjxi>LeRobot v0.4.0: Supercharging OSS Robot Learning with New Features and Integrations</h1> <div class="meta" data-astro-cid-rkg3zjxi> <time datetime="2025-10-25T00:00:00.000Z" data-astro-cid-rkg3zjxi>Sat Oct 25 2025</time> <span data-astro-cid-rkg3zjxi>• 4 min read</span> </div> <div class="tag-row" data-astro-cid-rkg3zjxi><a class="tag ai-news-tag" href="/ai-news/" data-astro-cid-rkg3zjxi>AI News</a><span class="tag" data-astro-cid-rkg3zjxi>Robotics</span><span class="tag" data-astro-cid-rkg3zjxi>Open Source</span></div> </header> <div class="post-body prose" data-astro-cid-rkg3zjxi> <h2 id="lerobot-v040-supercharging-oss-robot-learning">LeRobot v0.4.0: Supercharging OSS Robot Learning</h2>
<p>This release, LeRobot v0.4.0, marks a significant leap forward in open-source robotics, focusing on enhancing scalability, flexibility, and accessibility for robot learning. Key improvements include revamped datasets, expanded simulation environment support, a powerful new data processing pipeline, and a revolutionary plugin system for hardware integration.  The release also introduces new state-of-the-art VLA policies (pi0, pi0.5, and GR00T N1.5) and a comprehensive learning course.</p>
<h3 id="overview">Overview</h3>
<p>LeRobot v0.4.0 focuses on making robot learning more powerful, scalable, and user-friendly. The release introduces several key features:</p>
<ul>
<li><strong>Scalable Datasets:</strong> New <code>LeRobotDataset v3.0</code> with chunked episodes and streaming capabilities.</li>
<li><strong>Expanded Simulation Environments:</strong> Support for LIBERO and Meta-World.</li>
<li><strong>Flexible Codebase:</strong> New <code>Processors</code> pipeline for data handling and simplified multi-GPU training.</li>
<li><strong>Hardware Integration:</strong>  A new plugin system for easy integration of third-party hardware.</li>
<li><strong>Advanced Policies:</strong> Integration of PI0, PI0.5, and GR00T N1.5 VLA policies.</li>
<li><strong>Educational Resources:</strong> A new, open-source Hugging Face Robot Learning Course.</li>
</ul>
<h2 id="datasets-ready-for-the-next-wave-of-large-scale-robot-learning">Datasets: Ready for the Next Wave of Large-Scale Robot Learning</h2>
<p>LeRobot v0.4.0 introduces a completely overhauled dataset infrastructure with <strong>LeRobotDataset v3.0</strong>. This update is designed to handle massive datasets efficiently.</p>
<h3 id="key-features-of-lerobotdataset-v30">Key Features of LeRobotDataset v3.0:</h3>
<ul>
<li><strong>Chunked Episodes:</strong> Supports datasets exceeding 400GB, enabling unprecedented scalability (e.g., OXE).</li>
<li><strong>Efficient Video Storage &#x26; Streaming:</strong>  Faster loading and seamless streaming of video data.</li>
<li><strong>Unified Parquet Metadata:</strong>  All episode metadata stored in structured Parquet files for easier management.</li>
<li><strong>Improved Performance:</strong> Reduced dataset initialization times and more efficient memory usage.</li>
</ul>
<p><strong>Impact:</strong> This update significantly improves the scalability and efficiency of working with large-scale robot datasets, opening up new possibilities for training more complex and capable robot policies.</p>
<p><strong>Conversion Script:</strong> A conversion script is provided to migrate existing v2.1 datasets to the new v3.0 format.</p>
<h3 id="new-feature-dataset-editing-tools">New Feature: Dataset Editing Tools</h3>
<p>The release includes <code>lerobot-edit-dataset</code>, a CLI tool for flexible dataset manipulation:</p>
<ul>
<li><strong>Delete Episodes:</strong> Remove specific episodes from datasets.</li>
<li><strong>Split Datasets:</strong> Divide datasets by fractions or episode indices.</li>
<li><strong>Add/Remove Features:</strong> Easily modify the features within datasets.</li>
<li><strong>Merge Datasets:</strong> Combine multiple datasets into a single unified dataset.</li>
</ul>
<p><strong>Impact:</strong>  These tools streamline dataset curation and optimization, allowing researchers and developers to easily prepare datasets for training.</p>
<h2 id="simulation-environments-expanding-your-training-grounds">Simulation Environments: Expanding Your Training Grounds</h2>
<p>LeRobot v0.4.0 expands its simulation capabilities with support for two new benchmarks:</p>
<h3 id="libero-support">LIBERO Support</h3>
<p>LeRobot now officially supports LIBERO, a large open benchmark for Vision-Language-Action (VLA) policies, containing over 130 tasks.</p>
<p><strong>Impact:</strong> LIBERO provides a standardized evaluation hub for VLA policies, enabling easy integration and comparison.</p>
<h3 id="meta-world-integration">Meta-World Integration</h3>
<p>Integration with Meta-World, a benchmark for testing multi-task and generalization abilities in robotic manipulation, is included.</p>
<p><strong>Impact:</strong> Meta-World allows for evaluating the generalization capabilities of robot policies across diverse manipulation tasks.</p>
<h2 id="codebase-powerful-tools-for-everyone">Codebase: Powerful Tools For Everyone</h2>
<p>LeRobot v0.4.0 introduces significant improvements to its codebase, making data processing and training more flexible and accessible.</p>
<h3 id="the-new-pipeline-for-data-processing">The New Pipeline for Data Processing</h3>
<p>The introduction of <strong>Processors</strong> provides a modular pipeline for data handling.  Processors act as a “translator” between raw data and the expected format for AI models and robot hardware.</p>
<ul>
<li><strong>PolicyProcessorPipeline:</strong> Designed for models, handling batched tensors for training and inference.</li>
<li><strong>RobotProcessorPipeline:</strong> Designed for hardware, processing individual data points for real-time control.</li>
</ul>
<p><strong>Impact:</strong> The new pipeline simplifies data preprocessing and ensures data is in the correct format for each stage of the robot learning process.</p>
<h3 id="multi-gpu-training-made-easy">Multi-GPU Training Made Easy</h3>
<p>The release simplifies multi-GPU training by integrating Accelerate directly into the training pipeline.</p>
<p><strong>Command:</strong></p>
<pre class="astro-code github-dark-default" style="background-color:#0d1117;color:#e6edf3; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>accelerate launch \</span></span>
<span class="line"><span>--multi_gpu \</span></span>
<span class="line"><span>--num_processes=$NUM_GPUs \</span></span>
<span class="line"><span>$(which lerobot-train) \</span></span>
<span class="line"><span>--dataset.repo_id=${HF_USER}/my_dataset \</span></span>
<span class="line"><span>--policy.repo_id=${HF_USER}/my_trained_policy \</span></span>
<span class="line"><span>--policy.type=$POLICY_TYPE \</span></span>
<span class="line"><span># ... More training configuration flags</span></span>
<span class="line"><span></span></span></code></pre>
<p><strong>Impact:</strong> This simplifies distributed training, reducing training time significantly (up to 2x with 2 GPUs, 3x with 3 GPUs).</p>
<h2 id="policies-unleashing-open-world-generalization">Policies: Unleashing Open-World Generalization</h2>
<p>LeRobot v0.4.0 integrates several state-of-the-art VLA policies:</p>
<h3 id="pi0-and-pi05">PI0 and PI0.5</h3>
<p>Integration of PI0 and PI0.5 policies from Physical Intelligence.</p>
<ul>
<li><strong>Open-World Generalization:</strong> Adapts to new environments and situations.</li>
<li><strong>Co-training on Heterogeneous Data:</strong> Learns from diverse data sources.</li>
</ul>
<p><strong>Impact:</strong> PI0 and PI0.5 represent a significant step towards achieving true open-world generalization in robotics.</p>
<h3 id="gr00t-n15">GR00T N1.5</h3>
<p>Integration of NVIDIA’s GR00T N1.5 model.</p>
<ul>
<li><strong>Generalized Reasoning &#x26; Skills:</strong>  Excels at reasoning and manipulation tasks.</li>
<li><strong>Extensive Training Data:</strong> Trained on a massive dataset combining real and synthetic data.</li>
</ul>
<p><strong>Impact:</strong> GR00T N1.5 provides a powerful foundation model for various robotic tasks.</p>
<h2 id="robots-a-new-era-of-hardware-integration-with-the-plugin-system">Robots: A New Era of Hardware Integration with the Plugin System</h2>
<p>A new plugin system allows for easy integration of third-party hardware.</p>
<ul>
<li><strong>Extensibility:</strong> Develop custom hardware components as separate packages.</li>
<li><strong>Scalability:</strong> Supports a growing ecosystem of devices without modifying the core library.</li>
<li><strong>Community-Friendly:</strong> Lowers the barrier to entry for community contributions.</li>
</ul>
<p><strong>Impact:</strong> The plugin system significantly simplifies hardware integration, fostering a more collaborative and extensible ecosystem.</p>
<p><strong>Reachy 2 Integration:</strong>  Support for Pollen Robotics’ Reachy 2 is added.</p>
<p><strong>Phone Teleoperation:</strong> Enables teleoperation of robots from iOS/Android devices.</p>
<h2 id="the-hugging-face-robot-learning-course">The Hugging Face Robot Learning Course</h2>
<p>A new, self-paced, open-source course is launched to teach robot learning fundamentals.</p>
<p><strong>Topics Covered:</strong></p>
<ul>
<li>Fundamentals of robotics</li>
<li>Generative models for imitation learning</li>
<li>Reinforcement Learning</li>
<li>Generalist policies (PI0, PI0.5)</li>
</ul>
<p><strong>Impact:</strong>  The course makes robot learning accessible to a wider audience.</p>
<h2 id="final-thoughts-from-the-team">Final thoughts from the team</h2>
<p>The team expresses gratitude to the community for contributions and feedback.  They emphasize the importance of collaboration and look forward to future developments.</p>
<hr>
<p><strong>Reference Link:</strong> <a href="https://huggingface.co/blog/lerobot-release-v040">https://huggingface.co/blog/lerobot-release-v040</a></p> </div> </article> </div> <div class="back-link" data-astro-cid-rkg3zjxi><a href="/ai-news/" data-astro-cid-rkg3zjxi>← Back to AI News</a></div>  </main> <footer class="site-footer container"> <p>© 2025 AREZKI El Mehdi • <a href="https://github.com/earezki">GitHub</a> • <a href="/rss.xml">RSS</a></p> </footer>  <script>
      // Read/Unread article tracking
      (function() {
        const STORAGE_KEY = 'readArticles';
        
        function getReadArticles() {
          try {
            const data = localStorage.getItem(STORAGE_KEY);
            return data ? JSON.parse(data) : [];
          } catch (e) {
            return [];
          }
        }
        
        function markArticleAsRead(url) {
          try {
            const readArticles = getReadArticles();
            if (!readArticles.includes(url)) {
              readArticles.push(url);
              localStorage.setItem(STORAGE_KEY, JSON.stringify(readArticles));
            }
          } catch (e) {
            console.error('Failed to mark article as read:', e);
          }
        }
        
        function isArticleRead(url) {
          const readArticles = getReadArticles();
          return readArticles.includes(url);
        }
        
        // Update post cards on list pages
        function updatePostCards() {
          const postCards = document.querySelectorAll('.post-card[data-article-url]');
          postCards.forEach(function(card) {
            const url = card.getAttribute('data-article-url');
            if (url) {
              if (isArticleRead(url)) {
                card.classList.add('read');
                card.classList.remove('unread');
              } else {
                card.classList.add('unread');
                card.classList.remove('read');
              }
            }
          });
        }
        
        // Mark current article as read (on article pages)
        function markCurrentArticleAsRead() {
          const isArticlePage = document.querySelector('.post-body');
          if (isArticlePage) {
            const currentPath = window.location.pathname;
            markArticleAsRead(currentPath);
          }
        }
        
        // Initialize function
        function init() {
          updatePostCards();
          markCurrentArticleAsRead();
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', init);
        
        // Handle back/forward navigation (bfcache)
        window.addEventListener('pageshow', function(event) {
          // If page is loaded from cache, update the cards
          if (event.persisted) {
            init();
          }
        });
      })();
    </script> </body> </html> 