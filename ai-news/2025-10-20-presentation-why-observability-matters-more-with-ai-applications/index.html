<!DOCTYPE html><html lang="en" data-theme="dark"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><!-- Primary Meta Tags --><title>Why Observability Matters for AI Applications: A Deep Dive into LLM Monitoring • Dev|Journal</title><meta name="description" content="Main Heading: Observability in the Age of AI: Addressing the Unique Challenges of LLMs This presentation by Sally O'Malley from Red Hat delves into the…"><meta name="keywords" content="software architecture, backend development, microservices, Java, Python, Spring Boot, technical blog"><meta name="author" content="El Mehdi Arezki"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://earezki.com/ai-news/2025-10-20-presentation-why-observability-matters-more-with-ai-applications/"><meta property="og:title" content="Why Observability Matters for AI Applications: A Deep Dive into LLM Monitoring • Dev|Journal"><meta property="og:site_name" content="Dev|Journal"><meta property="og:description" content="Main Heading: Observability in the Age of AI: Addressing the Unique Challenges of LLMs This presentation by Sally O'Malley from Red Hat delves into the…"><meta property="og:image" content="https://earezki.com/assets/og-image-default.jpg"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:url" content="https://earezki.com/ai-news/2025-10-20-presentation-why-observability-matters-more-with-ai-applications/"><meta name="twitter:title" content="Why Observability Matters for AI Applications: A Deep Dive into LLM Monitoring • Dev|Journal"><meta name="twitter:description" content="Main Heading: Observability in the Age of AI: Addressing the Unique Challenges of LLMs This presentation by Sally O'Malley from Red Hat delves into the…"><meta name="twitter:image" content="https://earezki.com/assets/og-image-default.jpg"><meta name="twitter:creator" content="@earezki"><!-- Canonical and Indexing --><link rel="canonical" href="https://earezki.com/ai-news/2025-10-20-presentation-why-observability-matters-more-with-ai-applications/"><!-- Favicons --><link rel="icon" type="image/svg+xml" href="/favicon.svg"><link rel="icon" type="image/x-icon" href="/favicon.ico"><!-- RSS Feed --><link rel="alternate" type="application/rss+xml" title="RSS" href="/rss.xml"><!-- Analytics: Google Analytics (Legacy UA) --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-161447264-1"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);} 
      gtag('js', new Date()); 
      gtag('config', 'UA-161447264-1');
    </script><!-- Analytics: Umami --><script defer src="https://cloud.umami.is/script.js" data-website-id="4a26531d-1053-4f79-97a6-06a1366aff91"></script><!-- Theme Persistence (runs before page render to prevent flash) --><script>
      (function() {
        const theme = localStorage.getItem('theme');
        if (theme) { 
          document.documentElement.setAttribute('data-theme', theme); 
        }
      })();
    </script><!-- Structured Data (JSON-LD) --><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Why Observability Matters for AI Applications: A Deep Dive into LLM Monitoring","datePublished":"2025-10-20T00:00:00.000Z","dateModified":"2025-10-20T00:00:00.000Z","author":{"@type":"Person","name":"AREZKI El Mehdi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://earezki.com/ai-news/2025-10-20-presentation-why-observability-matters-more-with-ai-applications/"},"description":"Main Heading: Observability in the Age of AI: Addressing the Unique Challenges of LLMs This presentation by Sally O'Malley from Red Hat delves into the…"}</script><link rel="stylesheet" href="/_astro/_slug_.C8vOLobN.css">
<style>.toc[data-astro-cid-xvrfupwn]{position:sticky;top:90px;max-height:calc(100vh - 120px);overflow:auto;padding:1rem 1rem 1.2rem;background:var(--color-bg-alt);border:1px solid var(--color-border);border-radius:var(--radius-md);font-size:.8rem;line-height:1.3}.toc-title[data-astro-cid-xvrfupwn]{font-weight:600;font-size:.75rem;text-transform:uppercase;letter-spacing:.08em;margin-bottom:.6rem;color:var(--color-text-alt)}.toc[data-astro-cid-xvrfupwn] ul[data-astro-cid-xvrfupwn]{list-style:none;margin:0;padding:0;display:flex;flex-direction:column;gap:.35rem}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]{text-decoration:none;color:var(--color-text-alt);transition:color var(--transition)}.toc[data-astro-cid-xvrfupwn] a[data-astro-cid-xvrfupwn]:hover{color:var(--color-accent)}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn][class*=d-3]{margin-left:.75rem}.toc[data-astro-cid-xvrfupwn] li[data-astro-cid-xvrfupwn][class*=d-4]{margin-left:1.4rem}@media (max-width: 1080px){.toc[data-astro-cid-xvrfupwn]{display:none}}.breadcrumbs[data-astro-cid-ilhxcym7]{margin:0 0 1.5rem;font-size:.85rem}.breadcrumbs[data-astro-cid-ilhxcym7] ol[data-astro-cid-ilhxcym7]{list-style:none;padding:0;margin:0;display:flex;flex-wrap:wrap;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] li[data-astro-cid-ilhxcym7]{display:flex;align-items:center;gap:.5rem}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]{color:var(--color-text-alt);text-decoration:none;transition:color var(--transition)}.breadcrumbs[data-astro-cid-ilhxcym7] a[data-astro-cid-ilhxcym7]:hover{color:var(--color-accent);text-decoration:underline}.breadcrumbs[data-astro-cid-ilhxcym7] .separator[data-astro-cid-ilhxcym7]{color:var(--color-text-alt);opacity:.5;user-select:none}.breadcrumbs[data-astro-cid-ilhxcym7] .current[data-astro-cid-ilhxcym7]{color:var(--color-text);font-weight:500}.related-posts[data-astro-cid-dpgbfi7r]{margin:3rem 0;padding-top:2rem;border-top:2px solid var(--color-border)}.related-posts[data-astro-cid-dpgbfi7r] h2[data-astro-cid-dpgbfi7r]{font-size:1.5rem;margin:0 0 1.5rem;color:var(--color-text)}.related-posts-grid[data-astro-cid-dpgbfi7r]{display:grid;grid-template-columns:repeat(auto-fit,minmax(280px,1fr));gap:1.5rem}.related-post-card[data-astro-cid-dpgbfi7r]{background:var(--color-bg-alt);border:1px solid var(--color-border);border-radius:var(--radius-md);padding:1.25rem;transition:all var(--transition)}.related-post-card[data-astro-cid-dpgbfi7r]:hover{border-color:var(--color-accent);transform:translateY(-2px);box-shadow:var(--shadow-md)}.related-post-link[data-astro-cid-dpgbfi7r]{text-decoration:none;color:inherit;display:block}.related-post-card[data-astro-cid-dpgbfi7r] h3[data-astro-cid-dpgbfi7r]{margin:0 0 .75rem;font-size:1.1rem;font-weight:600;color:var(--color-text);line-height:1.3}.related-post-link[data-astro-cid-dpgbfi7r]:hover h3[data-astro-cid-dpgbfi7r]{color:var(--color-accent)}.related-excerpt[data-astro-cid-dpgbfi7r]{font-size:.85rem;color:var(--color-text-alt);line-height:1.5;margin:0 0 .75rem}.related-meta[data-astro-cid-dpgbfi7r]{font-size:.75rem;color:var(--color-text-alt);display:flex;gap:.5rem;align-items:center}@media (max-width: 680px){.related-posts-grid[data-astro-cid-dpgbfi7r]{grid-template-columns:1fr}}
.post-layout[data-astro-cid-rkg3zjxi]{display:grid;grid-template-columns:260px 1fr;gap:2.5rem}.sidebar-left[data-astro-cid-rkg3zjxi]{position:relative}@media (max-width: 1080px){.post-layout[data-astro-cid-rkg3zjxi]{grid-template-columns:1fr}}.ai-disclaimer-article[data-astro-cid-rkg3zjxi]{display:flex;gap:.75rem;padding:.9rem 1.1rem;margin:0 auto 2rem;max-width:780px;background:linear-gradient(135deg,#667eea1a,#764ba21a,#f093fb1a);border:2px solid transparent;border-radius:var(--radius-md);position:relative;background-clip:padding-box;font-size:.85rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi]:before{content:"";position:absolute;inset:-2px;border-radius:var(--radius-md);padding:2px;background:var(--ai-gradient-border);background-size:200% 200%;animation:gradient-rotate 3s linear infinite;-webkit-mask:linear-gradient(#fff 0 0) content-box,linear-gradient(#fff 0 0);-webkit-mask-composite:xor;mask:linear-gradient(#fff 0 0) content-box,linear-gradient(#fff 0 0);mask-composite:exclude;pointer-events:none}html[data-theme=dark] .ai-disclaimer-article[data-astro-cid-rkg3zjxi]{background:linear-gradient(135deg,#667eea26,#764ba226,#f093fb26)}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] svg[data-astro-cid-rkg3zjxi]{margin-top:.15rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] strong[data-astro-cid-rkg3zjxi]{color:var(--color-text);display:block;margin-bottom:.15rem}.ai-disclaimer-article[data-astro-cid-rkg3zjxi] div[data-astro-cid-rkg3zjxi]{line-height:1.5;color:var(--color-text-alt)}
</style><script type="module" src="/_astro/hoisted.2U5tn40l.js"></script></head> <body> <div id="readingProgress" role="progressbar" aria-label="Reading progress" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100" style="position:fixed;left:0;top:0;height:3px;background:linear-gradient(90deg,#2563eb,#9333ea);width:0;z-index:999;transition:width .15s ease;"></div>  <!-- Site Header --> <header class="site-header container"> <div class="logo-wrap"> <a class="logo" href="/" aria-label="Dev|Journal Home">
Dev|Journal
</a> </div> <nav class="main-nav" aria-label="Main navigation"> <a href="/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="m3 9 9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path> <polyline points="9 22 9 12 15 12 15 22"></polyline> </svg>
Home
</a> <a href="/ai-news/" class="ai-news-link"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="M12 2a2 2 0 0 1 2 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 0 1 7 7h-9.5a.5.5 0 0 0-.5.5.5.5 0 0 1-1 0 .5.5 0 0 0-.5-.5H1a7 7 0 0 1 7-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 0 1 2-2z"></path> <path d="M7 15v4a2 2 0 0 0 2 2h6a2 2 0 0 0 2-2v-4"></path> </svg>
AI News
</a> <a href="/tags/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <path d="M12 2H2v10l9.29 9.29c.94.94 2.48.94 3.42 0l6.58-6.58c.94-.94.94-2.48 0-3.42L12 2z"></path> <circle cx="7" cy="7" r="1.5"></circle> </svg>
Tags
</a> <a href="/about/"> <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true" style="vertical-align: -2px; margin-right: 4px;"> <circle cx="12" cy="12" r="10"></circle> <path d="M12 16v-4"></path> <path d="M12 8h.01"></path> </svg>
About
</a> <button id="themeToggle" class="theme-toggle" aria-label="Toggle dark mode"> <span class="theme-icon" aria-hidden="true">☾</span> <span class="theme-text">dark</span> </button> </nav> </header> <!-- Main Content --> <main class="container content-area">  <nav class="breadcrumbs" aria-label="Breadcrumb" data-astro-cid-ilhxcym7> <ol data-astro-cid-ilhxcym7> <li data-astro-cid-ilhxcym7>  <a href="/" data-astro-cid-ilhxcym7>Home</a> <span class="separator" aria-hidden="true" data-astro-cid-ilhxcym7>/</span>  </li><li data-astro-cid-ilhxcym7>  <a href="/ai-news/" data-astro-cid-ilhxcym7>Ai News</a> <span class="separator" aria-hidden="true" data-astro-cid-ilhxcym7>/</span>  </li><li data-astro-cid-ilhxcym7> <span class="current" aria-current="page" data-astro-cid-ilhxcym7>Why Observability Matters for AI Applications: A Deep Dive into LLM Monitoring</span> </li> </ol> </nav>  <div class="ai-disclaimer-article" data-astro-cid-rkg3zjxi> <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="flex-shrink: 0;" data-astro-cid-rkg3zjxi> <circle cx="12" cy="12" r="10" data-astro-cid-rkg3zjxi></circle> <line x1="12" y1="8" x2="12" y2="12" data-astro-cid-rkg3zjxi></line> <line x1="12" y1="16" x2="12.01" y2="16" data-astro-cid-rkg3zjxi></line> </svg> <div data-astro-cid-rkg3zjxi> <strong data-astro-cid-rkg3zjxi>AI-Generated Content:</strong> This article was created with AI assistance. Please verify important information and check original references.
</div> </div> <div class="post-layout" data-astro-cid-rkg3zjxi> <aside class="sidebar-left" data-astro-cid-rkg3zjxi> <nav class="toc" aria-label="Table of Contents" data-astro-cid-xvrfupwn> <div class="toc-title" data-astro-cid-xvrfupwn>On this page</div> <ul data-astro-cid-xvrfupwn> <li class="d-2" data-astro-cid-xvrfupwn> <a href="#main-heading-observability-in-the-age-of-ai-addressing-the-unique-challenges-of-llms" data-astro-cid-xvrfupwn> Main Heading: Observability in the Age of AI: Addressing the Unique Challenges of LLMs </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#summary" data-astro-cid-xvrfupwn> Summary </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#detailed-breakdown" data-astro-cid-xvrfupwn> Detailed Breakdown </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#1-introduction-the-rise-of-ai-and-the-need-for-observability" data-astro-cid-xvrfupwn> 1. Introduction: The Rise of AI and the Need for Observability </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#2-why-llms-pose-unique-challenges" data-astro-cid-xvrfupwn> 2. Why LLMs Pose Unique Challenges </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#3-building-an-open-source-observability-stack" data-astro-cid-xvrfupwn> 3. Building an Open-Source Observability Stack </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#4-key-metrics-to-monitor" data-astro-cid-xvrfupwn> 4. Key Metrics to Monitor </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#5-practical-demonstration" data-astro-cid-xvrfupwn> 5.  Practical Demonstration </a> </li><li class="d-3" data-astro-cid-xvrfupwn> <a href="#6-qa-and-discussion" data-astro-cid-xvrfupwn> 6.  Q&amp;A and Discussion </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#conclusion" data-astro-cid-xvrfupwn> Conclusion </a> </li><li class="d-2" data-astro-cid-xvrfupwn> <a href="#references" data-astro-cid-xvrfupwn> References </a> </li> </ul> </nav>  </aside> <article class="post" data-astro-cid-rkg3zjxi> <header class="post-header" data-astro-cid-rkg3zjxi> <h1 data-astro-cid-rkg3zjxi>Why Observability Matters for AI Applications: A Deep Dive into LLM Monitoring</h1> <div class="meta" data-astro-cid-rkg3zjxi> <time datetime="2025-10-20T00:00:00.000Z" data-astro-cid-rkg3zjxi>Mon Oct 20 2025</time> <span data-astro-cid-rkg3zjxi>• 4 min read</span> </div> <div class="tag-row" data-astro-cid-rkg3zjxi><a class="post-tag ai-news-tag" href="/tags/ai-news/" data-astro-cid-rkg3zjxi>AI News</a><a class="post-tag " href="/tags/observability/" data-astro-cid-rkg3zjxi>Observability</a><a class="post-tag " href="/tags/llm/" data-astro-cid-rkg3zjxi>LLM</a><a class="post-tag " href="/tags/kubernetes/" data-astro-cid-rkg3zjxi>Kubernetes</a><a class="post-tag " href="/tags/monitoring/" data-astro-cid-rkg3zjxi>Monitoring</a></div> </header> <div class="post-body prose" data-astro-cid-rkg3zjxi> <h2 id="main-heading-observability-in-the-age-of-ai-addressing-the-unique-challenges-of-llms">Main Heading: Observability in the Age of AI: Addressing the Unique Challenges of LLMs</h2>
<p>This presentation by Sally O’Malley from Red Hat delves into the critical importance of observability for modern AI applications, particularly Large Language Models (LLMs).  It highlights the unique challenges LLMs present compared to traditional applications and provides a practical, hands-on guide to building an open-source observability stack.  The talk emphasizes the need for monitoring performance, cost, and quality to ensure the reliability and effectiveness of AI-powered workloads.</p>
<h2 id="summary">Summary</h2>
<p>This presentation addresses the growing need for observability in AI applications, focusing specifically on the challenges posed by LLMs.  O’Malley outlines the characteristics of LLMs that make them distinct from traditional applications, such as non-uniformity, variable latency, and cost considerations.  She then details a comprehensive approach to building an observability stack using open-source tools like vLLM, Llama Stack, Prometheus, Grafana, and OpenTelemetry.  The presentation covers key metrics to monitor, including performance (latency), cost (token usage), and quality (tool utilization, accuracy).  Finally, O’Malley demonstrates how to implement this stack and provides insights into the benefits of tracing for debugging and understanding AI model behavior.  The discussion also covers considerations for different roles within an organization (developers, SREs, etc.) and the importance of tools like Llama Stack for managing and monitoring AI applications.</p>
<h2 id="detailed-breakdown">Detailed Breakdown</h2>
<h3 id="1-introduction-the-rise-of-ai-and-the-need-for-observability">1. Introduction: The Rise of AI and the Need for Observability</h3>
<ul>
<li><strong>Context:</strong> The presentation begins by emphasizing the rapid growth of AI adoption across industries.  85% of executives recognize AI’s importance, yet 75% lack the expertise to implement it effectively.</li>
<li><strong>The Observability Challenge:</strong>  Traditional observability practices are insufficient for LLMs due to their inherent characteristics.  The talk highlights the need for specialized monitoring techniques.</li>
<li><strong>Focus:</strong> The presentation centers on providing a practical, open-source solution for monitoring AI workloads.</li>
</ul>
<h3 id="2-why-llms-pose-unique-challenges">2. Why LLMs Pose Unique Challenges</h3>
<ul>
<li><strong>Non-Uniformity:</strong> LLMs exhibit variable response times, making traditional metrics less reliable.</li>
<li><strong>Cost:</strong>  Running LLMs can be expensive, especially with GPU-intensive models.  Token usage is a primary cost driver.</li>
<li><strong>Complexity:</strong>  LLM workflows involve multiple stages (prefill, decode, agents), requiring granular monitoring.</li>
<li><strong>Dynamic Behavior:</strong>  LLM outputs can vary significantly even with the same input, necessitating robust tracking.</li>
</ul>
<h3 id="3-building-an-open-source-observability-stack">3. Building an Open-Source Observability Stack</h3>
<ul>
<li><strong>Core Components:</strong> The recommended stack includes:
<ul>
<li><strong>vLLM:</strong> A fast and easy-to-use library for LLM inference.</li>
<li><strong>Llama Stack:</strong> A framework for building AI applications, providing components like RAG, agents, and a unified API.</li>
<li><strong>Prometheus:</strong> A metrics backend for collecting and storing time-series data.</li>
<li><strong>Grafana:</strong> A visualization tool for creating dashboards and analyzing metrics.</li>
<li><strong>OpenTelemetry:</strong> A standard for collecting telemetry data (metrics, traces, logs).</li>
<li><strong>Tempo:</strong> A tracing backend for analyzing request flows and identifying bottlenecks.</li>
</ul>
</li>
<li><strong>Deployment:</strong> The presentation focuses on deploying this stack using Kubernetes, leveraging tools like Minikube for local development.</li>
<li><strong>Llama Stack and vLLM Integration:</strong> Llama Stack simplifies the deployment and management of LLMs, providing tools for RAG, agents, and a unified API.  vLLM is used for efficient model inference.</li>
<li><strong>OpenTelemetry Collector:</strong>  This component collects telemetry data from applications and forwards it to the chosen backend (Prometheus, Tempo).</li>
<li><strong>ServiceMonitors:</strong>  These Kubernetes resources automatically configure Prometheus to scrape metrics from services.</li>
<li><strong>Example Queries:</strong>  The presenter demonstrates how to use Grafana to query metrics related to GPU utilization, model usage, and latency.</li>
</ul>
<h3 id="4-key-metrics-to-monitor">4. Key Metrics to Monitor</h3>
<ul>
<li><strong>Performance Metrics:</strong>
<ul>
<li><strong>Latency:</strong> Time taken for different stages of the LLM workflow (prefill, decode).</li>
<li><strong>Throughput:</strong>  The number of requests processed per unit of time.</li>
</ul>
</li>
<li><strong>Cost Metrics:</strong>
<ul>
<li><strong>Token Usage:</strong>  The number of tokens processed by the model, directly impacting cost.</li>
<li><strong>GPU Utilization:</strong>  The amount of GPU resources consumed.</li>
</ul>
</li>
<li><strong>Quality Metrics:</strong>
<ul>
<li><strong>Tool Utilization:</strong>  Whether the LLM is using the intended tools.</li>
<li><strong>Accuracy:</strong>  The correctness of the LLM’s responses (requires integration with evaluation metrics).</li>
</ul>
</li>
<li><strong>Tracing:</strong>
<ul>
<li><strong>End-to-End Traces:</strong>  Visualize the entire request flow, identifying bottlenecks and latency hotspots.</li>
<li><strong>Context:</strong>  Understand the context of each request and its dependencies.</li>
</ul>
</li>
</ul>
<h3 id="5--practical-demonstration">5.  Practical Demonstration</h3>
<ul>
<li><strong>Live Demo:</strong> The presentation includes a live demonstration of the observability stack in action.</li>
<li><strong>Real-time Monitoring:</strong> The presenter shows how to monitor GPU utilization, track token usage, and analyze traces in real-time.</li>
<li><strong>Interactive Exploration:</strong> The audience is encouraged to explore the dashboards and experiment with different queries.</li>
</ul>
<h3 id="6--qa-and-discussion">6.  Q&#x26;A and Discussion</h3>
<ul>
<li><strong>Participant Questions:</strong> The Q&#x26;A session addresses questions regarding cost, tool choices, and the suitability of observability for different roles.</li>
<li><strong>Key Takeaways:</strong>  The discussion reinforces the importance of observability for ensuring the reliability, efficiency, and cost-effectiveness of LLM-powered applications.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>The presentation advocates for a proactive approach to observability in the age of AI, particularly for LLMs. By leveraging open-source tools and focusing on key metrics, organizations can gain valuable insights into their AI workloads, optimize performance, control costs, and ensure the delivery of high-quality results.  The choice between tools like Dynatrace and open-source options like Grafana and Tempo depends on specific needs and priorities.  The presentation emphasizes the importance of tracing for understanding complex AI workflows and debugging issues.</p>
<h2 id="references">References</h2>
<ul>
<li><strong>Original Presentation:</strong> <a href="https://www.infoq.com/presentations/observability-llm/">https://www.infoq.com/presentations/observability-llm/</a></li>
<li><strong>Llama Stack:</strong> <a href="https://github.com/meta-llama/Llama-Stack">https://github.com/meta-llama/Llama-Stack</a></li>
<li><strong>vLLM:</strong> <a href="https://github.com/vllm-project/vllm">https://github.com/vllm-project/vllm</a></li>
<li><strong>Minikube:</strong> <a href="https://minikube.sigs.k8s.io/docs/">https://minikube.sigs.k8s.io/docs/</a></li>
<li><strong>OpenTelemetry:</strong> <a href="https://opentelemetry.io/">https://opentelemetry.io/</a></li>
<li><strong>Grafana:</strong> <a href="https://grafana.com/">https://grafana.com/</a></li>
<li><strong>Prometheus:</strong> <a href="https://prometheus.io/">https://prometheus.io/</a></li>
<li><strong>InfoQ Dev Summit Boston 2025:</strong> <a href="https://www.infoq.com/events/devsummit-boston-2025/">https://www.infoq.com/events/devsummit-boston-2025/</a></li>
</ul> </div>  <section class="related-posts" data-astro-cid-dpgbfi7r> <h2 data-astro-cid-dpgbfi7r>Related Posts</h2> <div class="related-posts-grid" data-astro-cid-dpgbfi7r> <article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/stock-weather-ai/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>Stock Weather AI</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>Stock Weather AI — Reading the Market&#39;s Forecast Imagine a weather report for the markets: a short, clear summary about…</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-10-03T23:00:00.000Z" data-astro-cid-dpgbfi7r> Oct 3, 2025 </time> <span data-astro-cid-dpgbfi7r>•</span> <span data-astro-cid-dpgbfi7r>3 min read</span> </div> </a> </article><article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-10-20-article-a-plan-do-check-act-framework-for-ai-code-generation/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>A Plan-Do-Check-Act Framework for AI Code Generation</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>Summary: A Structured Approach to AI Code Generation with PDCA This article introduces a Plan-Do-Check-Act (PDCA)…</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-10-20T00:00:00.000Z" data-astro-cid-dpgbfi7r> Oct 20, 2025 </time> <span data-astro-cid-dpgbfi7r>•</span> <span data-astro-cid-dpgbfi7r>4 min read</span> </div> </a> </article><article class="related-post-card" data-astro-cid-dpgbfi7r> <a href="/ai-news/2025-10-20-disaggregated-scheduled-fabric-scaling-metas-ai-journey/" class="related-post-link" data-astro-cid-dpgbfi7r> <h3 data-astro-cid-dpgbfi7r>Disaggregated Scheduled Fabric (DSF): Scaling Meta’s AI Infrastructure</h3> <p class="related-excerpt" data-astro-cid-dpgbfi7r>Summary: Meta&#39;s Disaggregated Scheduled Fabric (DSF) for Scalable AI Training Meta has developed Disaggregated…</p> <div class="related-meta" data-astro-cid-dpgbfi7r> <time datetime="2025-10-20T00:00:00.000Z" data-astro-cid-dpgbfi7r> Oct 20, 2025 </time> <span data-astro-cid-dpgbfi7r>•</span> <span data-astro-cid-dpgbfi7r>4 min read</span> </div> </a> </article> </div> </section>  </article> </div> <div class="back-link" data-astro-cid-rkg3zjxi><a href="/ai-news/" data-astro-cid-rkg3zjxi>← Back to AI News</a></div>  </main> <!-- Site Footer --> <footer class="site-footer container"> <p>
© 2025 AREZKI El Mehdi •
<a href="https://github.com/earezki">GitHub</a> •
<a href="/rss.xml">RSS</a> •
<a href="/sitemap-index.xml">Sitemap</a> </p> </footer> <!-- Theme Toggle Script -->  <!-- Article Read/Unread Tracking --> <script>
      /**
       * Tracks which articles have been read using localStorage
       * Updates post card styling on list pages
       */
      (function() {
        const STORAGE_KEY = 'readArticles';
        
        /**
         * Gets list of read article URLs from localStorage
         */
        function getReadArticles() {
          try {
            const data = localStorage.getItem(STORAGE_KEY);
            return data ? JSON.parse(data) : [];
          } catch (e) {
            console.error('Failed to get read articles:', e);
            return [];
          }
        }
        
        /**
         * Marks an article URL as read
         */
        function markArticleAsRead(url) {
          try {
            const readArticles = getReadArticles();
            if (!readArticles.includes(url)) {
              readArticles.push(url);
              localStorage.setItem(STORAGE_KEY, JSON.stringify(readArticles));
            }
          } catch (e) {
            console.error('Failed to mark article as read:', e);
          }
        }
        
        /**
         * Checks if an article has been read
         */
        function isArticleRead(url) {
          const readArticles = getReadArticles();
          return readArticles.includes(url);
        }
        
        /**
         * Updates post card styling on list pages based on read status
         */
        function updatePostCards() {
          const postCards = document.querySelectorAll('.post-card[data-article-url]');
          
          postCards.forEach(function(card) {
            const url = card.getAttribute('data-article-url');
            if (!url) return;
            
            if (isArticleRead(url)) {
              card.classList.add('read');
              card.classList.remove('unread');
            } else {
              card.classList.add('unread');
              card.classList.remove('read');
            }
          });
        }
        
        /**
         * Marks current article as read (on article detail pages)
         */
        function markCurrentArticleAsRead() {
          const isArticlePage = document.querySelector('.post-body');
          if (isArticlePage) {
            const currentPath = window.location.pathname;
            markArticleAsRead(currentPath);
          }
        }
        
        /**
         * Initialize tracking system
         */
        function init() {
          updatePostCards();
          markCurrentArticleAsRead();
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', init);
        
        // Handle back/forward navigation (bfcache)
        window.addEventListener('pageshow', function(event) {
          if (event.persisted) {
            init();
          }
        });
      })();
    </script> <!-- Code Copy Functionality --> <script>
      /**
       * Adds copy buttons to all code blocks
       */
      (function() {
        /**
         * Creates a copy button element
         */
        function createCopyButton() {
          const button = document.createElement('button');
          button.className = 'copy-code-button';
          button.setAttribute('aria-label', 'Copy code to clipboard');
          button.innerHTML = `
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect>
              <path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path>
            </svg>
            <span>Copy</span>
          `;
          return button;
        }
        
        /**
         * Creates a success checkmark icon
         */
        function createCheckIcon() {
          return `
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
              <polyline points="20 6 9 17 4 12"></polyline>
            </svg>
            <span>Copied!</span>
          `;
        }
        
        /**
         * Copies text to clipboard
         */
        async function copyToClipboard(text) {
          try {
            await navigator.clipboard.writeText(text);
            return true;
          } catch (err) {
            // Fallback for older browsers
            const textArea = document.createElement('textarea');
            textArea.value = text;
            textArea.style.position = 'fixed';
            textArea.style.left = '-999999px';
            document.body.appendChild(textArea);
            textArea.select();
            try {
              document.execCommand('copy');
              document.body.removeChild(textArea);
              return true;
            } catch (e) {
              document.body.removeChild(textArea);
              return false;
            }
          }
        }
        
        /**
         * Handles copy button click
         */
        async function handleCopyClick(button, codeBlock) {
          const code = codeBlock.textContent || '';
          const success = await copyToClipboard(code);
          
          if (success) {
            const originalHTML = button.innerHTML;
            button.classList.add('copied');
            button.innerHTML = createCheckIcon();
            
            setTimeout(function() {
              button.classList.remove('copied');
              button.innerHTML = originalHTML;
            }, 2000);
          }
        }
        
        /**
         * Adds copy buttons to all code blocks
         */
        function addCopyButtons() {
          const codeBlocks = document.querySelectorAll('.post-body pre');
          
          codeBlocks.forEach(function(pre) {
            // Skip if button already exists
            if (pre.querySelector('.copy-code-button')) {
              return;
            }
            
            const button = createCopyButton();
            const codeBlock = pre.querySelector('code');
            
            if (codeBlock) {
              button.addEventListener('click', function() {
                handleCopyClick(button, codeBlock);
              });
              
              pre.appendChild(button);
            }
          });
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', addCopyButtons);
      })();
    </script> </body> </html> 